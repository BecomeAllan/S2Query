{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticScholarSearch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPlB2Kq3Fs/SzsQi0DACOcV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BecomeAllan/S2Search/blob/main/SemanticScholarSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S5xfBIUWDWZ"
      },
      "source": [
        "# Consumindo a API do SemanticScholar\n",
        "\n",
        "A seguir, tem uma classe sem parámetros chamada `Search()`, que ao instanciar-la em uma variável é possível fazer pesquisas sobre papers utilizando a api do SemanticScholar, dentre os parâmetros temos:\n",
        "\n",
        "- Buscar: Pesquisas sobre tópicos onde adicionar tópicos utiliza-se + (mais) e remover tópicos usamos - (menos)\n",
        "\n",
        "- Fields: O que será retornado como dados. Para utilizar, escolha dentre as opções sem utilizar espaço e separadas de virgulas:\n",
        "  - externalIds\n",
        "  - url\n",
        "  - title\n",
        "  - abstract\n",
        "  - venue \n",
        "  - year \n",
        "  - referenceCount\n",
        "  - citationCount\n",
        "  - influentialCitationCount\n",
        "  - isOpenAccess\n",
        "  - fieldsOfStudy\n",
        "  - authors \n",
        "\n",
        "- Offset: Número que começa a puxar a partir da ordem dele a lista de papers. (0 seria o primeiro)\n",
        "\n",
        "- Limite: Número de papers a ser retornados (Máx. 10.000)\n",
        "\n",
        "**Obs:** A api do SemanticScholar disponibiliza 100 query's a cada 5 min, no qual apenas retorna no máx. 100 resutados (limite). Assim a cada 5 min, é possível puxar 10.000 papers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF-CJR6nVaZV"
      },
      "source": [
        "#@title Classe para pesquisa no SemanticScholar\n",
        "import IPython\n",
        "from google.colab import output\n",
        "import pandas as pd\n",
        "\n",
        "class Search():\n",
        "  def __init__(self):\n",
        "    self.data = \"\"\n",
        "    self.data_0 = \"\"\n",
        "\n",
        "    self._start()\n",
        "  \n",
        "  def _start(self):\n",
        "\n",
        "    output.register_callback('notebook.searching', self._searching)\n",
        "    output.register_callback('notebook.AddListItem', self._add_list_item)\n",
        "    output.register_callback('notebook.mergeData', self._merge_data)\n",
        "    output.register_callback('notebook.error', self._error)\n",
        "\n",
        "    display(IPython.display.HTML('''\n",
        "        <label for=\"query\">Buscar: </label>\n",
        "        <input type=\"text\" id=\"query\" value=\"Machine Learning+Deep Learning\" style=\"width: 400px;\"/>\n",
        "        <br/>\n",
        "        <br/>\n",
        "        \n",
        "        <label for=\"fields\">Fields: </label>\n",
        "        <input type=\"text\" id=\"fields\" value=\"title,abstract,isOpenAccess,fieldsOfStudy\" style=\"width: 400px;\"/>\n",
        "        <br/>\n",
        "        <br/>\n",
        " \n",
        "        <label for=\"limit\">Limite: </label>\n",
        "        <input type=\"text\" id=\"limit\" value=\"10\" style=\"width: 50px;\"/><br/>\n",
        "        <br/>\n",
        "\n",
        "        <label for=\"limit\">Offset: </label>\n",
        "        <input type=\"text\" id=\"offset\" value=\"0\" style=\"width: 50px;\"/><br/>\n",
        "        <br/>\n",
        "\n",
        "        <button id='button'>Pesquisar</button>\n",
        "        <br/>\n",
        "        <br/>\n",
        "        <script>\n",
        "          document.querySelector('#button').onclick = async () => {\n",
        "\n",
        "            var search = document.getElementById(\"query\").value\n",
        "            var fields = document.getElementById(\"fields\").value\n",
        "            var limit = parseInt(document.getElementById(\"limit\").value)\n",
        "            var offset = parseInt(document.getElementById(\"offset\").value)\n",
        "\n",
        "            google.colab.kernel.invokeFunction('notebook.searching', [], {});\n",
        "\n",
        "            if (limit >100) {\n",
        "              var number = limit\n",
        "              var data = \"\"\n",
        "              var promises = []\n",
        "              var offsetSearch = 0\n",
        "              var rest = 0\n",
        "\n",
        "              for (let index = 0; index < Math.floor(limit/100); index++) {\n",
        "                offsetSearch = 100*(index) + offset + 1*(index!==0)\n",
        "\n",
        "\n",
        "                promises.push(\n",
        "                  fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offsetSearch}&limit=100&fields=${fields}`)\n",
        "    .then(res=> {return(res.json())})\n",
        "    .then(res=> {return(res)})\n",
        "                )\n",
        "              }\n",
        "              \n",
        "              if (limit%100 !== 0) { \n",
        "                rest= limit%100\n",
        "                offsetSearch = offsetSearch+100\n",
        "                \n",
        "                console.log(rest)\n",
        "                console.log(offsetSearch)\n",
        "\n",
        "                promises.push(\n",
        "                fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offsetSearch}&limit=${rest}&fields=${fields}`)\n",
        "    .then(res=> {return(res.json())})\n",
        "    .then(res=> {return(res)})\n",
        "                )}\n",
        "\n",
        "              await Promise.all(promises).then(data=>{\n",
        "                google.colab.kernel.invokeFunction('notebook.mergeData', [data], {})\n",
        "              })\n",
        "              .catch(err=> { return (google.colab.kernel.invokeFunction('notebook.error', [err], {})) })\n",
        "\n",
        "            } else {\n",
        "            await fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offset}&limit=${limit}&fields=${fields}`)\n",
        "    .then(res=> {return(res.json())})\n",
        "    .then(res=> {\n",
        "      return(google.colab.kernel.invokeFunction('notebook.AddListItem', [res], {}))})\n",
        "    .catch(err=> { return (\n",
        "      google.colab.kernel.invokeFunction('notebook.error', [err], {})) })\n",
        "            }\n",
        "      \n",
        "     // .catch(err=>{\n",
        "    //   google.colab.kernel.invokeFunction('notebook._error', [], {});\n",
        "    //   })\n",
        "\n",
        "\n",
        "          };\n",
        "        </script>\n",
        "        '''))\n",
        "    \n",
        "\n",
        "  def _error(self,value):\n",
        "    try:\n",
        "      print(\"ERRO na API SemanticScholar:\")\n",
        "      print(value)\n",
        "    except:\n",
        "      pass \n",
        "\n",
        "  def _searching(self):\n",
        "    with output.use_tags('some_outputs'):\n",
        "      print(\"\\n\\nPesquisando...\")\n",
        "      sys.stdout.flush();\n",
        "\n",
        "  def _merge_data(self, data):\n",
        "    output.clear(output_tags='some_outputs')\n",
        "    print(f\"Achou {data[0]['total']} papers.\\n\")\n",
        "    self.data_0 = data\n",
        "\n",
        "    self.data = pd.DataFrame(data[0]['data'])\n",
        "\n",
        "    try:\n",
        "      for x in data[1:len(data)]:\n",
        "        try:\n",
        "          self.merge(pd.DataFrame(x['data']))\n",
        "        except:\n",
        "          self._error(x)\n",
        "    except:\n",
        "      pass \n",
        "\n",
        "\n",
        "    print(f\"Api devolveu >> {self.data.shape[0]} papers\\n\" )\n",
        "    print(self.data.head())\n",
        "\n",
        "\n",
        "  def merge(self, data):\n",
        "    self.data = pd.concat([self.data, data], ignore_index=True ) \n",
        "\n",
        "  def _add_list_item(self, value):\n",
        "    output.clear(output_tags='some_outputs')\n",
        "    print(f\"Achou {value['total']} papers.\\n\")\n",
        "    print(f\"Api devolveu >> {self.data.shape[0]} papers\\n\" )\n",
        "\n",
        "    self.data = pd.DataFrame(value['data'])\n",
        "    \n",
        "    print(self.data.head())\n",
        "\n"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCrYFOThaOR_"
      },
      "source": [
        "Resultados = Search()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zotFl5-ficaO"
      },
      "source": [
        "# Os dados ficam na variável data, no qual é uma tabela do tipo pandas\n",
        "print(Resultados.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCZf9v2yzskK"
      },
      "source": [
        "Resultados_2 = Search()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8G0F7fEFz9f"
      },
      "source": [
        "print(Resultados_2.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj227EcQz1e7"
      },
      "source": [
        "# Disponibiliza uma função merge para concatenar resultados de outras pesquisas\n",
        "Resultados_2.merge(Resultados.data)\n",
        "\n",
        "print(Resultados_2.data)\n",
        "\n",
        "Resultados_2.data.drop_duplicates(\"paperId\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}