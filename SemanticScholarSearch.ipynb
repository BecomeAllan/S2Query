{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemanticScholarSearch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('Deep-Learning': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "427b934c767a8cb2fbf72f7171fa98f18e655eb7e42e01e1f23dd3cf5c2b0152"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BecomeAllan/S2Search/blob/main/SemanticScholarSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S5xfBIUWDWZ"
      },
      "source": [
        "# Consumindo a API do SemanticScholar\n",
        "\n",
        "A seguir, tem uma classe chamada `Search()`, que ao instanciar-la em uma variável é possível fazer pesquisas sobre papers utilizando a api do SemanticScholar, dentre os parâmetros temos:\n",
        "\n",
        "- Buscar: Pesquisas sobre tópicos onde adicionar tópicos utiliza-se + (mais) e remover tópicos usamos - (menos)\n",
        "\n",
        "  ex. \"Machine+Medicine\"\n",
        "\n",
        "- Fields: O que será retornado como dados. Para utilizar, escolha dentre as opções sem utilizar espaço e separadas de virgulas:\n",
        "  - (str): externalIds\n",
        "  - (str): url\n",
        "  - (str): title\n",
        "  - (str): abstract\n",
        "  - (str): venue \n",
        "  - (str): year \n",
        "  - (str): referenceCount\n",
        "  - (str): citationCount\n",
        "  - (str): influentialCitationCount\n",
        "  - (str): isOpenAccess\n",
        "  - list (str): fieldsOfStudy\n",
        "  - list (str): authors \n",
        "\n",
        "  ex. \"title,abstract,isOpenAccess,fieldsOfStudy\"\n",
        "\n",
        "- Offset: Número que começa a puxar a partir da ordem dele a lista de papers. (0 seria o primeiro)\n",
        "\n",
        "- Limite: Número de papers a ser retornados (Máx. 10.000)\n",
        "\n",
        "**Obs:** A api do SemanticScholar disponibiliza 100 query's a cada 5 min, no qual apenas retorna no máx. 100 resutados (limite). Assim a cada 5 min, é possível puxar 10.000 papers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF-CJR6nVaZV",
        "cellView": "form"
      },
      "source": [
        "#@title Classe para pesquisa no SemanticScholar\n",
        "import IPython\n",
        "from google.colab import output\n",
        "import pandas as pd\n",
        "\n",
        "class Search():\n",
        "  def __init__(self, **kwargs):\n",
        "    self.data = \"\"\n",
        "    self.data_0 = \"\"\n",
        "\n",
        "    self.search = kwargs.get('search', None)\n",
        "    self.fields = kwargs.get('fields', None)\n",
        "    self.limit = kwargs.get('limit', None)\n",
        "    self.offset = kwargs.get('offset', None)\n",
        "\n",
        "    if self.search == None and self.fields == None and self.limit == None and self.offset == None:\n",
        "      self._start(False)\n",
        "    else:\n",
        "      self._start(True)\n",
        "  \n",
        "  def _start(self, *args):\n",
        "\n",
        "    output.register_callback('notebook.searching', self._searching)\n",
        "    output.register_callback('notebook.AddListItem', self._add_list_item)\n",
        "    output.register_callback('notebook.mergeData', self._merge_data)\n",
        "    output.register_callback('notebook.error', self._error)\n",
        "\n",
        "\n",
        "    boxs = ''' \n",
        "        <label for=\"query\">Buscar: </label>\n",
        "        <input type=\"text\" id=\"query\" value=\"Machine Learning+Deep Learning\" style=\"width: 400px;\"/>\n",
        "        <br/>\n",
        "        <br/>\n",
        "        \n",
        "        <label for=\"fields\">Fields: </label>\n",
        "        <input type=\"text\" id=\"fields\" value=\"title,abstract,isOpenAccess,fieldsOfStudy\" style=\"width: 400px;\"/>\n",
        "        <br/>\n",
        "        <br/>\n",
        " \n",
        "        <label for=\"limit\">Limite: </label>\n",
        "        <input type=\"text\" id=\"limit\" value=\"10\" style=\"width: 50px;\"/><br/>\n",
        "        <br/>\n",
        "\n",
        "        <label for=\"limit\">Offset: </label>\n",
        "        <input type=\"text\" id=\"offset\" value=\"0\" style=\"width: 50px;\"/><br/>\n",
        "        <br/>\n",
        "\n",
        "        <button id='button'>Pesquisar</button>\n",
        "        <br/>\n",
        "        <br/>\n",
        "           '''\n",
        "\n",
        "    button = ''' document.querySelector('#button').onclick = async () => ''' # {}\n",
        "\n",
        "    search_query = '''\n",
        "            var search = document.getElementById(\"query\").value\n",
        "            var fields = document.getElementById(\"fields\").value\n",
        "            var limit = parseInt(document.getElementById(\"limit\").value)\n",
        "            var offset = parseInt(document.getElementById(\"offset\").value)\n",
        "                  '''\n",
        "    search_params = '''\n",
        "            var search = \"{search}\"\n",
        "            var fields = \"{fields}\"\n",
        "            var limit = parseInt({limit})\n",
        "            var offset = parseInt({offset})\n",
        "                  '''\n",
        "    engine = '''\n",
        "            google.colab.kernel.invokeFunction('notebook.searching', [], {});\n",
        "\n",
        "            if (limit >100) {\n",
        "              var number = limit\n",
        "              var data = \"\"\n",
        "              var promises = []\n",
        "              var offsetSearch = 0\n",
        "              var rest = 0\n",
        "\n",
        "              for (let index = 0; index < Math.floor(limit/100); index++) {\n",
        "                offsetSearch = 100*(index) + offset + 1*(index!==0)\n",
        "\n",
        "\n",
        "                promises.push(\n",
        "                  fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offsetSearch}&limit=100&fields=${fields}`)\n",
        "    .then(res=> {return(res.json())})\n",
        "    .then(res=> {return(res)})\n",
        "                )\n",
        "              }\n",
        "              \n",
        "              if (limit%100 !== 0) { \n",
        "                rest= limit%100\n",
        "                offsetSearch = offsetSearch+100\n",
        "                \n",
        "                console.log(rest)\n",
        "                console.log(offsetSearch)\n",
        "\n",
        "                promises.push(\n",
        "                fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offsetSearch}&limit=${rest}&fields=${fields}`)\n",
        "    .then(res=> {return(res.json())})\n",
        "    .then(res=> {return(res)})\n",
        "                )}\n",
        "\n",
        "              await Promise.all(promises).then(data=>{\n",
        "                google.colab.kernel.invokeFunction('notebook.mergeData', [data], {})\n",
        "              })\n",
        "              .catch(err=> { return (google.colab.kernel.invokeFunction('notebook.error', [err], {})) })\n",
        "\n",
        "            } else {\n",
        "\n",
        "            await fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offset}&limit=${limit}&fields=${fields}`)\n",
        "    .then(res=> {return(res.json())})\n",
        "    .then(res=> {\n",
        "      console.log(res)\n",
        "      console.log(\"AQUIII\")\n",
        "      return(google.colab.kernel.invokeFunction('notebook.AddListItem', [res], {}))})\n",
        "    .catch(err=> { return (\n",
        "      google.colab.kernel.invokeFunction('notebook.error', [err], {})) })\n",
        "            }\n",
        "                  '''\n",
        "\n",
        "    asyncfun = \"async function asyncfun()\"\n",
        "\n",
        "    if args[0]:\n",
        "\n",
        "      main_app =  \"<script>\" + search_params.format(search=self.search, fields=self.fields, limit=self.limit, offset=self.offset) + asyncfun + \"{\" + engine + \"}\" + \"asyncfun()\" + \"</script>\"\n",
        "\n",
        "      display(IPython.display.HTML(main_app))\n",
        "      \n",
        "    else:\n",
        "      main_app = boxs + \"<script>\" + button + \"{\" + search_query + engine + \"}\" + \"</script>\"\n",
        "      \n",
        "      display(IPython.display.HTML(main_app))\n",
        "\n",
        "    \n",
        "\n",
        "  def _error(self,value):\n",
        "    try:\n",
        "      print(\"ERRO na API SemanticScholar:\\n\")\n",
        "      print(value)\n",
        "    except:\n",
        "      pass \n",
        "\n",
        "  def _searching(self):\n",
        "    with output.use_tags('some_outputs'):\n",
        "      print(\"\\n\\nPesquisando...\")\n",
        "      sys.stdout.flush();\n",
        "\n",
        "  def _merge_data(self, data):\n",
        "    output.clear(output_tags='some_outputs')\n",
        "    print(f\"Achou {data[0]['total']} papers.\\n\")\n",
        "    self.data_0 = data\n",
        "\n",
        "    self.data = pd.DataFrame(data[0]['data'])\n",
        "\n",
        "    try:\n",
        "      for x in data[1:len(data)]:\n",
        "        try:\n",
        "          self.merge(pd.DataFrame(x['data']))\n",
        "        except:\n",
        "          self._error(x)\n",
        "    except:\n",
        "      pass \n",
        "\n",
        "    print(f\"\\nApi devolveu >> {self.data.shape[0]} papers\\n\" )\n",
        "    print(self.data.head())\n",
        "\n",
        "\n",
        "  def merge(self, data):\n",
        "    self.data = pd.concat([self.data, data], ignore_index=True ) \n",
        "\n",
        "  def _add_list_item(self, value):\n",
        "    output.clear(output_tags='some_outputs')\n",
        "\n",
        "    print(f\"Achou {value['total']} papers.\\n\")\n",
        "\n",
        "    self.data = pd.DataFrame(value['data'])\n",
        "\n",
        "    print(f\"Api devolveu >> {self.data.shape[0]} papers\\n\" )\n",
        "    \n",
        "    print(self.data.head())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At8ZsoI1ZfbI"
      },
      "source": [
        "# Consumir a classe `Search()`\n",
        "\n",
        "A duas formas de pesquisar utilizando `Search()`:\n",
        "\n",
        "1. A primeira é utilizando parâmetros na propria classe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2dKxHXrkHvf"
      },
      "source": [
        "# \"Decision making\" AND \"optimization\" AND \"artificial intelligence\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCrYFOThaOR_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "237cc7a0-1543-4122-b68d-8c5d176a7725"
      },
      "source": [
        "Resultados = Search(search = \"Machine Learning+Deep Learning\" , fields = \"title,abstract,citationCount,isOpenAccess,fieldsOfStudy\", limit = \"2000\", offset = \"0\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<script>\n",
              "            var search = \"Machine Learning\"\n",
              "            var fields = \"title,abstract,citationCount,isOpenAccess,fieldsOfStudy\"\n",
              "            var limit = parseInt(2000)\n",
              "            var offset = parseInt(0)\n",
              "                  async function asyncfun(){\n",
              "            google.colab.kernel.invokeFunction('notebook.searching', [], {});\n",
              "\n",
              "            if (limit >100) {\n",
              "              var number = limit\n",
              "              var data = \"\"\n",
              "              var promises = []\n",
              "              var offsetSearch = 0\n",
              "              var rest = 0\n",
              "\n",
              "              for (let index = 0; index < Math.floor(limit/100); index++) {\n",
              "                offsetSearch = 100*(index) + offset + 1*(index!==0)\n",
              "\n",
              "\n",
              "                promises.push(\n",
              "                  fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offsetSearch}&limit=100&fields=${fields}`)\n",
              "    .then(res=> {return(res.json())})\n",
              "    .then(res=> {return(res)})\n",
              "                )\n",
              "              }\n",
              "              \n",
              "              if (limit%100 !== 0) { \n",
              "                rest= limit%100\n",
              "                offsetSearch = offsetSearch+100\n",
              "                \n",
              "                console.log(rest)\n",
              "                console.log(offsetSearch)\n",
              "\n",
              "                promises.push(\n",
              "                fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offsetSearch}&limit=${rest}&fields=${fields}`)\n",
              "    .then(res=> {return(res.json())})\n",
              "    .then(res=> {return(res)})\n",
              "                )}\n",
              "\n",
              "              await Promise.all(promises).then(data=>{\n",
              "                google.colab.kernel.invokeFunction('notebook.mergeData', [data], {})\n",
              "              })\n",
              "              .catch(err=> { return (google.colab.kernel.invokeFunction('notebook.error', [err], {})) })\n",
              "\n",
              "            } else {\n",
              "\n",
              "            await fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offset}&limit=${limit}&fields=${fields}`)\n",
              "    .then(res=> {return(res.json())})\n",
              "    .then(res=> {\n",
              "      console.log(res)\n",
              "      console.log(\"AQUIII\")\n",
              "      return(google.colab.kernel.invokeFunction('notebook.AddListItem', [res], {}))})\n",
              "    .catch(err=> { return (\n",
              "      google.colab.kernel.invokeFunction('notebook.error', [err], {})) })\n",
              "            }\n",
              "                  }asyncfun()</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Achou 5240039 papers.\n",
            "\n",
            "ERRO na API SemanticScholar:\n",
            "\n",
            "{'message': 'Internal Server Error'}\n",
            "ERRO na API SemanticScholar:\n",
            "\n",
            "{'message': 'Internal Server Error'}\n",
            "ERRO na API SemanticScholar:\n",
            "\n",
            "{'message': 'Internal Server Error'}\n",
            "ERRO na API SemanticScholar:\n",
            "\n",
            "{'message': 'Internal Server Error'}\n",
            "ERRO na API SemanticScholar:\n",
            "\n",
            "{'message': 'Internal Server Error'}\n",
            "ERRO na API SemanticScholar:\n",
            "\n",
            "{'message': 'Internal Server Error'}\n",
            "ERRO na API SemanticScholar:\n",
            "\n",
            "{'message': 'Internal Server Error'}\n",
            "ERRO na API SemanticScholar:\n",
            "\n",
            "{'message': 'Internal Server Error'}\n",
            "ERRO na API SemanticScholar:\n",
            "\n",
            "{'message': 'Internal Server Error'}\n",
            "\n",
            "Api devolveu >> 1009 papers\n",
            "\n",
            "                                    paperId  ...                    fieldsOfStudy\n",
            "0  46200b99c40e8586c8a0f588488ab6414119fb28  ...               [Computer Science]\n",
            "1  9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d  ...               [Computer Science]\n",
            "2  b42b1bfdc262bf99e9484e2e9df94df216b96374  ...               [Computer Science]\n",
            "3  25badc676197a70aaf9911865eb03469e402ba57  ...               [Computer Science]\n",
            "4  f9c602cc436a9ea2f9e7db48c77d924e09ce3c32  ...  [Computer Science, Mathematics]\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zotFl5-ficaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "fa1bc71f-f243-4a1f-a967-172e638aa4df"
      },
      "source": [
        "# Os dados ficam na variável data, no qual é uma tabela do tipo pandas\n",
        "print(Resultados.data.columns)\n",
        "print(Resultados.data.sort_values(\"citationCount\", ascending = False ).head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paperId</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>citationCount</th>\n",
              "      <th>isOpenAccess</th>\n",
              "      <th>fieldsOfStudy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>34f25a8704614163c4095b3ee2fc969b60de4698</td>\n",
              "      <td>Dropout: a simple way to prevent neural networ...</td>\n",
              "      <td>Deep neural nets with a large number of parame...</td>\n",
              "      <td>24510</td>\n",
              "      <td>False</td>\n",
              "      <td>[Computer Science]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>a4cec122a08216fe8a3bc19b22e78fbaea096256</td>\n",
              "      <td>Deep Learning</td>\n",
              "      <td>Machine-learning technology powers many aspect...</td>\n",
              "      <td>19531</td>\n",
              "      <td>False</td>\n",
              "      <td>[Medicine, Computer Science]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963</th>\n",
              "      <td>5d90f06bb70a0a3dced62413346235c02b1aa086</td>\n",
              "      <td>Learning Multiple Layers of Features from Tiny...</td>\n",
              "      <td>Groups at MIT and NYU have collected a dataset...</td>\n",
              "      <td>13232</td>\n",
              "      <td>False</td>\n",
              "      <td>[Computer Science]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>6bdb186ec4726e00a8051119636d4df3b94043b5</td>\n",
              "      <td>Caffe: Convolutional Architecture for Fast Fea...</td>\n",
              "      <td>Caffe provides multimedia scientists and pract...</td>\n",
              "      <td>13101</td>\n",
              "      <td>False</td>\n",
              "      <td>[Computer Science]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>46200b99c40e8586c8a0f588488ab6414119fb28</td>\n",
              "      <td>TensorFlow: A system for large-scale machine l...</td>\n",
              "      <td>TensorFlow is a machine learning system that o...</td>\n",
              "      <td>10598</td>\n",
              "      <td>False</td>\n",
              "      <td>[Computer Science]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      paperId  ...                 fieldsOfStudy\n",
              "754  34f25a8704614163c4095b3ee2fc969b60de4698  ...            [Computer Science]\n",
              "17   a4cec122a08216fe8a3bc19b22e78fbaea096256  ...  [Medicine, Computer Science]\n",
              "963  5d90f06bb70a0a3dced62413346235c02b1aa086  ...            [Computer Science]\n",
              "988  6bdb186ec4726e00a8051119636d4df3b94043b5  ...            [Computer Science]\n",
              "14   46200b99c40e8586c8a0f588488ab6414119fb28  ...            [Computer Science]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwfe0ZCyZ8YD"
      },
      "source": [
        "2. A segunda é atravez da api de busca, searchBox, no qual é possivel colocar os campos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCZf9v2yzskK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "fba90541-642b-4c5d-ed98-323245132691"
      },
      "source": [
        "Resultados_2 = Search()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              " \n",
              "        <label for=\"query\">Buscar: </label>\n",
              "        <input type=\"text\" id=\"query\" value=\"Machine Learning+Deep Learning\" style=\"width: 400px;\"/>\n",
              "        <br/>\n",
              "        <br/>\n",
              "        \n",
              "        <label for=\"fields\">Fields: </label>\n",
              "        <input type=\"text\" id=\"fields\" value=\"title,abstract,isOpenAccess,fieldsOfStudy\" style=\"width: 400px;\"/>\n",
              "        <br/>\n",
              "        <br/>\n",
              " \n",
              "        <label for=\"limit\">Limite: </label>\n",
              "        <input type=\"text\" id=\"limit\" value=\"10\" style=\"width: 50px;\"/><br/>\n",
              "        <br/>\n",
              "\n",
              "        <label for=\"limit\">Offset: </label>\n",
              "        <input type=\"text\" id=\"offset\" value=\"0\" style=\"width: 50px;\"/><br/>\n",
              "        <br/>\n",
              "\n",
              "        <button id='button'>Pesquisar</button>\n",
              "        <br/>\n",
              "        <br/>\n",
              "           <script> document.querySelector('#button').onclick = async () => {\n",
              "            var search = document.getElementById(\"query\").value\n",
              "            var fields = document.getElementById(\"fields\").value\n",
              "            var limit = parseInt(document.getElementById(\"limit\").value)\n",
              "            var offset = parseInt(document.getElementById(\"offset\").value)\n",
              "                  \n",
              "            google.colab.kernel.invokeFunction('notebook.searching', [], {});\n",
              "\n",
              "            if (limit >100) {\n",
              "              var number = limit\n",
              "              var data = \"\"\n",
              "              var promises = []\n",
              "              var offsetSearch = 0\n",
              "              var rest = 0\n",
              "\n",
              "              for (let index = 0; index < Math.floor(limit/100); index++) {\n",
              "                offsetSearch = 100*(index) + offset + 1*(index!==0)\n",
              "\n",
              "\n",
              "                promises.push(\n",
              "                  fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offsetSearch}&limit=100&fields=${fields}`)\n",
              "    .then(res=> {return(res.json())})\n",
              "    .then(res=> {return(res)})\n",
              "                )\n",
              "              }\n",
              "              \n",
              "              if (limit%100 !== 0) { \n",
              "                rest= limit%100\n",
              "                offsetSearch = offsetSearch+100\n",
              "                \n",
              "                console.log(rest)\n",
              "                console.log(offsetSearch)\n",
              "\n",
              "                promises.push(\n",
              "                fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offsetSearch}&limit=${rest}&fields=${fields}`)\n",
              "    .then(res=> {return(res.json())})\n",
              "    .then(res=> {return(res)})\n",
              "                )}\n",
              "\n",
              "              await Promise.all(promises).then(data=>{\n",
              "                google.colab.kernel.invokeFunction('notebook.mergeData', [data], {})\n",
              "              })\n",
              "              .catch(err=> { return (google.colab.kernel.invokeFunction('notebook.error', [err], {})) })\n",
              "\n",
              "            } else {\n",
              "\n",
              "            await fetch(`https://api.semanticscholar.org/graph/v1/paper/search?query=${search}&offset=${offset}&limit=${limit}&fields=${fields}`)\n",
              "    .then(res=> {return(res.json())})\n",
              "    .then(res=> {\n",
              "      console.log(res)\n",
              "      console.log(\"AQUIII\")\n",
              "      return(google.colab.kernel.invokeFunction('notebook.AddListItem', [res], {}))})\n",
              "    .catch(err=> { return (\n",
              "      google.colab.kernel.invokeFunction('notebook.error', [err], {})) })\n",
              "            }\n",
              "                  }</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Achou 652200 papers.\n",
            "\n",
            "Api devolveu >> 10 papers\n",
            "\n",
            "                                    paperId  ...       fieldsOfStudy\n",
            "0  846ff7afb7670d62f88b4a8cc99d306ffb81b075  ...          [Medicine]\n",
            "1  5dc53e50148b01fe8b9536eb79fa6b1dce924174  ...          [Medicine]\n",
            "2  7cc2e148d27a7508dd23c4e35eb63cc9b3e6a58f  ...  [Computer Science]\n",
            "3  59444b096f7c8a561d540102e8b5bfb189edabc6  ...                None\n",
            "4  eee313380ccb45807ea0afa3c1df86f6b48b8867  ...  [Computer Science]\n",
            "\n",
            "[5 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8G0F7fEFz9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50abc23f-9658-4a53-ebbc-4f9c8065a050"
      },
      "source": [
        "print(Resultados_2.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                    paperId  ...       fieldsOfStudy\n",
            "0  846ff7afb7670d62f88b4a8cc99d306ffb81b075  ...          [Medicine]\n",
            "1  5dc53e50148b01fe8b9536eb79fa6b1dce924174  ...          [Medicine]\n",
            "2  7cc2e148d27a7508dd23c4e35eb63cc9b3e6a58f  ...  [Computer Science]\n",
            "3  59444b096f7c8a561d540102e8b5bfb189edabc6  ...                None\n",
            "4  eee313380ccb45807ea0afa3c1df86f6b48b8867  ...  [Computer Science]\n",
            "5  46479bbea7749cb2db35b139206039531327053c  ...  [Computer Science]\n",
            "6  b69fe5a837277ddbea5215d6bacd3a902e9d11ce  ...          [Medicine]\n",
            "7  b0bf64ccbd651e8c7bc141d8aabaecff562e93a1  ...  [Computer Science]\n",
            "8  042ab08ec6782cf217f13175162bfd48f7350114  ...  [Computer Science]\n",
            "9  03e7832982986159400a8eeab148487ffcfabe56  ...  [Computer Science]\n",
            "\n",
            "[10 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNrq2PcNtb-f"
      },
      "source": [
        "\n",
        "# **SearchWeb()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_OkAhJHt3tS"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "# import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import ast\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "from time import sleep, time\n",
        "\n",
        "\n",
        "def timer(fun):\n",
        "  def warper(*args,**kwargs):\n",
        "    start = time()\n",
        "    d = fun(*args,**kwargs)\n",
        "    end = time()\n",
        "    print(f\"[{fun.__name__}]>> Demorou {round(end-start,2)}s\")\n",
        "    return d\n",
        "  return warper\n",
        "\n",
        "\n",
        "\n",
        "class SearchWeb():\n",
        "  def __init__(self, search=\"Machine Learning+Deep Learning\", poolCPU = 4, sleeptry=5, save = False, **kwargs):\n",
        "     \n",
        "    self.sleeptry = sleeptry\n",
        "    self.poolCPU = poolCPU\n",
        "    self.saveName = kwargs.get('Savename', \"Data\")\n",
        "\n",
        "    self.badcall = []\n",
        "    self._start = True\n",
        "\n",
        "    self.saveFile = save\n",
        "    self._search = search\n",
        "    self._sort = kwargs.get('sort', \"relevance\")\n",
        "    self._authors = kwargs.get('authors', [])\n",
        "    self._coAuthors = kwargs.get('coAuthors', [])\n",
        "    self._venues = kwargs.get('venues', ['PloS one', 'AAAI', 'Scientific reports', 'IEEE Access', 'ArXiv', 'Expert Syst. Appl.', 'ICML', 'Neurocomputing', 'Sensors', 'Remote. Sens.'])\n",
        "    self._yearFilter = kwargs.get('yearFilter', None) # {\"min\": 2008,\"max\": 2021}\n",
        "    self._requireViewablePdf = kwargs.get('requireViewablePdf', False)\n",
        "    self._publicationTypes = kwargs.get('publicationTypes', [\"ClinicalTrial\", \"CaseReport\", \"Editorial\",\"Study\",\"Book\",\"News\",\"Review\",\"Conference\",\"LettersAndComments\",\"JournalArticle\"])\n",
        "    self._fieldsOfStudy = kwargs.get('fieldsOfStudy', [\"biology\",\"art\",\"business\",\"computer-science\",\"chemistry\",\"economics\",\"engineering\",\"environmental-science\",\"geography\",\"geology\",\"history\",\"materials-science\",\"mathematics\",\"medicine\",\"philosophy\",\"physics\",\"political-science\",\"psychology\",\"sociology\"])\n",
        "    self._useFallbackRankerService = kwargs.get('useFallbackRankerService', False)\n",
        "    self._useFallbackSearchCluster = kwargs.get('useFallbackSearchCluster', False)\n",
        "    self._hydrateWithDdb = kwargs.get('hydrateWithDdb', True)\n",
        "    self._includeTldrs = kwargs.get('includeTldrs', True)\n",
        "    self._performTitleMatch = kwargs.get('performTitleMatch', True)\n",
        "    self._includeBadges = kwargs.get('includeBadges', True)\n",
        "    self._tldrModelVersion = kwargs.get('tldrModelVersion', 'v2.0.0')\n",
        "    self._getQuerySuggestions = kwargs.get('getQuerySuggestions', False)\n",
        "\n",
        "\n",
        "    self.post = {\n",
        "    \"page\": 1, \n",
        "    \"pageSize\": 10,\n",
        "    \"queryString\": self._search,\n",
        "    \"sort\": self._sort,\n",
        "    \"authors\": self._authors,\n",
        "    \"coAuthors\": self._coAuthors,\n",
        "    \"venues\": self._venues,\n",
        "    \"yearFilter\": self._yearFilter,\n",
        "    \"requireViewablePdf\": self._requireViewablePdf,\n",
        "    \"publicationTypes\": self._publicationTypes,\n",
        "    \"externalContentTypes\": [],\n",
        "    \"fieldsOfStudy\": self._fieldsOfStudy,\n",
        "    \"useFallbackRankerService\": self._useFallbackRankerService,\n",
        "    \"useFallbackSearchCluster\": self._useFallbackSearchCluster,\n",
        "    \"hydrateWithDdb\": self._hydrateWithDdb,\n",
        "    \"includeTldrs\": self._includeTldrs,\n",
        "    \"performTitleMatch\": self._performTitleMatch,\n",
        "    \"includeBadges\": self._includeBadges,\n",
        "    \"tldrModelVersion\": \"v2.0.0\",\n",
        "    \"getQuerySuggestions\": self._getQuerySuggestions,\n",
        "    }\n",
        "\n",
        "  \n",
        "  \n",
        "  def _paperExtract(self, data):\n",
        "    p = {\n",
        "        \"authors\": [author[0]['name'] for author in data.get('authors',[{'name':None},None])],\n",
        "        \"id\": data.get('id',None),\n",
        "        \"socialLinks\": data.get('socialLinks',None),\n",
        "        \"title\": data.get('title',{'text':None})['text'],\n",
        "        \"paperAbstract\": data.get('paperAbstract',{'text':None})['text'],\n",
        "        \"year\": data.get('year',{'text':None})['text'],\n",
        "        \"venue\": data.get('venue',{'text':None})['text'],\n",
        "        \"citationContexts\":data.get('citationContexts',None),\n",
        "        \"citationStats\": data.get('citationStats',None),\n",
        "        \"sources\":data.get('sources',None),\n",
        "        \"externalContentStats\":data.get('externalContentStats',None),\n",
        "        \"journal\":data.get('journal',None),\n",
        "        \"presentationUrls\":data.get('presentationUrls',None),\n",
        "        \"links\": data.get('links',None),\n",
        "        \"primaryPaperLink\": data.get('primaryPaperLink',None),\n",
        "        \"alternatePaperLinks\": data.get('alternatePaperLinks',None),\n",
        "        \"entities\": [author['name'] for author in data.get('entities',[{'name':None}])],\n",
        "        \"entityRelations\": data.get('entityRelations',None),\n",
        "        \"blogs\":data.get('blogs',None),\n",
        "        \"videos\":data.get('videos',None),\n",
        "        \"githubReferences\": data.get('githubReferences',None),\n",
        "        \"scorecardStats\": data.get('scorecardStats',None),\n",
        "        \"fieldsOfStudy\":data.get('fieldsOfStudy',None),\n",
        "        \"pubDate\":data.get('pubDate',None),\n",
        "        \"pubUpdateDate\":data.get('pubUpdateDate',None),\n",
        "        \"badges\":data.get('badges',None),\n",
        "        \"tldr\":data.get('tldr',None)\n",
        "        }\n",
        "    return p\n",
        "\n",
        "  def _query(self, page):\n",
        "    url = \"https://www.semanticscholar.org/api/1/search\"\n",
        "    post = self.post.copy()\n",
        "    post[\"page\"] = page\n",
        "    try:\n",
        "      res = requests.post(url, json=post, timeout=15)\n",
        "      res.encoding = 'utf-8'\n",
        "      return [res, page]\n",
        "    except:\n",
        "      return [{\"status_code\": 400}, page ]\n",
        "      \n",
        "\n",
        "  def _json(self, res):\n",
        "    # print(res.text)\n",
        "    return json.loads(res.text).copy()\n",
        "\n",
        "    # c['querySuggestions']\n",
        "    # c['totalPages']\n",
        "    # c['totalResults']\n",
        "  def save(self, name, data):\n",
        "    try:\n",
        "      with open(f'./{name}.json', 'w',encoding='UTF-8') as fp:\n",
        "          json.dump(data, fp)\n",
        "    except:\n",
        "      print(\"[Save]>> Error to save the data.\")\n",
        "  \n",
        "  def load_json(self, path):\n",
        "    try:\n",
        "      with open(f'{path}', 'r', encoding='UTF-8') as fp:\n",
        "          return json.load(fp)\n",
        "    except:\n",
        "      print(\"[load_json]>> Error to load json file.\")\n",
        "    \n",
        "  def _startFile(self, find):\n",
        "    jsonFile = Path(f\"./{self.saveName}.json\")\n",
        "    textFile = Path(f\"./{self.saveName}.text\")\n",
        "    \n",
        "    if jsonFile.is_file():\n",
        "      if find:\n",
        "        try:\n",
        "          print(f\"[_startFile] >> Loading ./{self.saveName}.json\")\n",
        "          with open(f'./{self.saveName}.json', 'r',encoding='UTF-8') as f:\n",
        "            data = json.load(f)\n",
        "          print(f\"[Create] >> Creating a ./{self.saveName}.text file to save data.\")\n",
        "          with open(f'./{self.saveName}.text', 'w',encoding='UTF-8') as fp:\n",
        "            fp.write(\"{\\\"Results\\\": [\")\n",
        "        \n",
        "        # print(data['Results'])\n",
        "          self._save(data['Results'])\n",
        "        except:\n",
        "          print(f\"[_startFile] >> Fail to load ./{self.saveName}.json\")\n",
        "          try:\n",
        "            # print(f\"[Create] >> Creating a ./{self.saveName}.text file to save data.\")\n",
        "            with open(f'./{self.saveName}.text', 'w', encoding='UTF-8') as fp:\n",
        "              fp.write(\"{\\\"Results\\\": [\")\n",
        "          except:\n",
        "            print(\"[Create] >> Fail\")\n",
        "      else:\n",
        "        return False\n",
        "    else:\n",
        "      try:\n",
        "        print(f\"[Create] >> Creating a ./{self.saveName}.text file to save data.\")\n",
        "        with open(f'./{self.saveName}.text', 'w',encoding='UTF-8') as fp:\n",
        "          fp.write(\"{\\\"Results\\\": [\")\n",
        "      except:\n",
        "        print(\"[Create] >> Fail\")\n",
        "    return True\n",
        "\n",
        "\n",
        "  def _save(self, check_point):\n",
        "    if str(check_point) == '[]' or str(check_point) == '[,]':\n",
        "      return _\n",
        "    else:\n",
        "      text = str(check_point)\n",
        "\n",
        "      text = re.sub('^\\[', '', text)\n",
        "      text = re.sub('\\]$', '', text)\n",
        "\n",
        "      \n",
        "      with open(f'./{self.saveName}.text', 'a', encoding='utf-8') as fp:\n",
        "        fp.write(text)\n",
        "          # json.dump(self.all['Results'], fp)\n",
        "      print(f\"[Save] >> Saving check_point at current directory, ./{self.saveName}.text\")\n",
        "      \n",
        "\n",
        "  def _endFile(self):\n",
        "    # ast.literal_eval(text)\n",
        "    try:\n",
        "      with open(f'./{self.saveName}.text', 'a', encoding='UTF-8') as fp:\n",
        "        fp.write(']}')\n",
        "      \n",
        "      try:\n",
        "        with open(f'./{self.saveName}.text', 'r', encoding='UTF-8') as fp:\n",
        "          text = fp.read()\n",
        "          text_dict = ast.literal_eval(text)\n",
        "        \n",
        "      \n",
        "      # os.rename(f'./{self.saveName}.text', f'./{self.saveName}.json')\n",
        "      # os.remove(f\"./{self.saveName}.text\")\n",
        "      # print(text_dict)\n",
        "        with open(f'./{self.saveName}.json', 'w', encoding='UTF-8') as fp:\n",
        "          json.dump(text_dict, fp)\n",
        "        print(f\"[Close] >> Closed and save in ./{self.saveName}.json file the data.\")\n",
        "      except:\n",
        "        print(f\"[Close] >> Fail to save the data ./{self.saveName}.json file.\")\n",
        "\n",
        "    except:\n",
        "      print('[Close] >> Fail')\n",
        "\n",
        "  \n",
        "\n",
        "  @timer\n",
        "  def _extract(self, pool, data):\n",
        "    try:\n",
        "      # print(\"data\")\n",
        "      # print(data)\n",
        "\n",
        "      # print(\"data['Response'].tolist()\")\n",
        "      # print(data['Response'].tolist())\n",
        "      self.papers_text = pool.map(self._json, data['Response'].tolist())\n",
        "      # print(\"self.papers_text\")\n",
        "      # print(self.papers_text)\n",
        "\n",
        "      if self._start:\n",
        "        print('\\n ---')\n",
        "        print(f\"Total Results: {self.papers_text[0]['totalResults']}\")\n",
        "        print(f\"Total Pages: {self.papers_text[0]['totalPages']}\")\n",
        "        print(f\"Query Suggestions: {self.papers_text[0]['querySuggestions']}\")\n",
        "        print('--- \\n')\n",
        "        self.totalPages = self.papers_text[0]['totalPages']\n",
        "        self.totalResults = self.papers_text[0]['totalResults']\n",
        "        self._start = False\n",
        "\n",
        "      \n",
        "      print(\"[_extract] >> extracting relevant data.\")\n",
        "      check_point= [{\"Page\": {\"N_Page\":page['query']['page'],\n",
        "                                   \"N_Papers\":len(page['results']),\n",
        "                                   \"Papers\": pool.map(self._paperExtract,\n",
        "                                                      page['results'])}} for page in self.papers_text]\n",
        "\n",
        "\n",
        "      # print(check_point)\n",
        "      if self.saveFile:\n",
        "        try:\n",
        "          self._save(check_point)\n",
        "        except:\n",
        "          print(\"_save >> [Fail] to save.\")\n",
        "          print(\"_extract>> [Fail], see .badcall to reextract content.\")\n",
        "          self.badcall.append(self.papers_text)\n",
        "          # print(self.badcall)\n",
        "      else:\n",
        "        self.all[\"Results\"].extend(check_point)\n",
        "\n",
        "\n",
        "    except:\n",
        "      print(\"_extract>> [Fail], see .badcall to reextract content.\")\n",
        "      self.badcall.append(self.papers_text)\n",
        "      # print(self.badcall)\n",
        "    \n",
        "    \n",
        "\n",
        "  # def _data(self, data):\n",
        "  #   if type(self.datasource) == str:\n",
        "  #     self.datasource = data\n",
        "  #   else:\n",
        "  #     self.datasource = pd.concat([self.datasource, data])\n",
        "\n",
        "  @timer\n",
        "  def _runtime(self, pool, pages):\n",
        "    self.totalPages = 0\n",
        "\n",
        "    find = False\n",
        "    \n",
        "    while True:\n",
        "      if self.saveFile:\n",
        "        close = self._startFile(find)\n",
        "      \n",
        "      print('\\n')\n",
        "      print('[_runtime]>> Start searching...')\n",
        "      # print(self.totalPages)\n",
        "      # print(self.totalResults)\n",
        "      # print(self.n)\n",
        "\n",
        "      if self.totalResults < self.n:\n",
        "        print('Entrei aq')\n",
        "        self.n = self.totalResults\n",
        "        pages = list(range(self._page, self.totalPages))\n",
        "      \n",
        "      try:\n",
        "        res = pool.map(self._query, pages)\n",
        "        # print(res)\n",
        "        self.codes = [[x[0], x[1], x[0].status_code] for x in res]\n",
        "        resultData = pd.DataFrame(self.codes, columns=[\"Response\", \"Page\", \"Code\"])\n",
        "        resultData.set_index(\"Page\")\n",
        "        \n",
        "        if resultData.query(\"Code !=200\").size == 0:\n",
        "          # self._data(resultData)\n",
        "          self._extract(pool, resultData.query(\"Code ==200\"))\n",
        "          if self.saveFile:\n",
        "            if close:\n",
        "              self._endFile()\n",
        "              find = True\n",
        "          break\n",
        "        else:\n",
        "          find = False\n",
        "\n",
        "          if resultData.query(\"Code ==200\").size != 0:\n",
        "            self._extract(pool, resultData.query(\"Code ==200\"))\n",
        "            if self.saveFile:\n",
        "              if close:\n",
        "                find = True\n",
        "                self._endFile()\n",
        "              \n",
        "          print(\"Bad call of pages:\")\n",
        "          # self._data(resultData.query(\"Code == 200\"))\n",
        "          # self.datasource.append(resultData.query(\"Code ==200\"))\n",
        "          pages = resultData.query(\"Code !=200\")[\"Page\"].values.tolist()\n",
        "          print(pages)\n",
        "          try:\n",
        "            with open(\"./BadCalls.text\", 'w', encoding='UTF-8') as fp:\n",
        "              fp.write(str(pages))\n",
        "          except:\n",
        "            print(\"Fail to save badcalls\")\n",
        "          print(f\"Tentando de novo daqui a {self.sleeptry/60} min...\")\n",
        "\n",
        "\n",
        "          sleep(self.sleeptry)\n",
        "      except:\n",
        "        pass\n",
        "      print(\"---\")\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    # self._extract(pool, self.datasource)\n",
        "\n",
        "\n",
        "  @timer\n",
        "  def get(self, n = 10, page = 1, pages = []):\n",
        "    self._pages = pages\n",
        "    self.n = n\n",
        "    self._page = page\n",
        "    self.totalResults = 1000000000000000000000\n",
        "    self.post[\"pageSize\"] = 10\n",
        "    self.post[\"page\"] = page\n",
        "    self.all = {\"Results\": []}\n",
        "    print('.post >>')\n",
        "    print(self.post)\n",
        "    # self.datasource = ''\n",
        "    print(\"\\n\")\n",
        "    print(\"Searching...\")\n",
        "    print(self.all)\n",
        "\n",
        "    \n",
        "\n",
        "    with mp.Pool(self.poolCPU) as pool:\n",
        "      if self.n > 10:\n",
        "    \n",
        "        if len(pages) != 0:\n",
        "          self._pages = pages\n",
        "        else:  \n",
        "          self._pages = list(range(self._page, (self.n//10)+self._page))\n",
        "      # for page in range(n//10):\n",
        "        self._runtime(pool, self._pages)\n",
        "          \n",
        "        if n%10>0:\n",
        "          self._pages = [self.n//10+self._page]\n",
        "          self.post[\"pageSize\"] = self.n%10\n",
        "\n",
        "          self._runtime(pool, self._pages)\n",
        "          \n",
        "      else:\n",
        "        # pass\n",
        "        self._pages = [self._page]\n",
        "        self.post[\"page\"] = self._page\n",
        "        self.post[\"pageSize\"] = self.n\n",
        "\n",
        "        self._runtime(pool, self._pages)\n",
        "\n",
        "    \n",
        "      # self._extract(pool, self.datasource)\n",
        "\n",
        "\n",
        "##### Description #####\n",
        "# ex. {\"params\": value} \n",
        "#  \n",
        "##### Params that can pass in SearchWeb().get(params = value): #####\n",
        "#     {\n",
        "#     \"n\": 1000 (how much papers)\n",
        "#     \"page\": 1, (where start search)\n",
        "#      }\n",
        "##### Params that can pass in SearchWeb(params = value): #####\n",
        "# data = '''{\n",
        "#     \"Savename\": 'Data'\n",
        "#     \"sleeptry\": 3 (seconds)\n",
        "#     \"poolCPU\": 4 (Number of clusters, CPU)\n",
        "#     \"save\": False\n",
        "#     \"queryString\": \"Machine Learning+Deep Learning\",\n",
        "#     \"sort\": \"total-citations\", #influence #\"pub-date\" #relevance\n",
        "#     \"authors\": [],\n",
        "#     \"coAuthors\": [],\n",
        "#     \"venues\": [\n",
        "#         \"PloS one\",\n",
        "#         \"AAAI\",\n",
        "#         \"Scientific reports\",\n",
        "#         \"IEEE Access\",\n",
        "#         \"ArXiv\",\n",
        "#         \"Expert Syst. Appl.\",\n",
        "#         \"ICML\",\n",
        "#         \"Neurocomputing\",\n",
        "#         \"Sensors\",\n",
        "#         \"Remote. Sens.\"\n",
        "#     ],\n",
        "#     \"yearFilter\": {\n",
        "#         \"min\": 2008,\n",
        "#         \"max\": 2021\n",
        "#     },\n",
        "#     \"requireViewablePdf\": True,\n",
        "#     \"publicationTypes\": [\n",
        "#         \"ClinicalTrial\",\n",
        "#         \"CaseReport\",\n",
        "#         \"Editorial\",\n",
        "#         \"Study\",\n",
        "#         \"Book\",\n",
        "#         \"News\",\n",
        "#         \"Review\",\n",
        "#         \"Conference\",\n",
        "#         \"LettersAndComments\",\n",
        "#         \"JournalArticle\"\n",
        "#     ],\n",
        "#     \"externalContentTypes\": [],\n",
        "#     \"fieldsOfStudy\": [\n",
        "#         \"biology\",\n",
        "#         \"art\",\n",
        "#         \"business\",\n",
        "#         \"computer-science\",\n",
        "#         \"chemistry\",\n",
        "#         \"economics\",\n",
        "#         \"engineering\",\n",
        "#         \"environmental-science\",\n",
        "#         \"geography\",\n",
        "#         \"geology\",\n",
        "#         \"history\",\n",
        "#         \"materials-science\",\n",
        "#         \"mathematics\",\n",
        "#         \"medicine\",\n",
        "#         \"philosophy\",\n",
        "#         \"physics\",\n",
        "#         \"political-science\",\n",
        "#         \"psychology\",\n",
        "#         \"sociology\"\n",
        "#     ],\n",
        "#     \"useFallbackRankerService\": False,\n",
        "#     \"useFallbackSearchCluster\": False,\n",
        "#     \"hydrateWithDdb\": True,\n",
        "#     \"includeTldrs\": True,\n",
        "#     \"performTitleMatch\": True,\n",
        "#     \"includeBadges\": True,\n",
        "#     \"tldrModelVersion\": \"v2.0.0\",\n",
        "#     \"getQuerySuggestions\": False\n",
        "# }\n",
        "# '''\n",
        "# '''\n",
        "# Obs. Params that have a list can be a empty list\n",
        "# Ex. {\"venues\": []}\n",
        "\n",
        "### Discoment here to have a script\n",
        "# if __name__ == '__main__':\n",
        "#   SearchWeb(\n",
        "#     search= \"decision making+optimization+artificial intelligence\",\n",
        "#     sort= \"influence\",\n",
        "#     Savename = \"influence\",\n",
        "#     save=True,\n",
        "#     poolCPU = 4,\n",
        "#     sleeptry = 3.5*60,\n",
        "#     venues = [],\n",
        "#     publicationTypes = ['JournalArticle'],\n",
        "#     fieldsOfStudy = [],\n",
        "#     getQuerySuggestions = True\n",
        "#     ).get(20000, page = 1)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_j2uslvt8A2"
      },
      "source": [
        "from_Webpage = SearchWeb(search= \"Machine Learning+Deep Learning\", sort= \"total-citations\", save=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzUBus_Vt9-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195e995a-2f8c-4155-974b-29bf265059ef"
      },
      "source": [
        "# Retorna 100 papers a partir da pag. 2 com base nos parametros passados em SearchWeb() que constitui ().post\n",
        "from_Webpage.get(100, page = 2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".post >>\n",
            "{'page': 2, 'pageSize': 10, 'queryString': 'Machine Learning+Deep Learning', 'sort': 'total-citations', 'authors': [], 'coAuthors': [], 'venues': ['PloS one', 'AAAI', 'Scientific reports', 'IEEE Access', 'ArXiv', 'Expert Syst. Appl.', 'ICML', 'Neurocomputing', 'Sensors', 'Remote. Sens.'], 'yearFilter': None, 'requireViewablePdf': False, 'publicationTypes': ['ClinicalTrial', 'CaseReport', 'Editorial', 'Study', 'Book', 'News', 'Review', 'Conference', 'LettersAndComments', 'JournalArticle'], 'externalContentTypes': [], 'fieldsOfStudy': ['biology', 'art', 'business', 'computer-science', 'chemistry', 'economics', 'engineering', 'environmental-science', 'geography', 'geology', 'history', 'materials-science', 'mathematics', 'medicine', 'philosophy', 'physics', 'political-science', 'psychology', 'sociology'], 'useFallbackRankerService': False, 'useFallbackSearchCluster': False, 'hydrateWithDdb': True, 'includeTldrs': True, 'performTitleMatch': True, 'includeBadges': True, 'tldrModelVersion': 'v2.0.0', 'getQuerySuggestions': False}\n",
            "\n",
            "\n",
            "Searching...\n",
            "{'Results': []}\n",
            "\n",
            "\n",
            "[_runtime]>> Start searching...\n",
            "\n",
            " ---\n",
            "Total Results: 51114\n",
            "Total Pages: 5111\n",
            "Query Suggestions: []\n",
            "--- \n",
            "\n",
            "[_extract] >> extracting relevant data.\n",
            "[_extract]>> Demorou 2.34s\n",
            "[_runtime]>> Demorou 7.84s\n",
            "[get]>> Demorou 8.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx4vC7d_CxYr",
        "outputId": "ee2fe47a-09b7-452c-d4cb-fcc2971b0be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from_Webpage.all"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Results': [{'Page': {'N_Page': 2,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [],\n",
              "      'authors': ['E. Samaniego',\n",
              "       'C. Anitescu',\n",
              "       'S. Goswami',\n",
              "       'Vien Minh Nguyen-Thanh',\n",
              "       'Hongwei Guo',\n",
              "       'Khader M. Hamdia',\n",
              "       'T. Rabczuk',\n",
              "       'X. Zhuang'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.59375,\n",
              "       'citationVelocity': 56.0,\n",
              "       'citedByBuckets': [{'count': 2, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 64, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 102, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 79.53625319613955,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 168,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 48,\n",
              "       'numViewableReferences': 48},\n",
              "      'entities': ['Machine learning',\n",
              "       'Computational mechanics',\n",
              "       'Finite element method',\n",
              "       'Isogeometric analysis',\n",
              "       'Computation',\n",
              "       'Loss function',\n",
              "       'Collocation',\n",
              "       'Approximation algorithm',\n",
              "       'Discretization',\n",
              "       'MIT Engineering Systems Division',\n",
              "       'In-game advertising'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '7af9fde25baab82e034ac0f9ef21fe1cbd19fdc1',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1908.10407'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1908.10407.pdf'}],\n",
              "      'paperAbstract': 'Partial Differential Equations (PDE) are fundamental to model different phenomena in science and engineering mathematically. Solving them is a crucial step towards a precise knowledge of the behaviour of natural and engineered systems. In general, in order to solve PDEs that represent real systems to an acceptable degree, analytical methods are usually not enough. One has to resort to discretization methods. For engineering problems, probably the best known option is the finite element method (FEM). However, powerful alternatives such as mesh-free methods and Isogeometric Analysis (IGA) are also available. The fundamental idea is to approximate the solution of the PDE by means of functions specifically built to have some desirable properties. In this contribution, we explore Deep Neural Networks (DNNs) as an option for approximation. They have shown impressive results in areas such as visual recognition. DNNs are regarded here as function approximation machines. There is great flexibility to define their structure and important advances in the architecture and the efficiency of the algorithms to implement them make DNNs a very interesting alternative to approximate the solution of a PDE. We concentrate in applications that have an interest for Computational Mechanics. Most contributions that have decided to explore this possibility have adopted a collocation strategy. In this contribution, we concentrate in mechanical problems and analyze the energetic format of the PDE. The energy of a mechanical system seems to be the natural loss function for a machine learning method to approach a mechanical problem. As proofs of concept, we deal with several problems and explore the capabilities of the method for applications in engineering.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1908.10407.pdf'},\n",
              "      'pubDate': '2019-08-27',\n",
              "      'pubUpdateDate': '2020-04-15',\n",
              "      'scorecardStats': [{'citationCount': 168,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'MAG',\n",
              "       'DBLP',\n",
              "       'ScienceParseMerged',\n",
              "       'Crossref',\n",
              "       'MAG',\n",
              "       'Anansi',\n",
              "       'Unpaywall',\n",
              "       'ScienceParseMerged',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv',\n",
              "       'ScienceParseMerged'],\n",
              "      'title': 'An Energy Approach to the Solution of Partial Differential Equations in Computational Mechanics via Machine Learning: Concepts, Implementation and Applications',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'This contribution focuses in mechanical problems and analyze the energetic format of the PDE, where the energy of a mechanical system seems to be the natural loss function for a machine learning method to approach a mechanical problem.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['O. Ghorbanzadeh',\n",
              "       'T. Blaschke',\n",
              "       'Khalil Gholamnia',\n",
              "       'S. Meena',\n",
              "       'D. Tiede',\n",
              "       'J. Aryal'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.273972602739726,\n",
              "       'citationVelocity': 52.666666666666664,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2017, 'startKey': 2017},\n",
              "        {'count': 32, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 73, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 53, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 122.37840722411993,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.031446540880503145,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 159,\n",
              "       'numKeyCitations': 5,\n",
              "       'numKeyReferences': 6,\n",
              "       'numReferences': 66,\n",
              "       'numViewableReferences': 66},\n",
              "      'entities': ['Machine learning',\n",
              "       'Artificial neural network',\n",
              "       'Convolutional neural network',\n",
              "       'Convolution',\n",
              "       'Object detection',\n",
              "       'Support vector machine',\n",
              "       'Random forest',\n",
              "       'Crowdsourcing',\n",
              "       'Computer vision',\n",
              "       'Geographic information science',\n",
              "       'Data curation',\n",
              "       'Digital elevation model',\n",
              "       'Naruto Shippuden: Clash of Ninja Revolution 3',\n",
              "       'Deep learning',\n",
              "       'Topography',\n",
              "       'Inventory',\n",
              "       'Field research',\n",
              "       'Microsoft Windows',\n",
              "       'Minimum bounding box',\n",
              "       'Radio frequency',\n",
              "       'Pixel',\n",
              "       'Map',\n",
              "       'TensorFlow',\n",
              "       'Object-based language',\n",
              "       'Conceptualization (information science)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '98f2aff0a60c24b41bc5c916807e0edb4da73e3c',\n",
              "      'journal': {'name': 'Remote. Sens.', 'pages': '196', 'volume': '11'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/98f2/aff0a60c24b41bc5c916807e0edb4da73e3c.pdf'}],\n",
              "      'paperAbstract': 'There is a growing demand for detailed and accurate landslide maps and inventories around the globe, but particularly in hazard-prone regions such as the Himalayas. Most standard mapping methods require expert knowledge, supervision and fieldwork. In this study, we use optical data from the Rapid Eye satellite and topographic factors to analyze the potential of machine learning methods, i.e., artificial neural network (ANN), support vector machines (SVM) and random forest (RF), and different deep-learning convolution neural networks (CNNs) for landslide detection. We use two training zones and one test zone to independently evaluate the performance of different methods in the highly landslide-prone Rasuwa district in Nepal. Twenty different maps are created using ANN, SVM and RF and different CNN instantiations and are compared against the results of extensive fieldwork through a mean intersection-over-union (mIOU) and other common metrics. This accuracy assessment yields the best result of 78.26% mIOU for a small window size CNN, which uses spectral information only. The additional information from a 5 m digital elevation model helps to discriminate between human settlements and landslides but does not improve the overall classification accuracy. CNNs do not automatically outperform ANN, SVM and RF, although this is sometimes claimed. Rather, the performance of CNNs strongly depends on their design, i.e., layer depth, input window sizes and training strategies. Here, we conclude that the CNN method is still in its infancy as most researchers will either use predefined parameters in solutions like Google TensorFlow or will apply different settings in a trial-and-error manner. Nevertheless, deep-learning can improve landslide mapping in the future if the effects of the different designs are better understood, enough training samples exist, and the effects of augmentation strategies to artificially increase the number of existing samples are better understood.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/98f2/aff0a60c24b41bc5c916807e0edb4da73e3c.pdf'},\n",
              "      'pubDate': '2019-01-20',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 159,\n",
              "        'keyCitationCount': 5,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'MAG', 'Anansi', 'ScienceParseMerged', 'Unpaywall'],\n",
              "      'title': 'Evaluation of Different Machine Learning Methods and Deep-Learning Convolutional Neural Networks for Landslide Detection',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'The CNN method is still in its infancy as most researchers will either use predefined parameters in solutions like Google TensorFlow or will apply different settings in a trial-and-error manner, Nevertheless, deep-learning can improve landslide mapping in the future if the effects of the different designs are better understood, enough training samples exist, and the results of augmentation strategies to artificially increase the number of existing samples are better understanding.'},\n",
              "      'venue': 'Remote. Sens.',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Duy-Tang Hoang', 'Hee-Jun Kang'],\n",
              "      'badges': [],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.10606060606060606,\n",
              "       'citationVelocity': 46.0,\n",
              "       'citedByBuckets': [{'count': 13, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 66, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 59, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 119.15814291103072,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.007246376811594203,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 138,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 92,\n",
              "       'numViewableReferences': 92},\n",
              "      'entities': ['Deep learning',\n",
              "       'Convolutional neural network',\n",
              "       'Autoencoder',\n",
              "       'Restricted Boltzmann machine',\n",
              "       'Machine learning',\n",
              "       'Systematic review',\n",
              "       'Nonlinear system',\n",
              "       'Algorithm'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '850565325986cc4f541ff81666ce0c7dd6cc8b2c',\n",
              "      'journal': {'name': 'Neurocomputing',\n",
              "       'pages': '327-335',\n",
              "       'volume': '335'},\n",
              "      'links': [{'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1016/j.neucom.2018.06.078'}],\n",
              "      'paperAbstract': 'Abstract Nowadays, Deep Learning is the most attractive research trend in the area of Machine Learning. With the ability of learning features from raw data by deep architectures with many layers of non-linear data processing units, Deep Learning has become a promising tool for intelligent bearing fault diagnosis. This survey paper intends to provide a systematic review of Deep Learning based bearing fault diagnosis. The three popular Deep Learning algorithms for bearing fault diagnosis including Autoencoder, Restricted Boltzmann Machine, and Convolutional Neural Network are briefly introduced. And their applications are reviewed through publications and research works on the area of bearing fault diagnosis. Further applications and challenges in this research area are also discussed.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'doi',\n",
              "       'url': 'https://doi.org/10.1016/j.neucom.2018.06.078'},\n",
              "      'pubDate': '2019-03-28',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 138,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'Unpaywall', 'MAG'],\n",
              "      'title': 'A survey on Deep Learning based bearing fault diagnosis',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': 'The three popular Deep Learning algorithms for Bearing fault diagnosis including Autoencoder, Restricted Boltzmann Machine, and Convolutional Neural Network are briefly introduced and their applications are reviewed through publications and research works on the area of bearing fault diagnosis.'},\n",
              "      'venue': 'Neurocomputing',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Rui Zhao',\n",
              "       'Ruqiang Yan',\n",
              "       'Zhenghua Chen',\n",
              "       'K. Mao',\n",
              "       'P. Wang',\n",
              "       'R. Gao'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.48148148148148145,\n",
              "       'citationVelocity': 24.0,\n",
              "       'citedByBuckets': [{'count': 6, 'endKey': 2017, 'startKey': 2017},\n",
              "        {'count': 36, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 31, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 27, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 14, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 135.37953489367726,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.02631578947368421,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 114,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 118,\n",
              "       'numViewableReferences': 118},\n",
              "      'entities': ['Deep learning',\n",
              "       'Machine learning',\n",
              "       'Convolutional neural network',\n",
              "       'Autoencoder',\n",
              "       'Recurrent neural network',\n",
              "       'Deep belief network',\n",
              "       'Speech recognition',\n",
              "       'Machine translation',\n",
              "       'Real life',\n",
              "       'Image segmentation',\n",
              "       'Data visualization',\n",
              "       'ImageNet',\n",
              "       'Black box',\n",
              "       'Test set',\n",
              "       'Dimensionality reduction',\n",
              "       'Feature extraction',\n",
              "       'Neural Networks',\n",
              "       'Internet',\n",
              "       'Outline of object recognition',\n",
              "       'Computer vision',\n",
              "       'Low-discrepancy sequence',\n",
              "       'Feature learning',\n",
              "       'Artificial neural network',\n",
              "       'End-to-end principle',\n",
              "       'Performance'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '44f4b1b90f8d5515f2486e07e4cb4b9589c27518',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1612.07640'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1612.07640.pdf'}],\n",
              "      'paperAbstract': 'Since 2006, deep learning (DL) has become a rapidly growing research direction, redefining state-of-the-art performances in a wide range of areas such as object recognition, image segmentation, speech recognition and machine translation. In modern manufacturing systems, data-driven machine health monitoring is gaining in popularity due to the widespread deployment of low-cost sensors and their connection to the Internet. Meanwhile, deep learning provides useful tools for processing and analyzing these big machinery data. The main purpose of this paper is to review and summarize the emerging research work of deep learning on machine health monitoring. After the brief introduction of deep learning techniques, the applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and its variants including Deep Belief Network (DBN) and Deep Boltzmann Machines (DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). Finally, some new trends of DL-based machine health monitoring methods are discussed.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1612.07640.pdf'},\n",
              "      'pubDate': '2016-12-16',\n",
              "      'pubUpdateDate': '2016-12-16',\n",
              "      'scorecardStats': [{'citationCount': 114,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Grobid',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP',\n",
              "       'ScienceParseMerged',\n",
              "       'Crawler',\n",
              "       'MAG',\n",
              "       'ArXiv',\n",
              "       'Anansi'],\n",
              "      'title': 'Deep Learning and Its Applications to Machine Health Monitoring: A Survey',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'The applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder and its variants, Restricted Boltzmann Machines, Convolutional Neural Networks, and Recurrent Neural Networks.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2016'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['A. Alkhateeb'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.17073170731707318,\n",
              "       'citationVelocity': 33.666666666666664,\n",
              "       'citedByBuckets': [{'count': 12, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 41, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 48, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 114.24493068323659,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.1485148514851485,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 101,\n",
              "       'numKeyCitations': 15,\n",
              "       'numKeyReferences': 1,\n",
              "       'numReferences': 21,\n",
              "       'numViewableReferences': 21},\n",
              "      'entities': ['Deep learning',\n",
              "       'Machine learning',\n",
              "       'Ray tracing (graphics)',\n",
              "       'Benchmark (computing)',\n",
              "       'Transmitter',\n",
              "       'Mathematical optimization',\n",
              "       'Algorithm'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Engineering', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'd1d8980d04d411c314910d1926f3bbaac46c2197',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1902.06435'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1902.06435.pdf'}],\n",
              "      'paperAbstract': 'Machine learning tools are finding interesting applications in millimeter wave (mmWave) and massive MIMO systems. This is mainly thanks to their powerful capabilities in learning unknown models and tackling hard optimization problems. To advance the machine learning research in mmWave/massive MIMO, however, there is a need for a common dataset. This dataset can be used to evaluate the developed algorithms, reproduce the results, set benchmarks, and compare the different solutions. In this work, we introduce the DeepMIMO dataset, which is a generic dataset for mmWave/massive MIMO channels. The DeepMIMO dataset generation framework has two important features. First, the DeepMIMO channels are constructed based on accurate ray-tracing data obtained from Remcom Wireless InSite. The DeepMIMO channels, therefore, capture the dependence on the environment geometry/materials and transmitter/receiver locations, which is essential for several machine learning applications. Second, the DeepMIMO dataset is generic/parameterized as the researcher can adjust a set of system and channel parameters to tailor the generated DeepMIMO dataset for the target machine learning application. The DeepMIMO dataset can then be completely defined by the (i) the adopted ray-tracing scenario and (ii) the set of parameters, which enables the accurate definition and reproduction of the dataset. In this paper, an example DeepMIMO dataset is described based on an outdoor ray-tracing scenario of 18 base stations and more than one million users. The paper also shows how this dataset can be used in an example deep learning application of mmWave beam prediction.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1902.06435.pdf'},\n",
              "      'pubDate': '2019-02-18',\n",
              "      'pubUpdateDate': '2019-02-18',\n",
              "      'scorecardStats': [{'citationCount': 101,\n",
              "        'keyCitationCount': 15,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MergedPDFExtraction',\n",
              "       'ArXiv',\n",
              "       'DBLP',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG'],\n",
              "      'title': 'DeepMIMO: A Generic Deep Learning Dataset for Millimeter Wave and Massive MIMO Applications',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': 'This work introduces the DeepMIMO dataset, which is a generic dataset for mmWave/massive MIMO channels, and shows how this dataset can be used in an example deep learning application of mmWave beam prediction.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': [\"A. D'Amour\",\n",
              "       'K. Heller',\n",
              "       'D. Moldovan',\n",
              "       'Ben Adlam',\n",
              "       'B. Alipanahi',\n",
              "       'Alex Beutel',\n",
              "       'Christina Chen',\n",
              "       'Jonathan Deaton',\n",
              "       'Jacob Eisenstein',\n",
              "       'M. Hoffman',\n",
              "       'F. Hormozdiari',\n",
              "       'N. Houlsby',\n",
              "       'Shaobo Hou',\n",
              "       'Ghassen Jerfel',\n",
              "       'A. Karthikesalingam',\n",
              "       'Mario Lucic',\n",
              "       'Y. Ma',\n",
              "       'C. McLean',\n",
              "       'Diana Mincu',\n",
              "       'Akinori Mitani',\n",
              "       'A. Montanari',\n",
              "       'Zachary Nado',\n",
              "       'Vivek Natarajan',\n",
              "       'Christopher Nielson',\n",
              "       'T. F. Osborne',\n",
              "       'R. Raman',\n",
              "       'K. Ramasamy',\n",
              "       'R. Sayres',\n",
              "       'J. Schrouff',\n",
              "       'Martin G. Seneviratne',\n",
              "       'Shannon Sequeira',\n",
              "       'Harini Suresh',\n",
              "       'Victor Veitch',\n",
              "       'Max Vladymyrov',\n",
              "       'Xuezhi Wang',\n",
              "       'Kellie Webster',\n",
              "       'S. Yadlowsky',\n",
              "       'Taedong Yun',\n",
              "       'Xiaohua Zhai',\n",
              "       'D. Sculley'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 5.615384615384615,\n",
              "       'citationVelocity': 49.5,\n",
              "       'citedByBuckets': [{'count': 13, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 86, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 93.37203833860272,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.010101010101010102,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 99,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 25,\n",
              "       'numReferences': 150,\n",
              "       'numViewableReferences': 150},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '71a85e735a3686bef8cce3725ae5ba82e2cabb1b',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2011.03395'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2011.03395.pdf'}],\n",
              "      'paperAbstract': 'ML models often exhibit unexpectedly poor behavior when they are deployed in real-world domains. We identify underspecification as a key reason for these failures. An ML pipeline is underspecified when it can return many predictors with equivalently strong held-out performance in the training domain. Underspecification is common in modern ML pipelines, such as those based on deep learning. Predictors returned by underspecified pipelines are often treated as equivalent based on their training domain performance, but we show here that such predictors can behave very differently in deployment domains. This ambiguity can lead to instability and poor model behavior in practice, and is a distinct failure mode from previously identified issues arising from structural mismatch between training and deployment domains. We show that this problem appears in a wide variety of practical ML pipelines, using examples from computer vision, medical imaging, natural language processing, clinical risk prediction based on electronic health records, and medical genomics. Our results show the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2011.03395.pdf'},\n",
              "      'pubDate': '2020-11-06',\n",
              "      'pubUpdateDate': '2020-11-24',\n",
              "      'scorecardStats': [{'citationCount': 99,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv'],\n",
              "      'title': 'Underspecification Presents Challenges for Credibility in Modern Machine Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'This work shows the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain, and shows that this problem appears in a wide variety of practical ML pipelines.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['S. Chatzis',\n",
              "       'Vasilis Siakoulis',\n",
              "       'Anastasios Petropoulos',\n",
              "       'Evangelos Stavroulakis',\n",
              "       'Nikos E. Vlachogiannakis'],\n",
              "      'badges': [],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.3488372093023256,\n",
              "       'citationVelocity': 32.0,\n",
              "       'citedByBuckets': [{'count': 2, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 25, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 43, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 28, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 124.82517520014721,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.061224489795918366,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 98,\n",
              "       'numKeyCitations': 6,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 39,\n",
              "       'numViewableReferences': 39},\n",
              "      'entities': ['Machine learning',\n",
              "       'Bootstrapping (statistics)',\n",
              "       'Deep learning',\n",
              "       'Gradient boosting',\n",
              "       'Random forest',\n",
              "       'Persistence (computer science)',\n",
              "       'Boosting (machine learning)',\n",
              "       'Neural Networks',\n",
              "       'Interdependence',\n",
              "       'Volatility',\n",
              "       'Algorithm',\n",
              "       'Sampling (signal processing)',\n",
              "       'Linkage (software)',\n",
              "       'Software propagation',\n",
              "       'Support vector machine'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '4739cd20cdb4fb88845ee404947173f4a53aed98',\n",
              "      'journal': {'name': 'Expert Syst. Appl.',\n",
              "       'pages': '353-371',\n",
              "       'volume': '112'},\n",
              "      'links': [{'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1016/j.eswa.2018.06.032'}],\n",
              "      'paperAbstract': 'Abstract This work contributes to this ongoing debate on the nature and the characteristics of propagation channels of crash events in international stock markets. Specifically, we investigate transmission mechanisms across stock markets along with effects from bond and currency markets. Our approach comprises a solid forecasting mechanism of the probability of a stock market crash event in various time frames. The developed approach combines different machine learning algorithms which are presented with daily stock, bond and currency data from 39 countries that cover a large spectrum of economies. Specifically, we leverage the merits of a series of techniques including Classification Trees, Support Vector Machines, Random Forests, Neural Networks, Extreme Gradient Boosting, and Deep Neural Networks. To the best of our knowledge, this is the first time that Deep Learning and Boosting approaches are considered in the literature as a means of predicting stock market crisis episodes. The independent variables included in our data contain information regarding both the two fundamental linkage channels through which financial contagion can be initiated: returns and volatility. We apply a suite of machine learning algorithms for selecting the most relevant variables out of a large set of proposed ones. Finally, we employ bootstrap sampling for adjusting the imbalanced nature of the available fitting dataset. Our experimental results provide strong evidence that stock market crises tend to exhibit persistence. We also find significant evidence of interdependence and cross-contagion effects among stock, bond and currency markets. Finally, we show that the use of Deep Neural Networks significantly increases the classification accuracy, while offering a robust way to create a global systemic early warning tool that is more efficient and risk-sensitive than the currently established ones. Thus, central banks may use these tools to early adjust their monetary policy, so as to ensure financial stability.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'doi',\n",
              "       'url': 'https://doi.org/10.1016/j.eswa.2018.06.032'},\n",
              "      'pubDate': '2018-12-01',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 98,\n",
              "        'keyCitationCount': 6,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Unpaywall', 'DBLP', 'MAG'],\n",
              "      'title': 'Forecasting stock market crisis events using deep and statistical machine learning techniques',\n",
              "      'tldr': {'abstractSimilarityScore': 45,\n",
              "       'text': 'This work investigates transmission mechanisms across stock markets along with effects from bond and currency markets, and shows that the use of Deep Neural Networks significantly increases the classification accuracy, while offering a robust way to create a global systemic early warning tool that is more efficient and risk-sensitive than the currently established ones.'},\n",
              "      'venue': 'Expert Syst. Appl.',\n",
              "      'videos': [],\n",
              "      'year': '2018'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08681127.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2906934'}],\n",
              "      'authors': ['R. Vinayakumar',\n",
              "       'M. Alazab',\n",
              "       'K. Soman',\n",
              "       'P. Poornachandran',\n",
              "       'S. Venkatraman'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.5,\n",
              "       'citationVelocity': 31.666666666666668,\n",
              "       'citedByBuckets': [{'count': 20, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 50, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 25, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 123.4182726040818,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.021052631578947368,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 95,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 17,\n",
              "       'numReferences': 44,\n",
              "       'numViewableReferences': 44},\n",
              "      'entities': ['Deep learning',\n",
              "       'Feature engineering',\n",
              "       'Zero-day (computing)',\n",
              "       'Image processing',\n",
              "       'Feature learning',\n",
              "       'Malware analysis',\n",
              "       'Big data',\n",
              "       'Machine learning',\n",
              "       'Arabic numeral 0',\n",
              "       'Real-time locating system',\n",
              "       'User (computing)',\n",
              "       'Categorization',\n",
              "       'Algorithm',\n",
              "       'Learning Disorders',\n",
              "       'Time complexity',\n",
              "       'Scalability',\n",
              "       'Antivirus software',\n",
              "       'Classification',\n",
              "       'Architecture as Topic',\n",
              "       'corporation',\n",
              "       'Escalation',\n",
              "       'Real-time clock'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'c847e7a0430a475caf7173cafb02cab9367779b8',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '46717-46738',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8681127'}],\n",
              "      'paperAbstract': 'Security breaches due to attacks by malicious software (malware) continue to escalate posing a major security concern in this digital age. With many computer users, corporations, and governments affected due to an exponential growth in malware attacks, malware detection continues to be a hot research topic. Current malware detection solutions that adopt the static and dynamic analysis of malware signatures and behavior patterns are time consuming and have proven to be ineffective in identifying unknown malwares in real-time. Recent malwares use polymorphic, metamorphic, and other evasive techniques to change the malware behaviors quickly and to generate a large number of new malwares. Such new malwares are predominantly variants of existing malwares, and machine learning algorithms (MLAs) are being employed recently to conduct an effective malware analysis. However, such approaches are time consuming as they require extensive feature engineering, feature learning, and feature representation. By using the advanced MLAs such as deep learning, the feature engineering phase can be completely avoided. Recently reported research studies in this direction show the performance of their algorithms with a biased training data, which limits their practical use in real-time situations. There is a compelling need to mitigate bias and evaluate these methods independently in order to arrive at a new enhanced method for effective zero-day malware detection. To fill the gap in the literature, this paper, first, evaluates the classical MLAs and deep learning architectures for malware detection, classification, and categorization using different public and private datasets. Second, we remove all the dataset bias removed in the experimental analysis by having different splits of the public and private datasets to train and test the model in a disjoint way using different timescales. Third, our major contribution is in proposing a novel image processing technique with optimal parameters for MLAs and deep learning architectures to arrive at an effective zero-day malware detection model. A comprehensive comparative study of our model demonstrates that our proposed deep learning architectures outperform classical MLAs. Our novelty in combining visualization and deep learning architectures for static, dynamic, and image processing-based hybrid approach applied in a big data environment is the first of its kind toward achieving robust intelligent zero-day malware detection. Overall, this paper paves way for an effective visual detection of malware using a scalable and hybrid deep learning framework for real-time deployments.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8681127'},\n",
              "      'pubDate': '2019-04-03',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 95,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['IEEE', 'MAG', 'ScienceParseMerged', 'Unpaywall', 'DBLP'],\n",
              "      'title': 'Robust Intelligent Malware Detection Using Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 39,\n",
              "       'text': 'A novelty in combining visualization and deep learning architectures for static, dynamic, and image processing-based hybrid approach applied in a big data environment is the first of its kind toward achieving robust intelligent zero-day malware detection.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://dl.acm.org/doi/pdf/10.1145/3470442'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'http://eprints.lse.ac.uk/100806/5/duetting19a_supp.pdf'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'http://eprints.lse.ac.uk/100806/6/duetting19a.pdf'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'http://eprints.lse.ac.uk/100806/87/Duetting_optimal_auctions_through_deep_learning_published.pdf'},\n",
              "       {'linkType': 'dblp',\n",
              "        'url': 'http://proceedings.mlr.press/v97/duetting19a.html'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'http://proceedings.mlr.press/v97/duetting19a/duetting19a-supp.pdf'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'http://proceedings.mlr.press/v97/duetting19a/duetting19a.pdf'},\n",
              "       {'linkType': 'arxiv', 'url': 'https://arxiv.org/pdf/1706.03459.pdf'},\n",
              "       {'linkType': 'doi', 'url': 'https://doi.org/10.1145/3470442'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://econcs.seas.harvard.edu/files/econcs/files/duetting_commacm20.pdf'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://economics.harvard.edu/files/economics/files/parkes_spring_2019.pdf'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://scholar.harvard.edu/files/zfeng/files/1706.03459.pdf'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://scholar.harvard.edu/files/zfeng/files/deep-amd-icml.pdf'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://scholar.harvard.edu/files/zfeng/files/deep-amd.pdf'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://scholar.harvard.edu/files/zfeng/files/deep-amd_01.pdf'}],\n",
              "      'authors': ['Paul Dütting', 'Zhe Feng', 'H. Narasimhan', 'D. Parkes'],\n",
              "      'badges': [{'id': 'UNPAYWALL'}, {'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.0625,\n",
              "       'citationVelocity': 27.666666666666668,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2017, 'startKey': 2017},\n",
              "        {'count': 8, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 17, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 32, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 34, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 73.11348815281993,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.20430107526881722,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 93,\n",
              "       'numKeyCitations': 19,\n",
              "       'numKeyReferences': 18,\n",
              "       'numReferences': 132,\n",
              "       'numViewableReferences': 132},\n",
              "      'entities': ['Deep learning',\n",
              "       'Artificial neural network',\n",
              "       'Network architecture',\n",
              "       'Layer (electronics)',\n",
              "       'Experiment',\n",
              "       'Pipeline (computing)',\n",
              "       'Computation',\n",
              "       'Pipeline (software)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1},\n",
              "       {'contentType': {'id': 'BLOG'}, 'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'b8e49216e5b4a017342b0be5f6fbbd79e690a1c7',\n",
              "      'journal': {'name': 'Communications of the ACM',\n",
              "       'pages': '109 - 116',\n",
              "       'volume': '64'},\n",
              "      'links': [{'linkType': 'acm',\n",
              "        'url': 'http://dl.acm.org/citation.cfm?id=3470442'}],\n",
              "      'paperAbstract': 'Designing an incentive compatible auction that maximizes expected revenue is an intricate task. The single-item case was resolved in a seminal piece of work by Myerson in 1981. Even after 30--40 years of intense research, the problem remains unsolved for settings with two or more items. We overview recent research results that show how tools from deep learning are shaping up to become a powerful tool for the automated design of near-optimal auctions auctions. In this approach, an auction is modeled as a multilayer neural network, with optimal auction design framed as a constrained learning problem that can be addressed with standard machine learning pipelines. Through this approach, it is possible to recover to a high degree of accuracy essentially all known analytically derived solutions for multi-item settings and obtain novel mechanisms for settings in which the optimal mechanism is unknown.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'acm',\n",
              "       'url': 'http://dl.acm.org/citation.cfm?id=3470442'},\n",
              "      'pubDate': '2017-06-12',\n",
              "      'pubUpdateDate': '2021-07-26',\n",
              "      'scorecardStats': [{'citationCount': 93,\n",
              "        'keyCitationCount': 19,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'ACM',\n",
              "       'ScienceParseMerged',\n",
              "       'Crossref',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP',\n",
              "       'DBLP',\n",
              "       'ArXiv',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'Optimal auctions through deep learning',\n",
              "      'tldr': {'abstractSimilarityScore': 38,\n",
              "       'text': 'This work overviews recent research results that show how tools from deep learning are shaping up to become a powerful tool for the automated design of near-optimal auctions auctions and recovers to a high degree of accuracy essentially all known analytically derived solutions for multi-item settings.'},\n",
              "      'venue': 'ICML',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Weizhong Yan', 'LiJie Yu'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.13043478260869565,\n",
              "       'citationVelocity': 22.666666666666668,\n",
              "       'citedByBuckets': [{'count': 8, 'endKey': 2017, 'startKey': 2017},\n",
              "        {'count': 16, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 25, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 23, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 20, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 79.60997393909561,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.010752688172043012,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 93,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 3,\n",
              "       'numReferences': 46,\n",
              "       'numViewableReferences': 46},\n",
              "      'entities': ['Anomaly detection',\n",
              "       'Deep learning',\n",
              "       'Machine learning',\n",
              "       'Feature learning',\n",
              "       'Sensor',\n",
              "       'Natural language processing',\n",
              "       'Speech recognition',\n",
              "       'Computer vision',\n",
              "       'Artificial neural network',\n",
              "       'Time series',\n",
              "       'Logic programming'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '97eebd000dff5a370f3e42b8d0fa89063371087e',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1908.09238'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1908.09238.pdf'}],\n",
              "      'paperAbstract': 'Monitoring gas turbine combustors health, in particular, early detecting abnormal behaviors and incipient faults, is critical in ensuring gas turbines operating efficiently and in preventing costly unplanned maintenance. One popular means of detecting combustor abnormalities is through continuously monitoring exhaust gas temperature profiles. Over the years many anomaly detection technologies have been explored for detecting combustor faults, however, the performance (detection rate) of anomaly detection solutions fielded is still inadequate. Advanced technologies that can improve detection performance are in great need. Aiming for improving anomaly detection performance, in this paper we introduce recently-developed deep learning (DL) in machine learning into the combustors anomaly detection application. Specifically, we use deep learning to hierarchically learn features from the sensor measurements of exhaust gas temperatures. And we then use the learned features as the input to a neural network classifier for performing combustor anomaly detection. Since such deep learned features potentially better capture complex relations among all sensor measurements and the underlying combustor behavior than handcrafted features do, we expect the learned features can lead to a more accurate and robust anomaly detection. Using the data collected from a real-world gas turbine combustion system, we demonstrated that the proposed deep learning based anomaly detection significantly indeed improved combustor anomaly detection performance.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1908.09238.pdf'},\n",
              "      'pubDate': '2019-08-25',\n",
              "      'pubUpdateDate': '2019-08-25',\n",
              "      'scorecardStats': [{'citationCount': 93,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'ArXiv',\n",
              "       'MAG',\n",
              "       'Anansi',\n",
              "       'DBLP',\n",
              "       'Anansi'],\n",
              "      'title': 'On Accurate and Reliable Anomaly Detection for Gas Turbine Combustors: A Deep Learning Approach',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': 'This paper uses recently-developed deep learning in machine learning to hierarchically learn features from the sensor measurements of exhaust gas temperatures and uses the learned features as the input to a neural network classifier for performing combustor anomaly detection.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'}]}},\n",
              "  {'Page': {'N_Page': 3,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09115663.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2020.3001973'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://dspace5.zcu.cz/bitstream/11025/39669/1/Dezaki_Artificial_09115663.pdf'},\n",
              "       {'linkType': 'medline',\n",
              "        'url': 'https://www.ncbi.nlm.nih.gov/pubmed/34192103'}],\n",
              "      'authors': ['M. Jamshidi',\n",
              "       'A. Lalbakhsh',\n",
              "       'J. Talla',\n",
              "       'Z. Peroutka',\n",
              "       'F. Hadjilooei',\n",
              "       'Pedram Lalbakhsh',\n",
              "       'M. Jamshidi',\n",
              "       'L. Spada',\n",
              "       'M. Mirmozafari',\n",
              "       'Mojgan Dehghani',\n",
              "       'Asal Sabet',\n",
              "       'Saeed Roshani',\n",
              "       'S. Roshani',\n",
              "       'Nima Bayat-Makou',\n",
              "       'B. Mohamadzade',\n",
              "       'Zahra Malek',\n",
              "       'A. Jamshidi',\n",
              "       'S. Kiani',\n",
              "       'H. Hashemi-Dezaki',\n",
              "       'Wahab Mohyuddin'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 1.68,\n",
              "       'citationVelocity': 46.0,\n",
              "       'citedByBuckets': [{'count': 25, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 67, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 110.81691023699118,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 92,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 7,\n",
              "       'numReferences': 89,\n",
              "       'numViewableReferences': 89},\n",
              "      'entities': ['Artificial intelligence',\n",
              "       'Deep learning',\n",
              "       'Medical imaging',\n",
              "       'Artificial neural network',\n",
              "       'Generative adversarial networks',\n",
              "       'Long short-term memory',\n",
              "       'Bioinformatics',\n",
              "       'Usability',\n",
              "       'Rendering (computer graphics)',\n",
              "       'Triune continuum paradigm',\n",
              "       'Halting problem'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '2ceac7a1587a321eaba63b91607e70b71f8c90a6',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '109581-109595',\n",
              "       'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9115663'}],\n",
              "      'paperAbstract': 'COVID-19 outbreak has put the whole world in an unprecedented difficult situation bringing life around the world to a frightening halt and claiming thousands of lives. Due to COVID-19’s spread in 212 countries and territories and increasing numbers of infected cases and death tolls mounting to 5,212,172 and 334,915 (as of May 22 2020), it remains a real threat to the public health system. This paper renders a response to combat the virus through Artificial Intelligence (AI). Some Deep Learning (DL) methods have been illustrated to reach this goal, including Generative Adversarial Networks (GANs), Extreme Learning Machine (ELM), and Long/Short Term Memory (LSTM). It delineates an integrated bioinformatics approach in which different aspects of information from a continuum of structured and unstructured data sources are put together to form the user-friendly platforms for physicians and researchers. The main advantage of these AI-based platforms is to accelerate the process of diagnosis and treatment of the COVID-19 disease. The most recent related publications and medical reports were investigated with the purpose of choosing inputs and targets of the network that could facilitate reaching a reliable Artificial Neural Network-based tool for challenges associated with COVID-19. Furthermore, there are some specific inputs for each platform, including various forms of the data, such as clinical data and medical imaging which can improve the performance of the introduced approaches toward the best responses in practical applications.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9115663'},\n",
              "      'pubDate': '2020-06-12',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 92,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'Anansi',\n",
              "       'Medline',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'WHO',\n",
              "       'IEEE',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'Unpaywall'],\n",
              "      'title': 'Artificial Intelligence and COVID-19: Deep Learning Approaches for Diagnosis and Treatment',\n",
              "      'tldr': {'abstractSimilarityScore': 39,\n",
              "       'text': 'A response to combat the virus through Artificial Intelligence (AI) is rendered in which different aspects of information from a continuum of structured and unstructured data sources are put together to form the user-friendly platforms for physicians and researchers.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/08988271.pdf'},\n",
              "       {'linkType': 'anansi', 'url': 'http://export.arxiv.org/pdf/1901.08247'},\n",
              "       {'linkType': 'arxiv', 'url': 'https://arxiv.org/pdf/1901.08247.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2020.2972859'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://www.merl.com/publications/docs/TR2020-034.pdf'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://zsb87.github.io/paper/bearing_dl_review.pdf'}],\n",
              "      'authors': ['Shen Zhang', 'Shibo Zhang', 'B. Wang', 'T. Habetler'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.1282051282051282,\n",
              "       'citationVelocity': 28.0,\n",
              "       'citedByBuckets': [{'count': 11, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 39, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 34, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 79.13333473311248,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.011904761904761904,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 84,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 15,\n",
              "       'numReferences': 215,\n",
              "       'numViewableReferences': 215},\n",
              "      'entities': ['Machine learning',\n",
              "       'Deep learning',\n",
              "       'Artificial neural network',\n",
              "       'Principal component analysis',\n",
              "       'Support vector machine',\n",
              "       'Algorithm',\n",
              "       'Statistical classification',\n",
              "       'Performance',\n",
              "       'Data mining',\n",
              "       'Sensor',\n",
              "       'Feature extraction',\n",
              "       'Time series',\n",
              "       'Categorization',\n",
              "       'Open-source software'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '1f1819af398f6aaf29265d5ebb95ccd748bc0859',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '29857-29881',\n",
              "       'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8988271'}],\n",
              "      'paperAbstract': 'In this survey paper, we systematically summarize existing literature on bearing fault diagnostics with deep learning (DL) algorithms. While conventional machine learning (ML) methods, including artificial neural network, principal component analysis, support vector machines, etc., have been successfully applied to the detection and categorization of bearing faults for decades, recent developments in DL algorithms in the last five years have sparked renewed interest in both industry and academia for intelligent machine health monitoring. In this paper, we first provide a brief review of conventional ML methods, before taking a deep dive into the state-of-the-art DL algorithms for bearing fault applications. Specifically, the superiority of DL based methods are analyzed in terms of fault feature extraction and classification performances; many new functionalities enabled by DL techniques are also summarized. In addition, to obtain a more intuitive insight, a comparative study is conducted on the classification accuracy of different algorithms utilizing the open source Case Western Reserve University (CWRU) bearing dataset. Finally, to facilitate the transition on applying various DL algorithms to bearing fault diagnostics, detailed recommendations and suggestions are provided for specific application conditions. Future research directions to further enhance the performance of DL algorithms on health monitoring are also discussed.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8988271'},\n",
              "      'pubDate': '2019-01-24',\n",
              "      'pubUpdateDate': '2020-02-10',\n",
              "      'scorecardStats': [{'citationCount': 84,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'Unpaywall',\n",
              "       'ScienceParseMerged',\n",
              "       'ArXiv',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'MAG',\n",
              "       'IEEE',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG'],\n",
              "      'title': 'Deep Learning Algorithms for Bearing Fault Diagnosticsx—A Comprehensive Review',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'A brief review of conventional ML methods is provided, before taking a deep dive into the state-of-the-art DL algorithms for bearing fault applications and many new functionalities enabled by DL techniques are also summarized.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08727539.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2920326'}],\n",
              "      'authors': ['H. Karimipour',\n",
              "       'A. Dehghantanha',\n",
              "       'R. Parizi',\n",
              "       'K. Choo',\n",
              "       'H. Leung'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.425531914893617,\n",
              "       'citationVelocity': 27.0,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 7, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 47, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 27, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 97.98164666572218,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.012195121951219513,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 82,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 1,\n",
              "       'numReferences': 40,\n",
              "       'numViewableReferences': 40},\n",
              "      'entities': ['Anomaly detection',\n",
              "       'Feature extraction',\n",
              "       'Scalability',\n",
              "       'Machine learning',\n",
              "       'Sensitivity and specificity',\n",
              "       'Interaction',\n",
              "       'Simulation',\n",
              "       'Causal filter'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'e6d85c87c57b467c7141263670bf628839918729',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '80778-80788',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8727539'}],\n",
              "      'paperAbstract': 'Smart grid technology increases reliability, security, and efficiency of the electrical grids. However, its strong dependencies on digital communication technology bring up new vulnerabilities that need to be considered for efficient and reliable power distribution. In this paper, an unsupervised anomaly detection based on statistical correlation between measurements is proposed. The goal is to design a scalable anomaly detection engine suitable for large-scale smart grids, which can differentiate an actual fault from a disturbance and an intelligent cyber-attack. The proposed method applies feature extraction utilizing symbolic dynamic filtering (SDF) to reduce computational burden while discovering causal interactions between the subsystems. The simulation results on IEEE 39, 118, and 2848 bus systems verify the performance of the proposed method under different operation conditions. The results show an accuracy of 99%, true positive rate of 98%, and false positive rate of less than 2%',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8727539'},\n",
              "      'pubDate': '2019-05-31',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 82,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['IEEE', 'DBLP', 'MAG', 'Unpaywall', 'ScienceParseMerged'],\n",
              "      'title': 'A Deep and Scalable Unsupervised Machine Learning System for Cyber-Attack Detection in Large-Scale Smart Grids',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'The goal is to design a scalable anomaly detection engine suitable for large-scale smart grids, which can differentiate an actual fault from a disturbance and an intelligent cyber-attack.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Jonathon Byrd', 'Zachary Chase Lipton'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.14705882352941177,\n",
              "       'citationVelocity': 27.333333333333332,\n",
              "       'citedByBuckets': [{'count': 9, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 34, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 39, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 89.8253073767547,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.036585365853658534,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 82,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 7,\n",
              "       'numReferences': 35,\n",
              "       'numViewableReferences': 35},\n",
              "      'entities': ['Deep learning',\n",
              "       'Reinforcement learning',\n",
              "       'Machine learning',\n",
              "       'Causal inference',\n",
              "       'Importance sampling',\n",
              "       'Epoch (reference date)',\n",
              "       'Domain adaptation',\n",
              "       'Experiment',\n",
              "       'Dropout (neural networks)',\n",
              "       'Causal filter',\n",
              "       'Linear separability',\n",
              "       'Manifold regularization',\n",
              "       'Artificial neural network',\n",
              "       'Algorithm',\n",
              "       'Matrix regularization'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'b661520bf0061b7d96ccf12016e351dd3a6ee780',\n",
              "      'journal': {'pages': '872-881'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1812.03372.pdf'}],\n",
              "      'paperAbstract': 'Importance-weighted risk minimization is a key ingredient in many machine learning algorithms for causal inference, domain adaptation, class imbalance, and off-policy reinforcement learning. While the effect of importance weighting is well-characterized for low-capacity misspecified models, little is known about how it impacts over-parameterized, deep neural networks. This work is inspired by recent theoretical results showing that on (linearly) separable data, deep linear networks optimized by SGD learn weight-agnostic solutions, prompting us to ask, for realistic deep networks, for which many practical datasets are separable, what is the effect of importance weighting? We present the surprising finding that while importance weighting impacts models early in training, its effect diminishes over successive epochs. Moreover, while L2 regularization and batch normalization (but not dropout), restore some of the impact of importance weighting, they express the effect via (seemingly) the wrong abstraction: why should practitioners tweak the L2 regularization, and by how much, to produce the correct weighting effect? Our experiments confirm these findings across a range of architectures and datasets.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1812.03372.pdf'},\n",
              "      'pubDate': '2018-12-08',\n",
              "      'pubUpdateDate': '2019-05-24',\n",
              "      'scorecardStats': [{'citationCount': 82,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'MAG',\n",
              "       'ArXiv',\n",
              "       'DBLP',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG',\n",
              "       'MAG',\n",
              "       'ScienceParseMerged',\n",
              "       'ScienceParseMerged',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'What is the Effect of Importance Weighting in Deep Learning?',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'The surprising finding that while importance weighting impacts models early in training, its effect diminishes over successive epochs is presented.'},\n",
              "      'venue': 'ICML',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Senzhang Wang', 'Jiannong Cao', 'Philip S. Yu'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.2,\n",
              "       'citationVelocity': 27.333333333333332,\n",
              "       'citedByBuckets': [{'count': 5, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 35, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 42, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 75.23643585226563,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.012195121951219513,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 82,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 68,\n",
              "       'numReferences': 212,\n",
              "       'numViewableReferences': 212},\n",
              "      'entities': ['Deep learning',\n",
              "       'Data mining',\n",
              "       'Convolutional neural network',\n",
              "       'Recurrent neural network',\n",
              "       'Feature learning',\n",
              "       'Global Positioning System',\n",
              "       'Anomaly detection',\n",
              "       'Mobile device',\n",
              "       'Artificial neural network',\n",
              "       'Statistical classification',\n",
              "       'Machine learning',\n",
              "       'Social network',\n",
              "       'Environmental resource management',\n",
              "       'Predictive learning',\n",
              "       'Categorization'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'a54c647f6db73621ec496ea86355726161c0898d',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1906.04928'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1906.04928.pdf'}],\n",
              "      'paperAbstract': 'With the fast development of various positioning techniques such as Global Position System (GPS), mobile devices and remote sensing, spatio-temporal data has become increasingly available nowadays. Mining valuable knowledge from spatio-temporal data is critically important to many real world applications including human mobility understanding, smart transportation, urban planning, public safety, health care and environmental management. As the number, volume and resolution of spatio-temporal datasets increase rapidly, traditional data mining methods, especially statistics based methods for dealing with such data are becoming overwhelmed. Recently, with the advances of deep learning techniques, deep leaning models such as convolutional neural network (CNN) and recurrent neural network (RNN) have enjoyed considerable success in various machine learning tasks due to their powerful hierarchical feature learning ability in both spatial and temporal domains, and have been widely applied in various spatio-temporal data mining (STDM) tasks such as predictive learning, representation learning, anomaly detection and classification. In this paper, we provide a comprehensive survey on recent progress in applying deep learning techniques for STDM. We first categorize the types of spatio-temporal data and briefly introduce the popular deep learning models that are used in STDM. Then a framework is introduced to show a general pipeline of the utilization of deep learning models for STDM. Next we classify existing literatures based on the types of ST data, the data mining tasks, and the deep learning models, followed by the applications of deep learning for STDM in different domains including transportation, climate science, human mobility, location based social network, crime analysis, and neuroscience. Finally, we conclude the limitations of current research and point out future research directions.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1906.04928.pdf'},\n",
              "      'pubDate': '2019-06-11',\n",
              "      'pubUpdateDate': '2019-06-24',\n",
              "      'scorecardStats': [{'citationCount': 82,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'ArXiv',\n",
              "       'DBLP',\n",
              "       'Unpaywall',\n",
              "       'MAG',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged'],\n",
              "      'title': 'Deep Learning for Spatio-Temporal Data Mining: A Survey',\n",
              "      'tldr': {'abstractSimilarityScore': 46,\n",
              "       'text': 'A comprehensive survey on recent progress in applying deep learning techniques for STDM is provided and existing literatures are classified based on the types of spatio-temporal data, the data mining tasks, and the deep learning models.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/08938741.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2961372'}],\n",
              "      'authors': ['Sudeep Tanwar',\n",
              "       'Qasim Bhatia',\n",
              "       'P. Patel',\n",
              "       'Aparna Kumari',\n",
              "       'P. Singh',\n",
              "       'Wei-Chiang Hong'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.24242424242424243,\n",
              "       'citationVelocity': 37.0,\n",
              "       'citedByBuckets': [{'count': 33, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 41, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 103.91836684908438,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 74,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 5,\n",
              "       'numReferences': 66,\n",
              "       'numViewableReferences': 66},\n",
              "      'entities': ['Machine learning',\n",
              "       'Unmanned aerial vehicle',\n",
              "       'Long short-term memory',\n",
              "       'Convolutional neural network',\n",
              "       'Deep learning',\n",
              "       'Data security',\n",
              "       'Double-spending',\n",
              "       'Support vector machine',\n",
              "       'Privacy',\n",
              "       'Database',\n",
              "       'Bootstrap aggregating',\n",
              "       'Smart city',\n",
              "       'Emergence',\n",
              "       'Cluster analysis',\n",
              "       'Bitcoin',\n",
              "       'Replication (computing)',\n",
              "       'Algorithm'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '68abf193387b31cfa709e94385e852c5729957fb',\n",
              "      'journal': {'name': 'IEEE Access', 'pages': '474-488', 'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8938741'}],\n",
              "      'paperAbstract': 'In recent years, the emergence of blockchain technology (BT) has become a unique, most disruptive, and trending technology. The decentralized database in BT emphasizes data security and privacy. Also, the consensus mechanism in it makes sure that data is secured and legitimate. Still, it raises new security issues such as majority attack and double-spending. To handle the aforementioned issues, data analytics is required on blockchain based secure data. Analytics on these data raises the importance of arisen technology Machine Learning (ML). ML involves the rational amount of data to make precise decisions. Data reliability and its sharing are very crucial in ML to improve the accuracy of results. The combination of these two technologies (ML and BT) can provide highly precise results. In this paper, we present a detailed study on ML adoption for making BT-based smart applications more resilient against attacks. There are various traditional ML techniques, for instance, Support Vector Machines (SVM), clustering, bagging, and Deep Learning (DL) algorithms such as Convolutional Neural Network (CNN) and Long short-term memory (LSTM) can be used to analyse the attacks on a blockchain-based network. Further, we include how both the technologies can be applied in several smart applications such as Unmanned Aerial Vehicle (UAV), Smart Grid (SG), healthcare, and smart cities. Then, future research issues and challenges are explored. At last, a case study is presented with a conclusion.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8938741'},\n",
              "      'pubDate': None,\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 74,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['IEEE',\n",
              "       'Unpaywall',\n",
              "       'Crossref',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP'],\n",
              "      'title': 'Machine Learning Adoption in Blockchain-Based Smart Applications: The Challenges, and a Way Forward',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'A detailed study on ML adoption for making BT-based smart applications more resilient against attacks and how both the technologies can be applied in several smart applications such as Unmanned Aerial Vehicle (UAV), Smart Grid (SG), healthcare, and smart cities.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Ning Xie', 'Gabrielle Ras', 'M. V. Gerven', 'Derek Doran'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 1.3333333333333333,\n",
              "       'citationVelocity': 30.0,\n",
              "       'citedByBuckets': [{'count': 18, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 42, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 67.73823916515217,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.05,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 60,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 49,\n",
              "       'numReferences': 278,\n",
              "       'numViewableReferences': 278},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'f1321f2df5bc686d3adfba8eae06a6c12cb88ef8',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2004.14545'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2004.14545.pdf'}],\n",
              "      'paperAbstract': 'Deep neural network (DNN) is an indispensable machine learning tool for achieving human-level performance on many learning tasks. Yet, due to its black-box nature, it is inherently difficult to understand which aspects of the input data drive the decisions of the network. There are various real-world scenarios in which humans need to make actionable decisions based on the output DNNs. Such decision support systems can be found in critical domains, such as legislation, law enforcement, etc. It is important that the humans making high-level decisions can be sure that the DNN decisions are driven by combinations of data features that are appropriate in the context of the deployment of the decision support system and that the decisions made are legally or ethically defensible. Due to the incredible pace at which DNN technology is being developed, the development of new methods and studies on explaining the decision-making process of DNNs has blossomed into an active research field. A practitioner beginning to study explainable deep learning may be intimidated by the plethora of orthogonal directions the field is taking. This complexity is further exacerbated by the general confusion that exists in defining what it means to be able to explain the actions of a deep learning system and to evaluate a system\\'s \"ability to explain\". To alleviate this problem, this article offers a \"field guide\" to deep learning explainability for those uninitiated in the field. The field guide: i) Discusses the traits of a deep learning system that researchers enhance in explainability research, ii) places explainability in the context of other related deep learning research areas, and iii) introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning. The guide is designed as an easy-to-digest starting point for those just embarking in the field.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2004.14545.pdf'},\n",
              "      'pubDate': '2020-04-30',\n",
              "      'pubUpdateDate': '2021-09-13',\n",
              "      'scorecardStats': [{'citationCount': 60,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG',\n",
              "       'ArXiv',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'Explainable Deep Learning: A Field Guide for the Uninitiated',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'A \"field guide\" to deep learning explainability for those uninitiated in the field, which discusses the traits of a deep learning system that researchers enhance in explainability research, and introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['A. Shoeibi',\n",
              "       'Marjane Khodatars',\n",
              "       'R. Alizadehsani',\n",
              "       'Navid Ghassemi',\n",
              "       'M. Jafari',\n",
              "       'Parisa Moridian',\n",
              "       'Ali Khadem',\n",
              "       'Delaram Sadeghi',\n",
              "       'Sadiq Hussain',\n",
              "       'A. Zare',\n",
              "       'Z. Sani',\n",
              "       'J. Bazeli',\n",
              "       'F. Khozeimeh',\n",
              "       'A. Khosravi',\n",
              "       'S. Nahavandi',\n",
              "       'U. Acharya',\n",
              "       'Peng Shi'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 1.8666666666666667,\n",
              "       'citationVelocity': 29.0,\n",
              "       'citedByBuckets': [{'count': 15, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 43, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 64.11911747039355,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.017241379310344827,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 58,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 10,\n",
              "       'numReferences': 193,\n",
              "       'numViewableReferences': 193},\n",
              "      'entities': ['Deep learning',\n",
              "       'Receiver operating characteristic',\n",
              "       'Computer engineering',\n",
              "       'Database',\n",
              "       'Sensitivity and specificity',\n",
              "       'Artificial intelligence',\n",
              "       'Jaccard index',\n",
              "       'Machine learning',\n",
              "       'Electrical engineering',\n",
              "       'F1 score',\n",
              "       'System administrator',\n",
              "       'Film-type patterned retarder',\n",
              "       'Feature selection',\n",
              "       'CT scan',\n",
              "       'Feature extraction',\n",
              "       'Ground truth',\n",
              "       'X-Ray (Amazon Kindle)',\n",
              "       'Negative feedback',\n",
              "       'Sørensen–Dice coefficient',\n",
              "       'Statistical classification',\n",
              "       'Informatics',\n",
              "       'Twisted nematic field effect',\n",
              "       'Data acquisition',\n",
              "       'Tomography',\n",
              "       'Email'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Engineering'],\n",
              "      'githubReferences': [],\n",
              "      'id': '08597b34ad2a8760713437fbe0733045b16f089b',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2007.10785'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2007.10785.pdf'}],\n",
              "      'paperAbstract': 'Coronavirus, or COVID-19, is a hazardous disease that has endangered the health of many people around the world by directly affecting the lungs. COVID-19 is a medium-sized, coated virus with a single-stranded RNA. This virus has one of the largest RNA genomes and is approximately 120 nm. The X-Ray and computed tomography (CT) imaging modalities are widely used to obtain a fast and accurate medical diagnosis. Identifying COVID-19 from these medical images is extremely challenging as it is time-consuming, demanding, and prone to human errors. Hence, artificial intelligence (AI) methodologies can be used to obtain consistent high performance. Among the AI methodologies, deep learning (DL) networks have gained much popularity compared to traditional machine learning (ML) methods. Unlike ML techniques, all stages of feature extraction, feature selection, and classification are accomplished automatically in DL models. In this paper, a complete survey of studies on the application of DL techniques for COVID-19 diagnostic and automated segmentation of lungs is discussed, concentrating on works that used X-Ray and CT images. Additionally, a review of papers on the forecasting of coronavirus prevalence in different parts of the world with DL techniques is presented. Lastly, the challenges faced in the automated detection of COVID-19 using DL techniques and directions for future research are discussed.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2007.10785.pdf'},\n",
              "      'pubDate': '2020-07-16',\n",
              "      'pubUpdateDate': '2020-07-27',\n",
              "      'scorecardStats': [{'citationCount': 58,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv',\n",
              "       'DBLP'],\n",
              "      'title': 'Automated Detection and Forecasting of COVID-19 using Deep Learning Techniques: A Review',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'A complete survey of studies on the application of DL techniques for COVID-19 diagnostic and automated segmentation of lungs is discussed, concentrating on works that used X-Ray and CT images.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08732985.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2921578'}],\n",
              "      'authors': ['Q. Tao', 'F. Liu', 'Y. Li', 'D. Sidorov'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.16666666666666666,\n",
              "       'citationVelocity': 19.333333333333332,\n",
              "       'citedByBuckets': [{'count': 6, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 24, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 28, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 37.02157349509826,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.05172413793103448,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 58,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 17,\n",
              "       'numViewableReferences': 17},\n",
              "      'entities': ['Deep learning',\n",
              "       'Convolutional neural network',\n",
              "       'Machine learning',\n",
              "       'Artificial neural network'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '82a32d99b23afabc552d80be0ebcf2302ef66cc3',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '76690-76698',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8732985'}],\n",
              "      'paperAbstract': 'Air pollution forecasting can provide reliable information about the future pollution situation, which is useful for an efficient operation of air pollution control and helps to plan for prevention. Dynamics of air pollution are usually reflected by various factors, such as the temperature, humidity, wind direction, wind speed, snowfall, rainfall, and so on, which increase the difficulty in understanding the change of air pollutant concentration. In this paper, a short-term forecasting model based on deep learning is proposed for PM2.5 (particulate matter with an aerodynamic diameter less than or equal to $2.5~\\\\mu \\\\text{m}$ ) concentration, and the convolutional-based bidirectional gated recurrent unit (CBGRU) method is presented, which combines 1D convnets (convolutional neural networks) and bidirectional GRU (gated recurrent unit) neural networks. The case is carried out by using the Beijing PM2.5 data set in UCI Machine Learning Repository. Comparing the prediction results with the traditional ones, it is proved that the error of the CBGRU model is lower and the prediction performance is better.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8732985'},\n",
              "      'pubDate': '2019-06-07',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 58,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG', 'DBLP', 'IEEE', 'Unpaywall', 'ScienceParseMerged'],\n",
              "      'title': 'Air Pollution Forecasting Using a Deep Learning Model Based on 1D Convnets and Bidirectional GRU',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': 'A short-term forecasting model based on deep learning is proposed for PM2.5 concentration and it is proved that the error of the CBGRU model is lower and the prediction performance is better.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Neil C Thompson',\n",
              "       'Kristjan H. Greenewald',\n",
              "       'Keeheon Lee',\n",
              "       'Gabriel F. Manso'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 1.5625,\n",
              "       'citationVelocity': 28.5,\n",
              "       'citedByBuckets': [{'count': 16, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 41, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 44.65009136999255,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.017543859649122806,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 57,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 10,\n",
              "       'numReferences': 107,\n",
              "       'numViewableReferences': 107},\n",
              "      'entities': ['Deep learning',\n",
              "       'Computation',\n",
              "       'Computer vision',\n",
              "       'Speech recognition',\n",
              "       'Machine learning',\n",
              "       'Extrapolation',\n",
              "       'Humans'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '5712e681ae68abfeee7924061de27475bb801f56',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2007.05558'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2007.05558.pdf'}],\n",
              "      'paperAbstract': \"Deep learning's recent history has been one of achievement: from triumphing over humans in the game of Go to world-leading performance in image recognition, voice recognition, translation, and other tasks. But this progress has come with a voracious appetite for computing power. This article reports on the computational demands of Deep Learning applications in five prominent application areas and shows that progress in all five is strongly reliant on increases in computing power. Extrapolating forward this reliance reveals that progress along current lines is rapidly becoming economically, technically, and environmentally unsustainable. Thus, continued progress in these applications will require dramatically more computationally-efficient methods, which will either have to come from changes to deep learning or from moving to other machine learning methods.\",\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2007.05558.pdf'},\n",
              "      'pubDate': '2020-07-10',\n",
              "      'pubUpdateDate': '2020-07-10',\n",
              "      'scorecardStats': [{'citationCount': 57,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'ArXiv',\n",
              "       'Anansi',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP'],\n",
              "      'title': 'The Computational Limits of Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 39,\n",
              "       'text': 'It is shown that progress in all five prominent application areas is strongly reliant on increases in computing power, and that progress along current lines is rapidly becoming economically, technically, and environmentally unsustainable.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'}]}},\n",
              "  {'Page': {'N_Page': 4,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08613773.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2892795'}],\n",
              "      'authors': ['Zhiqiong Wang',\n",
              "       'Mo Li',\n",
              "       'Huaxia Wang',\n",
              "       'Hanyu Jiang',\n",
              "       'Yu-dong Yao',\n",
              "       'Hao Zhang',\n",
              "       'Junchang Xin'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.125,\n",
              "       'citationVelocity': 19.0,\n",
              "       'citedByBuckets': [{'count': 6, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 24, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 27, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 138.74318564533417,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.05263157894736842,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 57,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 38,\n",
              "       'numViewableReferences': 38},\n",
              "      'entities': ['Convolutional neural network',\n",
              "       'Computer-aided design',\n",
              "       'Artificial neural network',\n",
              "       'Experiment',\n",
              "       'Cluster analysis'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '8a74c98896b57626324520741cb172013421d6f6',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '105146-105158',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8613773'}],\n",
              "      'paperAbstract': 'A computer-aided diagnosis (CAD) system based on mammograms enables early breast cancer detection, diagnosis, and treatment. However, the accuracy of the existing CAD systems remains unsatisfactory. This paper explores a breast CAD method based on feature fusion with convolutional neural network (CNN) deep features. First, we propose a mass detection method based on CNN deep features and unsupervised extreme learning machine (ELM) clustering. Second, we build a feature set fusing deep features, morphological features, texture features, and density features. Third, an ELM classifier is developed using the fused feature set to classify benign and malignant breast masses. Extensive experiments demonstrate the accuracy and efficiency of our proposed mass detection and breast cancer classification method.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8613773'},\n",
              "      'pubDate': '2019-01-16',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 57,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ScienceParseMerged', 'IEEE', 'MAG', 'DBLP', 'Unpaywall'],\n",
              "      'title': 'Breast Cancer Detection Using Extreme Learning Machine Based on Feature Fusion With CNN Deep Features',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'This paper proposes a mass detection method based on CNN deep features and unsupervised extreme learning machine (ELM) clustering and builds a feature set fusing deep features, morphological features, texture features, and density features.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['P. Burlina', 'S. Billings', 'N. Joshi', 'J. Albayda'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.3157894736842105,\n",
              "       'citationVelocity': 15.0,\n",
              "       'citedByBuckets': [{'count': 11, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 13, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 19, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 13, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 76.00029355141014,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.017857142857142856,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 56,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 59,\n",
              "       'numViewableReferences': 59},\n",
              "      'entities': ['Inclusion Body Myositis (disorder)',\n",
              "       'Polymyositis',\n",
              "       'Myopathy',\n",
              "       'Learning Disorders',\n",
              "       'Scrippsiella aff. hangoei Mc-Neil A',\n",
              "       'Classification',\n",
              "       'Hemoglobin Sunshine Seth',\n",
              "       'Chromodoris joshi',\n",
              "       'Diagnosis, clinical',\n",
              "       'Neural Network Simulation',\n",
              "       'Dermatomyositis',\n",
              "       'Platelet Glycoprotein 4, human',\n",
              "       'Inclusion Bodies',\n",
              "       'Standard deviation',\n",
              "       'Muscle'],\n",
              "      'entityRelations': [{'destEntityId': '19241',\n",
              "        'destEntityName': 'Polymyositis',\n",
              "        'destEntitySlug': 'Polymyositis',\n",
              "        'mentionContexts': ['Eighty subjects comprised of 19 with inclusion body myositis ( IBM ) , 14 with <e2>polymyositis</e2> ( PM ) , 14 with <e1>dermatomyositis</e1> ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .'],\n",
              "        'mentionTexts': [['dermatomyositis', 'polymyositis']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_child_of'},\n",
              "        'srcEntityId': '121566',\n",
              "        'srcEntityName': 'Dermatomyositis',\n",
              "        'srcEntitySlug': 'Dermatomyositis'},\n",
              "       {'destEntityId': '19241',\n",
              "        'destEntityName': 'Polymyositis',\n",
              "        'destEntitySlug': 'Polymyositis',\n",
              "        'mentionContexts': ['Eighty subjects comprised of 19 with inclusion body myositis ( IBM ) , 14 with <e2>polymyositis</e2> ( PM ) , 14 with <e1>dermatomyositis</e1> ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .'],\n",
              "        'mentionTexts': [['dermatomyositis', 'polymyositis']],\n",
              "        'relationshipSubtype': 'clinically_similar',\n",
              "        'relationshipType': {'id': 'is_similar_to'},\n",
              "        'srcEntityId': '121566',\n",
              "        'srcEntityName': 'Dermatomyositis',\n",
              "        'srcEntitySlug': 'Dermatomyositis'},\n",
              "       {'destEntityId': '121566',\n",
              "        'destEntityName': 'Dermatomyositis',\n",
              "        'destEntitySlug': 'Dermatomyositis',\n",
              "        'mentionContexts': ['Eighty subjects comprised of 19 with inclusion body myositis ( IBM ) , 14 with <e1>polymyositis</e1> ( PM ) , 14 with <e2>dermatomyositis</e2> ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .'],\n",
              "        'mentionTexts': [['polymyositis', 'dermatomyositis']],\n",
              "        'relationshipSubtype': 'clinically_similar',\n",
              "        'relationshipType': {'id': 'is_similar_to'},\n",
              "        'srcEntityId': '19241',\n",
              "        'srcEntityName': 'Polymyositis',\n",
              "        'srcEntitySlug': 'Polymyositis'},\n",
              "       {'destEntityId': '19241',\n",
              "        'destEntityName': 'Polymyositis',\n",
              "        'destEntitySlug': 'Polymyositis',\n",
              "        'mentionContexts': ['Eighty subjects comprised of 19 with inclusion body myositis ( IBM ) , 14 with <e2>polymyositis</e2> ( PM ) , 14 with <e1>dermatomyositis</e1> ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .'],\n",
              "        'mentionTexts': [['dermatomyositis', 'polymyositis']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_sibling_of'},\n",
              "        'srcEntityId': '121566',\n",
              "        'srcEntityName': 'Dermatomyositis',\n",
              "        'srcEntitySlug': 'Dermatomyositis'},\n",
              "       {'destEntityId': '121566',\n",
              "        'destEntityName': 'Dermatomyositis',\n",
              "        'destEntitySlug': 'Dermatomyositis',\n",
              "        'mentionContexts': ['Eighty subjects comprised of 19 with inclusion body myositis ( IBM ) , 14 with <e1>polymyositis</e1> ( PM ) , 14 with <e2>dermatomyositis</e2> ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .'],\n",
              "        'mentionTexts': [['polymyositis', 'dermatomyositis']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_sibling_of'},\n",
              "        'srcEntityId': '19241',\n",
              "        'srcEntityName': 'Polymyositis',\n",
              "        'srcEntitySlug': 'Polymyositis'},\n",
              "       {'destEntityId': '121566',\n",
              "        'destEntityName': 'Dermatomyositis',\n",
              "        'destEntitySlug': 'Dermatomyositis',\n",
              "        'mentionContexts': ['Eighty subjects comprised of 19 with inclusion body myositis ( IBM ) , 14 with <e1>polymyositis</e1> ( PM ) , 14 with <e2>dermatomyositis</e2> ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .'],\n",
              "        'mentionTexts': [['polymyositis', 'dermatomyositis']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_broader_than'},\n",
              "        'srcEntityId': '19241',\n",
              "        'srcEntityName': 'Polymyositis',\n",
              "        'srcEntitySlug': 'Polymyositis'},\n",
              "       {'destEntityId': '22416',\n",
              "        'destEntityName': 'Inclusion Body Myositis (disorder)',\n",
              "        'destEntitySlug': 'Inclusion-Body-Myositis-(disorder)',\n",
              "        'mentionContexts': ['Eighty subjects comprised of 19 with inclusion body myositis ( <e2>IBM</e2> ) , 14 with <e1>polymyositis</e1> ( PM ) , 14 with dermatomyositis ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .',\n",
              "         'Eighty subjects comprised of 19 with <e2>inclusion body myositis</e2> ( IBM ) , 14 with <e1>polymyositis</e1> ( PM ) , 14 with dermatomyositis ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .'],\n",
              "        'mentionTexts': [['polymyositis', 'IBM'],\n",
              "         ['polymyositis', 'inclusion body myositis']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_sibling_of'},\n",
              "        'srcEntityId': '19241',\n",
              "        'srcEntityName': 'Polymyositis',\n",
              "        'srcEntitySlug': 'Polymyositis'},\n",
              "       {'destEntityId': '19241',\n",
              "        'destEntityName': 'Polymyositis',\n",
              "        'destEntitySlug': 'Polymyositis',\n",
              "        'mentionContexts': ['Eighty subjects comprised of 19 with inclusion body myositis ( <e1>IBM</e1> ) , 14 with <e2>polymyositis</e2> ( PM ) , 14 with dermatomyositis ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .',\n",
              "         'Eighty subjects comprised of 19 with <e1>inclusion body myositis</e1> ( IBM ) , 14 with <e2>polymyositis</e2> ( PM ) , 14 with dermatomyositis ( DM ) , and 33 normal ( N ) subjects were included in this study , where 3214 muscle ultrasound images of 7 muscles ( observed bilaterally ) were acquired .'],\n",
              "        'mentionTexts': [['IBM', 'polymyositis'],\n",
              "         ['inclusion body myositis', 'polymyositis']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_sibling_of'},\n",
              "        'srcEntityId': '22416',\n",
              "        'srcEntityName': 'Inclusion Body Myositis (disorder)',\n",
              "        'srcEntitySlug': 'Inclusion-Body-Myositis-(disorder)'}],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Medicine'],\n",
              "      'githubReferences': [],\n",
              "      'id': '7fd75610f9714c08a59ba2708fb0ae9d9cbea0e6',\n",
              "      'journal': {'name': 'PLoS ONE', 'volume': '12'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/7fd7/5610f9714c08a59ba2708fb0ae9d9cbea0e6.pdf'}],\n",
              "      'paperAbstract': 'Objective To evaluate the use of ultrasound coupled with machine learning (ML) and deep learning (DL) techniques for automated or semi-automated classification of myositis. Methods Eighty subjects comprised of 19 with inclusion body myositis (IBM), 14 with polymyositis (PM), 14 with dermatomyositis (DM), and 33 normal (N) subjects were included in this study, where 3214 muscle ultrasound images of 7 muscles (observed bilaterally) were acquired. We considered three problems of classification including (A) normal vs. affected (DM, PM, IBM); (B) normal vs. IBM patients; and (C) IBM vs. other types of myositis (DM or PM). We studied the use of an automated DL method using deep convolutional neural networks (DL-DCNNs) for diagnostic classification and compared it with a semi-automated conventional ML method based on random forests (ML-RF) and “engineered” features. We used the known clinical diagnosis as the gold standard for evaluating performance of muscle classification. Results The performance of the DL-DCNN method resulted in accuracies ± standard deviation of 76.2% ± 3.1% for problem (A), 86.6% ± 2.4% for (B) and 74.8% ± 3.9% for (C), while the ML-RF method led to accuracies of 72.3% ± 3.3% for problem (A), 84.3% ± 2.3% for (B) and 68.9% ± 2.5% for (C). Conclusions This study demonstrates the application of machine learning methods for automatically or semi-automatically classifying inflammatory muscle disease using muscle ultrasound. Compared to the conventional random forest machine learning method used here, which has the drawback of requiring manual delineation of muscle/fat boundaries, DCNN-based classification by and large improved the accuracies in all classification problems while providing a fully automated approach to classification.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/7fd7/5610f9714c08a59ba2708fb0ae9d9cbea0e6.pdf'},\n",
              "      'pubDate': '2017-08-30',\n",
              "      'pubUpdateDate': '2017-08-30',\n",
              "      'scorecardStats': [{'citationCount': 56,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Medline',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG',\n",
              "       'PubMedCentral',\n",
              "       'Unpaywall'],\n",
              "      'title': 'Automated diagnosis of myositis from muscle ultrasound: Exploring the use of machine learning and deep learning methods',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'Compared to the conventional random forest machine learning method used here, which has the drawback of requiring manual delineation of muscle/fat boundaries, DCNN-based classification by and large improved the accuracies in all classification problems while providing a fully automated approach to classification.'},\n",
              "      'venue': 'PloS one',\n",
              "      'videos': [],\n",
              "      'year': '2017'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08807125.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2936564'}],\n",
              "      'authors': ['Hakan Gunduz'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.12,\n",
              "       'citationVelocity': 18.333333333333332,\n",
              "       'citedByBuckets': [{'count': 2, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 25, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 28, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 48.9441303733834,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.09090909090909091,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 55,\n",
              "       'numKeyCitations': 5,\n",
              "       'numKeyReferences': 9,\n",
              "       'numReferences': 44,\n",
              "       'numViewableReferences': 44},\n",
              "      'entities': ['Convolution',\n",
              "       'Deep learning',\n",
              "       'Matthews correlation coefficient',\n",
              "       'Feature model',\n",
              "       'Convolutional neural network',\n",
              "       'Machine learning',\n",
              "       'Performance',\n",
              "       'Microsoft Forefront'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '9486aa1489470905898ea35f9ef9f3853a28ba3a',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '115540-115551',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8807125'}],\n",
              "      'paperAbstract': 'Parkinson’s Disease (PD) is a progressive neurodegenerative disease with multiple motor and non-motor characteristics. PD patients commonly face vocal impairments during the early stages of the disease. So, diagnosis systems based on vocal disorders are at the forefront on recent PD detection studies. Our study proposes two frameworks based on Convolutional Neural Networks to classify Parkinson’s Disease (PD) using sets of vocal (speech) features. Although, both frameworks are employed for the combination of various feature sets, they have difference in terms of combining feature sets. While the first framework combines different feature sets before given to 9-layered CNN as inputs, whereas the second framework passes feature sets to the parallel input layers which are directly connected to convolution layers. Thus, deep features from each parallel branch are extracted simultaneously before combining in the merge layer. Proposed models are trained with dataset taken from UCI Machine Learning repository and their performances are validated with Leave-One-Person-Out Cross Validation (LOPO CV). Due to imbalanced class distribution in our data, F-Measure and Matthews Correlation Coefficient metrics are used for the assessment along with accuracy. Experimental results show that the second framework seems to be very promising, since it is able to learn deep features from each feature set via parallel convolution layers. Extracted deep features are not only successful at distinguishing PD patients from healthy individuals but also effective in boosting up the discriminative power of the classifiers.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8807125'},\n",
              "      'pubDate': '2019-08-20',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 55,\n",
              "        'keyCitationCount': 5,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'Unpaywall', 'IEEE', 'ScienceParseMerged', 'MAG'],\n",
              "      'title': 'Deep Learning-Based Parkinson’s Disease Classification Using Vocal Feature Sets',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'Experimental results show that the second framework seems to be very promising, since it is able to learn deep features from each feature set via parallel convolution layers, which are successful at distinguishing PD patients from healthy individuals and effective in boosting up the discriminative power of the classifiers.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Li Yang', 'A. Shami'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 2.727272727272727,\n",
              "       'citationVelocity': 26.0,\n",
              "       'citedByBuckets': [{'count': 11, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 41, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 60.11760721769868,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.07692307692307693,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 52,\n",
              "       'numKeyCitations': 4,\n",
              "       'numKeyReferences': 13,\n",
              "       'numReferences': 176,\n",
              "       'numViewableReferences': 176},\n",
              "      'entities': ['Machine learning',\n",
              "       'Mathematical optimization',\n",
              "       'Algorithm',\n",
              "       'Experiment',\n",
              "       'Library (computing)',\n",
              "       'Benchmark (computing)',\n",
              "       'Optimization problem'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '2e5d2f2dc01b150dffc163a9f457848e9b5b5c38',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2007.15745'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2007.15745.pdf'}],\n",
              "      'paperAbstract': 'Abstract Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the model’s performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter optimization problems are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2007.15745.pdf'},\n",
              "      'pubDate': '2020-07-30',\n",
              "      'pubUpdateDate': '2020-11-20',\n",
              "      'scorecardStats': [{'citationCount': 52,\n",
              "        'keyCitationCount': 4,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'ArXiv',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'Crossref',\n",
              "       'Anansi',\n",
              "       'Unpaywall',\n",
              "       'MAG'],\n",
              "      'title': 'On Hyperparameter Optimization of Machine Learning Algorithms: Theory and Practice',\n",
              "      'tldr': {'abstractSimilarityScore': 49,\n",
              "       'text': 'This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively and introducing several state-of-the-art optimization techniques.'},\n",
              "      'venue': 'Neurocomputing',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Maithra Raghu', 'Erica Schmidt'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.14814814814814814,\n",
              "       'citationVelocity': 17.0,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 27, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 23, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 35.761741363978295,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 51,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 7,\n",
              "       'numReferences': 296,\n",
              "       'numViewableReferences': 296},\n",
              "      'entities': ['Deep learning',\n",
              "       'Machine learning',\n",
              "       'File spanning',\n",
              "       'Pipeline (computing)',\n",
              "       'Artificial neural network',\n",
              "       'Graph (abstract data type)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'BLOG'}, 'count': 1},\n",
              "       {'contentType': {'id': 'NEWS'}, 'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '70acb0ee229593fffe73885f3004f24df38f74ec',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2003.11755'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2003.11755.pdf'}],\n",
              "      'paperAbstract': 'Over the past few years, we have seen fundamental breakthroughs in core problems in machine learning, largely driven by advances in deep neural networks. At the same time, the amount of data collected in a wide array of scientific domains is dramatically increasing in both size and complexity. Taken together, this suggests many exciting opportunities for deep learning applications in scientific settings. But a significant challenge to this is simply knowing where to start. The sheer breadth and diversity of different deep learning techniques makes it difficult to determine what scientific problems might be most amenable to these methods, or which specific combination of methods might offer the most promising first approach. In this survey, we focus on addressing this central issue, providing an overview of many widely used deep learning models, spanning visual, sequential and graph structured data, associated tasks and different training methods, along with techniques to use deep learning with less data and better interpret these complex models --- two central considerations for many scientific use cases. We also include overviews of the full design process, implementation tips, and links to a plethora of tutorials, research summaries and open-sourced deep learning pipelines and pretrained models, developed by the community. We hope that this survey will help accelerate the use of deep learning across different scientific domains.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2003.11755.pdf'},\n",
              "      'pubDate': '2020-03-26',\n",
              "      'pubUpdateDate': '2020-03-26',\n",
              "      'scorecardStats': [{'citationCount': 51,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'ArXiv',\n",
              "       'Anansi'],\n",
              "      'title': 'A Survey of Deep Learning for Scientific Discovery',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'This survey provides an overview of many widely used deep learning models, spanning visual, sequential and graph structured data, associated tasks and different training methods, along with techniques to use deep learning with less data and better interpret these complex models --- two central considerations for many scientific use cases.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Xinyu Li', 'Yuanxin He', 'Xiaojun Jing'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.15,\n",
              "       'citationVelocity': 16.0,\n",
              "       'citedByBuckets': [{'count': 5, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 20, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 23, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 53.1896908159655,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.041666666666666664,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 48,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 9,\n",
              "       'numReferences': 106,\n",
              "       'numViewableReferences': 106},\n",
              "      'entities': ['Deep learning',\n",
              "       'Activity recognition',\n",
              "       'Radar',\n",
              "       'Human–computer interaction',\n",
              "       'Feature extraction',\n",
              "       'Feature learning',\n",
              "       'Machine learning',\n",
              "       'Privacy',\n",
              "       'High- and low-level',\n",
              "       'Heuristic',\n",
              "       'Sensor',\n",
              "       'MinEd',\n",
              "       'Map',\n",
              "       'Contactless smart card'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Geology'],\n",
              "      'githubReferences': [],\n",
              "      'id': '3cb50209b0c77656b7621d553fb48dc84d52cc41',\n",
              "      'journal': {'name': 'Remote. Sens.', 'pages': '1068', 'volume': '11'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/3cb5/0209b0c77656b7621d553fb48dc84d52cc41.pdf'}],\n",
              "      'paperAbstract': 'Radar, as one of the sensors for human activity recognition (HAR), has unique characteristics such as privacy protection and contactless sensing. Radar-based HAR has been applied in many fields such as human–computer interaction, smart surveillance and health assessment. Conventional machine learning approaches rely on heuristic hand-crafted feature extraction, and their generalization capability is limited. Additionally, extracting features manually is time–consuming and inefficient. Deep learning acts as a hierarchical approach to learn high-level features automatically and has achieved superior performance for HAR. This paper surveys deep learning based HAR in radar from three aspects: deep learning techniques, radar systems, and deep learning for radar-based HAR. Especially, we elaborate deep learning approaches designed for activity recognition in radar according to the dimension of radar returns (i.e., 1D, 2D and 3D echoes). Due to the difference of echo forms, corresponding deep learning approaches are different to fully exploit motion information. Experimental results have demonstrated the feasibility of applying deep learning for radar-based HAR in 1D, 2D and 3D echoes. Finally, we address some current research considerations and future opportunities.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/3cb5/0209b0c77656b7621d553fb48dc84d52cc41.pdf'},\n",
              "      'pubDate': '2019-05-06',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 48,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ScienceParseMerged', 'Unpaywall', 'DBLP', 'MAG', 'Anansi'],\n",
              "      'title': 'A Survey of Deep Learning-Based Human Activity Recognition in Radar',\n",
              "      'tldr': {'abstractSimilarityScore': 46,\n",
              "       'text': 'This paper elaborate deep learning approaches designed for activity recognition in radar according to the dimension of radar returns, including 1D, 2D and 3D echoes and addresses some current research considerations and future opportunities.'},\n",
              "      'venue': 'Remote. Sens.',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1909.07330.pdf'}],\n",
              "      'authors': ['Yashar Kiarashinejad',\n",
              "       'M. Zandehshahvar',\n",
              "       'Sajjad Abdollahramezani',\n",
              "       'Omid Hemmatyar',\n",
              "       'Reza Pourabolghasem',\n",
              "       'A. Adibi'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.53125,\n",
              "       'citationVelocity': 16.0,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 32, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 15, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 43.114799468997305,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 48,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 72,\n",
              "       'numViewableReferences': 72},\n",
              "      'entities': ['Deep learning',\n",
              "       'Dimensionality reduction',\n",
              "       'Autoencoder',\n",
              "       'Artificial intelligence',\n",
              "       'Algorithm',\n",
              "       'Support vector machine',\n",
              "       'Convex hull',\n",
              "       'Machine learning',\n",
              "       'British undergraduate degree classification',\n",
              "       'Computation',\n",
              "       'Simulation',\n",
              "       'Plasmon',\n",
              "       'Mathematical optimization'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'BLOG'}, 'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Physics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'b60a161de5116442733f7d8bbace8887ddb56b19',\n",
              "      'journal': {'name': 'Advanced Intelligent Systems', 'volume': '2'},\n",
              "      'links': [{'linkType': 'publisher',\n",
              "        'publisherName': 'Wiley',\n",
              "        'url': 'https://doi.org/10.1002/aisy.201900132'}],\n",
              "      'paperAbstract': 'Herein, a new approach for using the intelligence aspects of artificial intelligence for knowledge discovery rather than device optimization in electromagnetic (EM) nanostructures is presented. This approach uses training data obtained through full‐wave EM simulations of a series of nanostructures to train geometric deep learning algorithms to assess the range of feasible responses as well as the feasibility of a desired response from a class of EM nanostructures. To facilitate the knowledge discovery, this approach combines the dimensionality reduction technique with convex‐hull and one‐class support‐vector‐machine (SVM) algorithms to find the range of the feasible responses in the latent response space of the EM nanostructure. More importantly, the one‐class SVM algorithm can be trained to provide the degree of feasibility of a response from a given nanostructure. This important information can be used to modify the initial structure to an alternative one that can enable an initially unfeasible response. To show the applicability of this approach, it is applied to two important classes of binary metasurfaces (MSs), formed by an array of plasmonic nanostructures, and periodic MSs formed by an array of dielectric nanopillars. These theoretical and experimental results confirm the unique features of this approach for knowledge discovery in EM nanostructures.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'publisher',\n",
              "       'publisherName': 'Wiley',\n",
              "       'url': 'https://doi.org/10.1002/aisy.201900132'},\n",
              "      'pubDate': '2019-09-16',\n",
              "      'pubUpdateDate': '2020-02-01',\n",
              "      'scorecardStats': [{'citationCount': 48,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'MAG',\n",
              "       'Unpaywall',\n",
              "       'DBLP',\n",
              "       'ArXiv',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'Wiley',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG'],\n",
              "      'title': 'Knowledge Discovery in Nanophotonics Using Geometric Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 72,\n",
              "       'text': 'A new approach for using the intelligence aspects of artificial intelligence for knowledge discovery rather than device optimization in electromagnetic (EM) nanostructures is presented that combines the dimensionality reduction technique with convex‐hull and one‐class support‐vector‐machine (SVM) algorithms to find the range of the feasible responses in the latent response space of the EM nanostructure.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['W. Samek',\n",
              "       'G. Montavon',\n",
              "       'S. Lapuschkin',\n",
              "       'Christopher J. Anders',\n",
              "       'K. Müller'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.9333333333333333,\n",
              "       'citationVelocity': 15.666666666666666,\n",
              "       'citedByBuckets': [{'count': 3, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 15, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 29, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 45.99410947722253,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.02127659574468085,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 47,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 11,\n",
              "       'numReferences': 176,\n",
              "       'numViewableReferences': 176},\n",
              "      'entities': ['Machine learning',\n",
              "       'Kernel method',\n",
              "       'Unsupervised learning',\n",
              "       'Nonlinear system',\n",
              "       'Deep learning',\n",
              "       'Anomaly detection',\n",
              "       'Cluster analysis',\n",
              "       'Artificial neural network',\n",
              "       'Supervised learning',\n",
              "       'Neural network software',\n",
              "       'Problem solving',\n",
              "       'Predictive modelling',\n",
              "       'Best practice',\n",
              "       'Simulation',\n",
              "       'Algorithm',\n",
              "       'Time complexity',\n",
              "       'Text corpus',\n",
              "       'Image gradient'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'ac0a59165ee2ac666b1880316eefe349b87f6ba0',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2003.07631'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2003.07631.pdf'}],\n",
              "      'paperAbstract': 'With the broader and highly successful usage of machine learning in industry and the sciences, there has been a growing demand for explainable AI. Interpretability and explanation methods for gaining a better understanding about the problem solving abilities and strategies of nonlinear Machine Learning such as Deep Learning (DL), LSTMs, and kernel methods are therefore receiving increased attention. In this work we aim to (1) provide a timely overview of this active emerging field and explain its theoretical foundations, (2) put interpretability algorithms to a test both from a theory and comparative evaluation perspective using extensive simulations, (3) outline best practice aspects i.e. how to best include interpretation methods into the standard usage of machine learning and (4) demonstrate successful usage of explainable AI in a representative selection of application scenarios. Finally, we discuss challenges and possible future directions of this exciting foundational field of machine learning.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2003.07631.pdf'},\n",
              "      'pubDate': '2020-03-17',\n",
              "      'pubUpdateDate': '2020-03-17',\n",
              "      'scorecardStats': [{'citationCount': 47,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ArXiv',\n",
              "       'Anansi',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'Toward Interpretable Machine Learning: Transparent Deep Neural Networks and Beyond',\n",
              "      'tldr': {'abstractSimilarityScore': 46,\n",
              "       'text': 'This work aims to provide a timely overview of this active emerging field of machine learning and explain its theoretical foundations, put interpretability algorithms to a test both from a theory and comparative evaluation perspective using extensive simulations, and outline best practice aspects.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://www.mdpi.com/1424-8220/20/18/5097/pdf'},\n",
              "       {'linkType': 'anansi', 'url': 'http://de.arxiv.org/pdf/2004.00218'},\n",
              "       {'linkType': 'arxiv', 'url': 'https://arxiv.org/pdf/2004.00218.pdf'},\n",
              "       {'linkType': 'doi', 'url': 'https://doi.org/10.3390/s20185097'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://res.mdpi.com/d_attachment/sensors/sensors-20-05097/article_deploy/sensors-20-05097-v2.pdf'},\n",
              "       {'linkType': 'dblp',\n",
              "        'url': 'https://www.wikidata.org/entity/Q99244539'}],\n",
              "      'authors': ['S. Singh',\n",
              "       'Lipo Wang',\n",
              "       'Sukrit Gupta',\n",
              "       'Haveesh Goli',\n",
              "       'P. Padmanabhan',\n",
              "       \"Bal'azs Guly'as\"],\n",
              "      'badges': [{'id': 'UNPAYWALL'}, {'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 2.888888888888889,\n",
              "       'citationVelocity': 22.0,\n",
              "       'citedByBuckets': [{'count': 9, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 35, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 66.31461222759856,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.045454545454545456,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 44,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 4,\n",
              "       'numReferences': 163,\n",
              "       'numViewableReferences': 163},\n",
              "      'entities': ['Deep learning',\n",
              "       'Medical imaging',\n",
              "       'Machine learning',\n",
              "       'Convolutional neural network',\n",
              "       'Internationalization and localization',\n",
              "       'Medical image computing',\n",
              "       'Preprocessor',\n",
              "       'Image analysis',\n",
              "       'Artificial neural network',\n",
              "       '3D computer graphics'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Medicine',\n",
              "       'Computer Science',\n",
              "       'Biology',\n",
              "       'Engineering'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'b2baac1e61d11372be888b4d55e5d1e4494c7b3c',\n",
              "      'journal': {'name': 'Sensors (Basel, Switzerland)', 'volume': '20'},\n",
              "      'links': [{'linkType': 'medline',\n",
              "        'url': 'https://www.ncbi.nlm.nih.gov/pubmed/32906819'}],\n",
              "      'paperAbstract': 'The rapid advancements in machine learning, graphics processing technologies and the availability of medical imaging data have led to a rapid increase in the use of deep learning models in the medical domain. This was exacerbated by the rapid advancements in convolutional neural network (CNN) based architectures, which were adopted by the medical imaging community to assist clinicians in disease diagnosis. Since the grand success of AlexNet in 2012, CNNs have been increasingly used in medical image analysis to improve the efficiency of human clinicians. In recent years, three-dimensional (3D) CNNs have been employed for the analysis of medical images. In this paper, we trace the history of how the 3D CNN was developed from its machine learning roots, we provide a brief mathematical description of 3D CNN and provide the preprocessing steps required for medical images before feeding them to 3D CNNs. We review the significant research in the field of 3D medical imaging analysis using 3D CNNs (and its variants) in different medical areas such as classification, segmentation, detection and localization. We conclude by discussing the challenges associated with the use of 3D CNNs in the medical imaging domain (and the use of deep learning models in general) and possible future trends in the field.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'medline',\n",
              "       'url': 'https://www.ncbi.nlm.nih.gov/pubmed/32906819'},\n",
              "      'pubDate': '2020-04-01',\n",
              "      'pubUpdateDate': '2020-09-07',\n",
              "      'scorecardStats': [{'citationCount': 44,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'MAG',\n",
              "       'Medline',\n",
              "       'Crossref',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'Unpaywall',\n",
              "       'MAG',\n",
              "       'PubMedCentral',\n",
              "       'DBLP',\n",
              "       'ArXiv'],\n",
              "      'title': '3D Deep Learning on Medical Images: A Review',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': 'The history of how the 3D CNN was developed from its machine learning roots is traced, a brief mathematical description of3D CNN is provided and the preprocessing steps required for medical images before feeding them to 3DCNNs are provided.'},\n",
              "      'venue': 'Sensors',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Markus Borg',\n",
              "       'Cristofer Englund',\n",
              "       'K. Wnuk',\n",
              "       'B. Durán',\n",
              "       'C. Levandowski',\n",
              "       'Shenjian Gao',\n",
              "       'Yanwen Tan',\n",
              "       'Henrik Kaijser',\n",
              "       'Henrik Lönn',\n",
              "       'J. Törnqvist'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.11764705882352941,\n",
              "       'citationVelocity': 14.666666666666666,\n",
              "       'citedByBuckets': [{'count': 8, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 17, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 19, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 55.70614910244735,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.06818181818181818,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 44,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 8,\n",
              "       'numReferences': 128,\n",
              "       'numViewableReferences': 128},\n",
              "      'entities': ['Verification and validation',\n",
              "       'Machine learning',\n",
              "       'Software engineering',\n",
              "       'Automotive software',\n",
              "       'System testing',\n",
              "       'Test case'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '0472f261e6a98c1e2b26df99af487a5297b3703c',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1812.05389'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1812.05389.pdf'}],\n",
              "      'paperAbstract': 'Deep Neural Networks (DNN) will emerge as a cornerstone in automotive software engineering. However, developing systems with DNNs introduces novel challenges for safety assessments. This paper reviews the state-of-the-art in verification and validation of safety-critical systems that rely on machine learning. Furthermore, we report from a workshop series on DNNs for perception with automotive experts in Sweden, confirming that ISO 26262 largely contravenes the nature of DNNs. We recommend aerospace-to-automotive knowledge transfer and systems-based safety approaches, e.g., safety cage architectures and simulated system test cases.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1812.05389.pdf'},\n",
              "      'pubDate': '2018-12-13',\n",
              "      'pubUpdateDate': '2019-01-31',\n",
              "      'scorecardStats': [{'citationCount': 44,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'ArXiv',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Unpaywall',\n",
              "       'MAG',\n",
              "       'MAG',\n",
              "       'ScienceParseMerged'],\n",
              "      'title': 'Safely Entering the Deep: A Review of Verification and Validation for Machine Learning and a Challenge Elicitation in the Automotive Industry',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'The state-of-the-art in verification and validation of safety-critical systems that rely on machine learning is reviewed, confirming that ISO 26262 largely contravenes the nature of DNNs.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2018'}]}},\n",
              "  {'Page': {'N_Page': 5,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [],\n",
              "      'authors': ['Alberto Gasparin', 'S. Lukovic', 'C. Alippi'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.5185185185185185,\n",
              "       'citationVelocity': 14.666666666666666,\n",
              "       'citedByBuckets': [{'count': 4, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 27, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 13, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 25.548068879330952,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.06818181818181818,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 44,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 8,\n",
              "       'numReferences': 100,\n",
              "       'numViewableReferences': 100},\n",
              "      'entities': ['Projections and Predictions',\n",
              "       'Deep learning',\n",
              "       'Electrical load',\n",
              "       'Recurrent neural network',\n",
              "       'Time series',\n",
              "       'Convolutional neural network',\n",
              "       'Natural language processing',\n",
              "       'Machine translation',\n",
              "       'Feedforward neural network',\n",
              "       'Load profile',\n",
              "       'MIMO',\n",
              "       'Experiment',\n",
              "       'Artificial neural network',\n",
              "       'Long short-term memory',\n",
              "       'Machine learning',\n",
              "       'Signal processing',\n",
              "       'triclocarban 0.005 MG/MG Medicated Bar Soap',\n",
              "       'Computer vision',\n",
              "       'triciribine phosphate',\n",
              "       'Nonlinear system',\n",
              "       'Neural Network Simulation',\n",
              "       'HL7PublishingSubSection <operations>',\n",
              "       'Neural Networks',\n",
              "       'Discrepancy function',\n",
              "       'Entity Name Part Qualifier - adopted'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '003a11f401e286ccfd3a699d8f55db5cf81fd540',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1907.09207'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1907.09207.pdf'}],\n",
              "      'paperAbstract': 'Management and efficient operations in critical infrastructure such as Smart Grids take huge advantage of accurate power load forecasting which, due to its nonlinear nature, remains a challenging task. Recently, deep learning has emerged in the machine learning field achieving impressive performance in a vast range of tasks, from image classification to machine translation. Applications of deep learning models to the electric load forecasting problem are gaining interest among researchers as well as the industry, but a comprehensive and sound comparison among different architectures is not yet available in the literature. This work aims at filling the gap by reviewing and experimentally evaluating on two real-world datasets the most recent trends in electric load forecasting, by contrasting deep learning architectures on short term forecast (one day ahead prediction). Specifically, we focus on feedforward and recurrent neural networks, sequence to sequence models and temporal convolutional neural networks along with architectural variants, which are known in the signal processing community but are novel to the load forecasting one.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1907.09207.pdf'},\n",
              "      'pubDate': '2019-07-22',\n",
              "      'pubUpdateDate': '2019-07-22',\n",
              "      'scorecardStats': [{'citationCount': 44,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'DBLP',\n",
              "       'ScienceParseMerged',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'ArXiv'],\n",
              "      'title': 'Deep Learning for Time Series Forecasting: The Electric Load Case',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'This work focuses on feedforward and recurrent neural networks, sequence to sequence models and temporal convolutional neural networks along with architectural variants, which are known in the signal processing community but are novel to the load forecasting one.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['WeiWei Jiang'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.1,\n",
              "       'citationVelocity': 21.0,\n",
              "       'citedByBuckets': [{'count': 20, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 22, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 27.72117549674307,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.07142857142857142,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 42,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 160,\n",
              "       'numReferences': 234,\n",
              "       'numViewableReferences': 234},\n",
              "      'entities': ['Deep learning',\n",
              "       'Machine learning',\n",
              "       'Computer scientist',\n",
              "       'Baseline (configuration management)',\n",
              "       'Artificial neural network'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Economics', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '00c7a21bd4d7c2c67ae54efbd2f6336cd5dc17e6',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2003.01859'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2003.01859.pdf'}],\n",
              "      'paperAbstract': 'Stock market prediction has been a classical yet challenging problem, with the attention from both economists and computer scientists. With the purpose of building an effective prediction model, both linear and machine learning tools have been explored for the past couple of decades. Lately, deep learning models have been introduced as new frontiers for this topic and the rapid development is too fast to catch up. Hence, our motivation for this survey is to give a latest review of recent works on deep learning models for stock market prediction. We not only category the different data sources, various neural network structures, and common used evaluation metrics, but also the implementation and reproducibility. Our goal is to help the interested researchers to synchronize with the latest progress and also help them to easily reproduce the previous studies as baselines. Base on the summary, we also highlight some future research directions in this topic.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2003.01859.pdf'},\n",
              "      'pubDate': '2020-02-29',\n",
              "      'pubUpdateDate': '2020-02-29',\n",
              "      'scorecardStats': [{'citationCount': 42,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi'],\n",
              "      'title': 'Applications of deep learning in stock market prediction: recent progress',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'A review of recent works on deep learning models for stock market prediction by category the different data sources, various neural network structures, and common used evaluation metrics to help the interested researchers to synchronize with the latest progress and also help them to easily reproduce the previous studies as baselines.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08695760.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2912896'}],\n",
              "      'authors': ['Pan Wang', 'X. Chen', 'Feng Ye', 'Zhixin Sun'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.4166666666666667,\n",
              "       'citationVelocity': 14.0,\n",
              "       'citedByBuckets': [{'count': 4, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 24, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 14, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 47.969145352538185,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 42,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 3,\n",
              "       'numReferences': 54,\n",
              "       'numViewableReferences': 54},\n",
              "      'entities': ['Traffic classification',\n",
              "       'Deep learning',\n",
              "       'Encryption',\n",
              "       'Machine learning',\n",
              "       'Feature learning',\n",
              "       'Mobile device',\n",
              "       'Community'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '5288e5808a02a81e87e18dd99671913daa31bafb',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '54024-54033',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8695760'}],\n",
              "      'paperAbstract': 'The rapid adoption of mobile devices has dramatically changed the access to various networking services and led to the explosion of mobile service traffic. Mobile service traffic classification has been a crucial task that attracts strong interest in mobile network management and security as well as machine learning communities for past decades. However, with more and more adoptions of encryption over mobile services, it brings a lot of challenges about mobile traffic classification. Although classical machine learning approaches can solve many issues that port and payload-based methods cannot solve, it still has some limitations, such as time-consuming, costly handcrafted features, and frequent features update. With the excellent ability of automatic feature learning, Deep Learning (DL) undoubtedly becomes a highly desirable approach for mobile services traffic classification, especially encrypted traffic. This survey paper looks at emerging research into the application of DL methods to encrypted traffic classification of mobile services and presents a general framework of DL-based mobile encrypted traffic classification. Moreover, we review most of the recent existing work according to dataset selection, model input design, and model architecture. Furthermore, we propose some noteworthy issues and challenges about DL-based mobile services traffic classification.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8695760'},\n",
              "      'pubDate': '2019-04-23',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 42,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'IEEE', 'Unpaywall', 'MAG'],\n",
              "      'title': 'A Survey of Techniques for Mobile Service Encrypted Traffic Classification Using Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 47,\n",
              "       'text': 'This survey paper looks at emerging research into the application of DL methods to encrypted traffic classification of mobile services and presents a general framework of DL-based mobileencrypted traffic classification, and proposes some noteworthy issues and challenges.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Saptarshi Sengupta',\n",
              "       'Sanchita Basak',\n",
              "       'P. Saikia',\n",
              "       'Sayak Paul',\n",
              "       'Vasilios Tsalavoutis',\n",
              "       'Frederick Ditliac Atiah',\n",
              "       'V. Ravi',\n",
              "       'R. Peters'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.23809523809523808,\n",
              "       'citationVelocity': 14.0,\n",
              "       'citedByBuckets': [{'count': 5, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 21, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 16, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 54.74697962750937,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.023809523809523808,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 42,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 5,\n",
              "       'numReferences': 306,\n",
              "       'numViewableReferences': 306},\n",
              "      'entities': ['Deep learning',\n",
              "       'Uptime',\n",
              "       'Pattern recognition',\n",
              "       'Medical imaging',\n",
              "       'Computer',\n",
              "       'Fault detection and isolation',\n",
              "       'Image processing',\n",
              "       'Systems theory',\n",
              "       'Time series',\n",
              "       'IBM Power Systems',\n",
              "       'Multi-agent system',\n",
              "       'Mathematical optimization',\n",
              "       'Thrust',\n",
              "       'PRIMER',\n",
              "       'Artificial neural network',\n",
              "       'Algorithm'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'e6ed2eae6d810deb0dd00b2bdedf07252dedd51b',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1905.13294'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1905.13294.pdf'}],\n",
              "      'paperAbstract': 'Deep learning has solved a problem that as little as five years ago was thought by many to be intractable - the automatic recognition of patterns in data; and it can do so with accuracy that often surpasses human beings. It has solved problems beyond the realm of traditional, hand-crafted machine learning algorithms and captured the imagination of practitioners trying to make sense out of the flood of data that now inundates our society. As public awareness of the efficacy of DL increases so does the desire to make use of it. But even for highly trained professionals it can be daunting to approach the rapidly increasing body of knowledge produced by experts in the field. Where does one start? How does one determine if a particular model is applicable to their problem? How does one train and deploy such a network? A primer on the subject can be a good place to start. With that in mind, we present an overview of some of the key multilayer ANNs that comprise DL. We also discuss some new automatic architecture optimization protocols that use multi-agent approaches. Further, since guaranteeing system uptime is becoming critical to many computer applications, we include a section on using neural networks for fault detection and subsequent mitigation. This is followed by an exploratory survey of several application areas where DL has emerged as a game-changing technology: anomalous behavior detection in financial applications or in financial time-series forecasting, predictive and prescriptive analytics, medical image processing and analysis and power systems research. The thrust of this review is to outline emerging areas of application-oriented research within the DL community as well as to provide a reference to researchers seeking to use it in their work for what it does best: statistical pattern recognition with unparalleled learning capacity with the ability to scale with information.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1905.13294.pdf'},\n",
              "      'pubDate': '2019-05-30',\n",
              "      'pubUpdateDate': '2019-05-30',\n",
              "      'scorecardStats': [{'citationCount': 42,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ScienceParseMerged',\n",
              "       'ScienceParseMerged',\n",
              "       'ArXiv',\n",
              "       'Anansi',\n",
              "       'MAG',\n",
              "       'Unpaywall',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'ScienceParseMerged',\n",
              "       'DBLP'],\n",
              "      'title': 'A Review of Deep Learning with Special Emphasis on Architectures, Applications and Recent Trends',\n",
              "      'tldr': {'abstractSimilarityScore': 39,\n",
              "       'text': 'The thrust of this review is to outline emerging areas of application-oriented research within the DL community as well as to provide a reference to researchers seeking to use it in their work for what it does best: statistical pattern recognition with unparalleled learning capacity with the ability to scale with information.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08668403.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2905633'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://www.truprojects.in/admin/imgs/pro_img/kasongo2019.pdf'}],\n",
              "      'authors': ['S. M. Kasongo', 'Yanxia Sun'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.6538461538461539,\n",
              "       'citationVelocity': 13.666666666666666,\n",
              "       'citedByBuckets': [{'count': 6, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 26, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 9, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 48.65638910356905,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.07317073170731707,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 41,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 57,\n",
              "       'numViewableReferences': 57},\n",
              "      'entities': ['Deep learning',\n",
              "       'Intrusion detection system',\n",
              "       'Wireless intrusion prevention system',\n",
              "       'Machine learning',\n",
              "       'Feature engineering',\n",
              "       'Decision tree',\n",
              "       'Data mining',\n",
              "       'Feature vector',\n",
              "       'K-nearest neighbors algorithm',\n",
              "       'Selection algorithm',\n",
              "       'Naive Bayes classifier',\n",
              "       'Feature selection',\n",
              "       \"Whole Earth 'Lectronic Link\",\n",
              "       'Artificial neural network'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'ca0e89449f1f04b8c617469dd30abaa56e67ea87',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '38597-38607',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8668403'}],\n",
              "      'paperAbstract': 'In recent years, the increased use of wireless networks for the transmission of large volumes of information has generated a myriad of security threats and privacy concerns; consequently, there has been the development of a number of preventive and protective measures including intrusion detection systems (IDS). Intrusion detection mechanisms play a pivotal role in securing computer and network systems; however, for various IDS, the performance remains a major issue. Moreover, the accuracy of existing methodologies for IDS using machine learning is heavily affected when the feature space grows. In this paper, we propose a IDS based on deep learning using feed forward deep neural networks (FFDNNs) coupled with a filter-based feature selection algorithm. The FFDNN-IDS is evaluated using the well-known NSL-knowledge discovery and data mining (NSL-KDD) dataset and it is compared to the following existing machine learning methods: support vectors machines, decision tree, K-Nearest Neighbor, and Naïve Bayes. The experimental results prove that the FFDNN-IDS achieves an increase in accuracy in comparison to other methods.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8668403'},\n",
              "      'pubDate': '2019-03-18',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 41,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ScienceParseMerged',\n",
              "       'DBLP',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'Unpaywall',\n",
              "       'IEEE',\n",
              "       'MAG'],\n",
              "      'title': 'A Deep Learning Method With Filter Based Feature Engineering for Wireless Intrusion Detection System',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'This paper proposes a IDS based on deep learning using feed forward deep neural networks (FFDNNs) coupled with a filter-based feature selection algorithm and proves that the FFDNN-IDS achieves an increase in accuracy in comparison to other methods.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['N. Prakash', 'A. Manconi', 'S. Loew'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.09523809523809523,\n",
              "       'citationVelocity': 20.0,\n",
              "       'citedByBuckets': [{'count': 21, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 19, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 51.369081191233086,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.075,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 40,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 8,\n",
              "       'numReferences': 91,\n",
              "       'numViewableReferences': 91},\n",
              "      'entities': ['Machine learning',\n",
              "       'Deep learning',\n",
              "       'Pixel',\n",
              "       'Feature extraction',\n",
              "       'Matthews correlation coefficient',\n",
              "       'Convolutional neural network',\n",
              "       'Object-based language',\n",
              "       'Cross entropy',\n",
              "       'Loss function',\n",
              "       'Conditional random field',\n",
              "       'Limited availability',\n",
              "       'Video post-processing',\n",
              "       'Image resolution',\n",
              "       'Artificial neural network',\n",
              "       'Ground truth',\n",
              "       'Experiment',\n",
              "       'Internet backbone',\n",
              "       'FOCAL (programming language)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'e72f29e88350ba95376e7131da98804a8a68993a',\n",
              "      'journal': {'name': 'Remote. Sens.', 'pages': '346', 'volume': '12'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/e72f/29e88350ba95376e7131da98804a8a68993a.pdf'}],\n",
              "      'paperAbstract': 'Mapping landslides using automated methods is a challenging task, which is still largely done using human efforts. Today, the availability of high-resolution EO data products is increasing exponentially, and one of the targets is to exploit this data source for the rapid generation of landslide inventory. Conventional methods like pixel-based and object-based machine learning strategies have been studied extensively in the last decade. In addition, recent advances in CNN (convolutional neural network), a type of deep-learning method, has been widely successful in extracting information from images and have outperformed other conventional learning methods. In the last few years, there have been only a few attempts to adapt CNN for landslide mapping. In this study, we introduce a modified U-Net model for semantic segmentation of landslides at a regional scale from EO data using ResNet34 blocks for feature extraction. We also compare this with conventional pixel-based and object-based methods. The experiment was done in Douglas County, a study area selected in the south of Portland in Oregon, USA, and landslide inventory extracted from SLIDO (Statewide Landslide Information Database of Oregon) was considered as the ground truth. Landslide mapping is an imbalanced learning problem with very limited availability of training data. Our network was trained on a combination of focal Tversky loss and cross-entropy loss functions using augmented image tiles sampled from a selected training area. The deep-learning method was observed to have a better performance than the conventional methods with an MCC (Matthews correlation coefficient) score of 0.495 and a POD (probability of detection) rate of 0.72.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/e72f/29e88350ba95376e7131da98804a8a68993a.pdf'},\n",
              "      'pubDate': '2020-01-21',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 40,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Unpaywall',\n",
              "       'MAG',\n",
              "       'Anansi',\n",
              "       'Crossref',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP'],\n",
              "      'title': 'Mapping Landslides on EO Data: Performance of Deep Learning Models vs. Traditional Machine Learning Models',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'A modified U-Net model is introduced for semantic segmentation of landslides at a regional scale from EO data using ResNet34 blocks for feature extraction and is compared with conventional pixel-based and object-based methods.'},\n",
              "      'venue': 'Remote. Sens.',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['R. Carmona', 'M. Laurière'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.1,\n",
              "       'citationVelocity': 13.333333333333334,\n",
              "       'citedByBuckets': [{'count': 2, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 20, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 18, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 27.803296226071524,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.05,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 40,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 3,\n",
              "       'numReferences': 50,\n",
              "       'numViewableReferences': 50},\n",
              "      'entities': ['Machine learning',\n",
              "       'Loss function',\n",
              "       'Optimal control',\n",
              "       'Stochastic gradient descent',\n",
              "       'Mathematical optimization',\n",
              "       'Numerical partial differential equations',\n",
              "       'Artificial neural network',\n",
              "       'Numerical method',\n",
              "       'Optimization problem',\n",
              "       'Image noise',\n",
              "       'Computation',\n",
              "       'Approximation algorithm',\n",
              "       'Finite element method'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '8c276955fba84356ebfba02bfd30af21f650b215',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1908.01613'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1908.01613.pdf'}],\n",
              "      'paperAbstract': 'We propose two algorithms for the solution of the optimal control of ergodic McKean-Vlasov dynamics. Both algorithms are based on the approximation of the theoretical solutions by neural networks, the latter being characterized by their architecture and a set of parameters. This allows the use of modern machine learning tools, and efficient implementations of stochastic gradient descent. The first algorithm is based on the idiosyncrasies of the ergodic optimal control problem. We provide a mathematical proof of the convergence of the algorithm, and we analyze rigorously the approximation by controlling the different sources of error. The second method is an adaptation of the deep Galerkin method to the system of partial differential equations issued from the optimality condition. We demonstrate the efficiency of these algorithms on several numerical examples, some of them being chosen to show that our algorithms succeed where existing ones failed. We also argue that both methods can easily be applied to problems in dimensions larger than what can be found in the existing literature. Finally, we illustrate the fact that, although the first algorithm is specifically designed for mean field control problems, the second one is more general and can also be applied to the partial differential equation systems arising in the theory of mean field games.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1908.01613.pdf'},\n",
              "      'pubDate': '2019-07-13',\n",
              "      'pubUpdateDate': '2019-08-05',\n",
              "      'scorecardStats': [{'citationCount': 40,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ArXiv',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP',\n",
              "       'MAG'],\n",
              "      'title': 'Convergence Analysis of Machine Learning Algorithms for the Numerical Solution of Mean Field Control and Games: II - The Finite Horizon Case',\n",
              "      'tldr': {'abstractSimilarityScore': 70,\n",
              "       'text': 'Two algorithms are proposed for the solution of the optimal control of ergodic McKean-Vlasov dynamics based on the approximation of the theoretical solutions by neural networks, which allows the use of modern machine learning tools, and efficient implementations of stochastic gradient descent.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Onur Avcı',\n",
              "       'Osama Abdeljaber',\n",
              "       'S. Kiranyaz',\n",
              "       'Mohammed F. M. Hussein',\n",
              "       'M. Gabbouj',\n",
              "       'D. Inman'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 12.333333333333334,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 4, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 32, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 13.25222784517516,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 37,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 255,\n",
              "       'numViewableReferences': 255},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Engineering', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'af810cacb9992794e0247487a76d377d8e52dc25',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2004.04373'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2004.04373.pdf'}],\n",
              "      'paperAbstract': 'Abstract Monitoring structural damage is extremely important for sustaining and preserving the service life of civil structures. While successful monitoring provides resolute and staunch information on the health, serviceability, integrity and safety of structures; maintaining continuous performance of a structure depends highly on monitoring the occurrence, formation and propagation of damage. Damage may accumulate on structures due to different environmental and human-induced factors. Numerous monitoring and detection approaches have been developed to provide practical means for early warning against structural damage or any type of anomaly. Considerable effort has been put into vibration-based methods, which utilize the vibration response of the monitored structure to assess its condition and identify structural damage. Meanwhile, with emerging computing power and sensing technology in the last decade, Machine Learning (ML) and especially Deep Learning (DL) algorithms have become more feasible and extensively used in vibration-based structural damage detection with elegant performance and often with rigorous accuracy. While there have been multiple review studies published on vibration-based structural damage detection, there has not been a study where the transition from traditional methods to ML and DL methods are described and discussed. This paper aims to fulfill this gap by presenting the highlights of the traditional methods and provide a comprehensive review of the most recent applications of ML and DL algorithms utilized for vibration-based structural damage detection in civil structures.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2004.04373.pdf'},\n",
              "      'pubDate': '2020-04-09',\n",
              "      'pubUpdateDate': '2021-01-15',\n",
              "      'scorecardStats': [{'citationCount': 37,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'Unpaywall',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'DBLP',\n",
              "       'MAG',\n",
              "       'ArXiv'],\n",
              "      'title': 'A Review of Vibration-Based Damage Detection in Civil Structures: From Traditional Methods to Machine Learning and Deep Learning Applications',\n",
              "      'tldr': {'abstractSimilarityScore': 39,\n",
              "       'text': 'This paper aims to fulfill the gap by presenting the highlights of the traditional methods and provide a comprehensive review of the most recent applications of ML and DL algorithms utilized for vibration-based structural damage detection in civil structures.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Laurent Valentin Jospin',\n",
              "       'Wray L. Buntine',\n",
              "       'F. Boussaid',\n",
              "       'Hamid Laga',\n",
              "       'M. Bennamoun'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 18.0,\n",
              "       'citedByBuckets': [{'count': 8, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 28, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 34.079727354813926,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.05555555555555555,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 36,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 10,\n",
              "       'numReferences': 106,\n",
              "       'numViewableReferences': 106},\n",
              "      'entities': ['Deep learning',\n",
              "       'Machine learning',\n",
              "       'Black box',\n",
              "       'Neural Networks',\n",
              "       'Semantics (computer science)',\n",
              "       'Bayesian network',\n",
              "       'Hands-on computing'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '2d05724c9f1d8e1b721a501051bfff01ab2f232e',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2007.06823'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2007.06823.pdf'}],\n",
              "      'paperAbstract': 'Modern deep learning methods have equipped researchers and engineers with incredibly powerful tools to tackle problems that previously seemed impossible. However, since deep learning methods operate as black boxes, the uncertainty associated with their predictions is often challenging to quantify. Bayesian statistics offer a formalism to understand and quantify the uncertainty associated with deep neural networks predictions. This paper provides a tutorial for researchers and scientists who are using machine learning, especially deep learning, with an overview of the relevant literature and a complete toolset to design, implement, train, use and evaluate Bayesian neural networks.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2007.06823.pdf'},\n",
              "      'pubDate': '2020-07-14',\n",
              "      'pubUpdateDate': '2020-07-14',\n",
              "      'scorecardStats': [{'citationCount': 36,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi', 'MergedPDFExtraction', 'DBLP', 'ArXiv', 'MAG'],\n",
              "      'title': 'Hands-on Bayesian Neural Networks - a Tutorial for Deep Learning Users',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'This paper provides a tutorial for researchers and scientists who are using machine learning, especially deep learning, with an overview of the relevant literature and a complete toolset to design, implement, train, use and evaluate Bayesian neural networks.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'dblp',\n",
              "        'url': 'https://doi.org/10.1016/j.neucom.2018.10.104'}],\n",
              "      'authors': ['Daniele Liciotti',\n",
              "       'Michele Bernardini',\n",
              "       'L. Romeo',\n",
              "       'E. Frontoni'],\n",
              "      'badges': [],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.3076923076923077,\n",
              "       'citationVelocity': 11.0,\n",
              "       'citedByBuckets': [{'count': 3, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 13, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 17, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 37.57138623889204,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.15151515151515152,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 33,\n",
              "       'numKeyCitations': 5,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 63,\n",
              "       'numViewableReferences': 63},\n",
              "      'entities': ['Deep learning'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '3dc60086112974e2104b753a7fdd7f0a0c2d89a6',\n",
              "      'journal': {'name': 'Neurocomputing',\n",
              "       'pages': '501-513',\n",
              "       'volume': '396'},\n",
              "      'links': [{'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1016/J.NEUCOM.2018.10.104'}],\n",
              "      'paperAbstract': 'Abstract The recent advancement and development of computer electronic devices has led to the adoption of smart home sensing systems, stimulating the demand for associated products and services. Accordingly, the increasingly large amount of data calls the machine learning (ML) field for automatic recognition of human behaviour. In this work, different deep learning (DL) models that learn to classify human activities were proposed. In particular, the long short-term memory (LSTM) was applied for modelling spatio-temporal sequences acquired by smart home sensors. Experimental results performed on the Center for Advanced Studies in Adaptive Systems datasets show that the proposed LSTM-based approaches outperform existing DL and ML methods, giving superior results compared to the existing literature.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'doi',\n",
              "       'url': 'https://doi.org/10.1016/J.NEUCOM.2018.10.104'},\n",
              "      'pubDate': '2020-07-05',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 33,\n",
              "        'keyCitationCount': 5,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG', 'Crossref', 'Unpaywall', 'DBLP'],\n",
              "      'title': 'A sequential deep learning application for recognising human activities in smart homes',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'Experimental results performed on the Center for Advanced Studies in Adaptive Systems datasets show that the proposed LSTM-based approaches outperform existing DL and ML methods, giving superior results compared to the existing literature.'},\n",
              "      'venue': 'Neurocomputing',\n",
              "      'videos': [],\n",
              "      'year': '2020'}]}},\n",
              "  {'Page': {'N_Page': 6,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08786773.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2927134'}],\n",
              "      'authors': ['A. Gumaei',\n",
              "       'M. Hassan',\n",
              "       'Abdulhameed Alelaiwi',\n",
              "       'Hussain Alsalman'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.2,\n",
              "       'citationVelocity': 11.0,\n",
              "       'citedByBuckets': [{'count': 15, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 18, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 63.14434690671285,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.030303030303030304,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 33,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 1,\n",
              "       'numReferences': 30,\n",
              "       'numViewableReferences': 30},\n",
              "      'entities': ['Activity recognition',\n",
              "       'Deep learning',\n",
              "       'Multimodal interaction',\n",
              "       'Machine learning',\n",
              "       'Overfitting',\n",
              "       'Instability',\n",
              "       'Computer data storage',\n",
              "       'Gradient',\n",
              "       'Sensor',\n",
              "       'Modality (human–computer interaction)',\n",
              "       'Care-of address',\n",
              "       'Recurrent neural network',\n",
              "       'Artificial neural network'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '40c7e97580e8ab66778916608bbcf9c7f2452868',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '99152-99160',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8786773'}],\n",
              "      'paperAbstract': 'Human activity recognition from multimodal body sensor data has proven to be an effective approach for the care of elderly or physically impaired people in a smart healthcare environment. However, traditional machine learning techniques are mostly focused on a single sensing modality, which is not practical for robust healthcare applications. Therefore, recently increasing attention is being given by the researchers on the development of robust machine learning techniques that can exploit multimodal body sensor data and provide important decision making in Smart healthcare. In this paper, we propose an effective multi-sensors-based framework for human activity recognition using a hybrid deep learning model, which combines the simple recurrent units (SRUs) with the gated recurrent units (GRUs) of neural networks. We use the deep SRUs to process the sequences of multimodal input data by using the capability of their internal memory states. Moreover, we use the deep GRUs to store and learn how much of the past information is passed to the future state for solving fluctuations or instability in accuracy and vanishing gradient problems. The system has been compared against the conventional approaches on a publicly available standard dataset. The experimental results show that the proposed approach outperforms the available state-of-the-art methods.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8786773'},\n",
              "      'pubDate': '2019-08-02',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 33,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['IEEE', 'ScienceParseMerged', 'MAG', 'DBLP', 'Unpaywall'],\n",
              "      'title': 'A Hybrid Deep Learning Model for Human Activity Recognition Using Multimodal Body Sensing Data',\n",
              "      'tldr': {'abstractSimilarityScore': 38,\n",
              "       'text': 'This paper proposes an effective multi-sensors-based framework for human activity recognition using a hybrid deep learning model, which combines the simple recurrent units (SRUs) with the gated recurrentunits (GRUs) of neural networks.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Junaed Younus Khan',\n",
              "       'Md. Tawkat Islam Khondaker',\n",
              "       'Anindya Iqbal',\n",
              "       'Sadia Afroz'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.14285714285714285,\n",
              "       'citationVelocity': 11.0,\n",
              "       'citedByBuckets': [{'count': 3, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 14, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 16, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 29.526960882124055,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.06060606060606061,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 33,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 4,\n",
              "       'numReferences': 32,\n",
              "       'numViewableReferences': 32},\n",
              "      'entities': ['Machine learning',\n",
              "       'Benchmark (computing)',\n",
              "       'Deep learning',\n",
              "       'Social media',\n",
              "       'Software propagation',\n",
              "       'Attempt'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '09adaadcd4cc3e7aafef6573df7cab133cb9517b',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1905.04749'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1905.04749.pdf'}],\n",
              "      'paperAbstract': 'The proliferation of fake news and its propagation on social media have become a major concern due to its ability to create devastating impacts. Different machine learning approaches have been attempted to detect it. However, most of those focused on a special type of news (such as political) and did not apply many advanced techniques. In this research, we conduct a benchmark study to assess the performance of different applicable approaches on three different datasets where the largest and most diversified one was developed by us. We also implemented some advanced deep learning models that have shown promising results.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1905.04749.pdf'},\n",
              "      'pubDate': '2019-05-12',\n",
              "      'pubUpdateDate': '2019-05-12',\n",
              "      'scorecardStats': [{'citationCount': 33,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ArXiv',\n",
              "       'DBLP',\n",
              "       'MAG',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'A Benchmark Study on Machine Learning Methods for Fake News Detection',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'A benchmark study to assess the performance of different applicable approaches on three different datasets where the largest and most diversified one was developed by us and implemented some advanced deep learning models that have shown promising results.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Lasse F. Wolff Anthony',\n",
              "       'Benjamin Kanding',\n",
              "       'Raghavendra Selvan'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 1.5555555555555556,\n",
              "       'citationVelocity': 16.0,\n",
              "       'citedByBuckets': [{'count': 9, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 23, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 30.15475609245207,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.03125,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 32,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 7,\n",
              "       'numReferences': 27,\n",
              "       'numViewableReferences': 27},\n",
              "      'entities': ['Deep learning',\n",
              "       'Machine learning',\n",
              "       'Hardware acceleration',\n",
              "       'Time complexity',\n",
              "       'Artificial neural network'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Engineering', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'de5157a3d62ab114813379a6568f716b483feece',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2007.03051'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2007.03051.pdf'}],\n",
              "      'paperAbstract': 'Deep learning (DL) can achieve impressive results across a wide variety of tasks, but this often comes at the cost of training models for extensive periods on specialized hardware accelerators. This energy-intensive workload has seen immense growth in recent years. Machine learning (ML) may become a significant contributor to climate change if this exponential trend continues. If practitioners are aware of their energy and carbon footprint, then they may actively take steps to reduce it whenever possible. In this work, we present Carbontracker, a tool for tracking and predicting the energy and carbon footprint of training DL models. We propose that energy and carbon footprint of model development and training is reported alongside performance metrics using tools like Carbontracker. We hope this will promote responsible computing in ML and encourage research into energy-efficient deep neural networks.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2007.03051.pdf'},\n",
              "      'pubDate': '2020-07-06',\n",
              "      'pubUpdateDate': '2020-07-06',\n",
              "      'scorecardStats': [{'citationCount': 32,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv',\n",
              "       'MAG'],\n",
              "      'title': 'Carbontracker: Tracking and Predicting the Carbon Footprint of Training Deep Learning Models',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'This work proposes that energy and carbon footprint of model development and training is reported alongside performance metrics using tools like Carbontracker, and hopes this will promote responsible computing in ML and encourage research into energy-efficient deep neural networks.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Hamed Majidifard', 'Y. Adu-Gyamfi', 'W. Buttlar'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.38461538461538464,\n",
              "       'citationVelocity': 15.5,\n",
              "       'citedByBuckets': [{'count': 13, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 18, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 8.579215530518075,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.03225806451612903,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 31,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 1,\n",
              "       'numReferences': 101,\n",
              "       'numViewableReferences': 101},\n",
              "      'entities': ['Machine learning',\n",
              "       'Deep learning',\n",
              "       'Google Street View',\n",
              "       'Distress (novel)',\n",
              "       'Inventory',\n",
              "       'Ground truth',\n",
              "       'Computer vision',\n",
              "       'Algorithm'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'b11d8e8a46bb8a010f1b78c457cc38020cb198e3',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2004.13314'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2004.13314.pdf'}],\n",
              "      'paperAbstract': 'Abstract Pavement condition assessment provides information to make more cost-effective and consistent decisions regarding management of pavement network. Generally, pavement distress inspections are performed using sophisticated data collection vehicles and/or foot-on-ground surveys. In either approach, the process of distress detection is human-dependent, expensive, inefficient, and/or unsafe. Automated pavement distress detection via road images is still a challenging issue among pavement researchers and computer-vision community. In recent years, advancement in deep learning has enabled researchers to develop robust tools for analyzing pavement images at unprecedented accuracies. Nevertheless, deep learning models necessitate a big ground truth dataset, which is often not readily accessible for pavement field. In this study, we reviewed our previous study, which a labeled pavement dataset was presented as the first step towards a more robust, easy-to-deploy pavement condition assessment system. In total, 7237 google street-view images were extracted, manually annotated for classification (nine categories of distress classes). Afterward, YOLO (you look only once) deep learning framework was implemented to train the model using the labeled dataset. In the current study, a U-net based model is developed to quantify the severity of the distresses, and finally, a hybrid model is developed by integrating the YOLO and U-net model to classify the distresses and quantify their severity simultaneously. Various pavement condition indices are developed by implementing various machine learning algorithms using the YOLO deep learning framework for distress classification and U-net for segmentation and distress densification. The output of the distress classification and segmentation models are used to develop a comprehensive pavement condition tool which rates each pavement image according to the type and severity of distress extracted. As a result, we are able to avoid over-dependence on human judgement throughout the pavement condition evaluation process. The outcome of this study could be conveniently employed to evaluate the pavement conditions during its service life and help to make valid decisions for rehabilitation or reconstruction of the roads at the right time.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2004.13314.pdf'},\n",
              "      'pubDate': '2020-04-28',\n",
              "      'pubUpdateDate': '2020-06-30',\n",
              "      'scorecardStats': [{'citationCount': 31,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'Unpaywall',\n",
              "       'MAG',\n",
              "       'ArXiv',\n",
              "       'MergedPDFExtraction',\n",
              "       'Crossref',\n",
              "       'MAG'],\n",
              "      'title': 'Deep Machine Learning Approach to Develop a New Asphalt Pavement Condition Index',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'The outcome of this study could be conveniently employed to evaluate the pavement conditions during its service life and help to make valid decisions for rehabilitation or reconstruction of the roads at the right time.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['S. Zhang', 'Shibo Zhang', 'Bingnan Wang', 'T. Habetler'],\n",
              "      'badges': [],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 10.0,\n",
              "       'citedByBuckets': [{'count': 7, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 17, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 6, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 26.37312035648222,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.13333333333333333,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 30,\n",
              "       'numKeyCitations': 4,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 0,\n",
              "       'numViewableReferences': 0},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'e90fb6aa035360cd37684f282068cba9f9aec345',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1901.08247'},\n",
              "      'links': [],\n",
              "      'paperAbstract': '',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': None,\n",
              "      'pubDate': None,\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 30,\n",
              "        'keyCitationCount': 4,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP'],\n",
              "      'title': 'Machine Learning and Deep Learning Algorithms for Bearing Fault Diagnostics - A Comprehensive Review',\n",
              "      'tldr': None,\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'anansi',\n",
              "        'url': 'http://wpage.unina.it/antonio.montieri/pubs/neucom_dl_mobiletc_final.pdf'}],\n",
              "      'authors': ['Giuseppe Aceto', 'D. Ciuonzo', 'A. Montieri', 'A. Pescapé'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 15.0,\n",
              "       'citedByBuckets': [{'count': 8, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 22, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 46.39897432950465,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 30,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 4,\n",
              "       'numReferences': 49,\n",
              "       'numViewableReferences': 49},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'fbf63e30ac40d2abe4524a7ab9bd160d0ce0ee42',\n",
              "      'journal': {'name': 'Neurocomputing',\n",
              "       'pages': '306-315',\n",
              "       'volume': '409'},\n",
              "      'links': [{'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1016/j.neucom.2020.05.036'}],\n",
              "      'paperAbstract': 'Abstract Traffic Classification (TC), consisting in how to infer applications generating network traffic, is currently the enabler for valuable profiling information, other than being the workhorse for service differentiation/blocking. Further, TC is fostered by the blooming of mobile (mostly encrypted) traffic volumes, fueled by the huge adoption of hand-held devices. While researchers and network operators still rely on machine learning to pursue accurate inference, we envision Deep Learning (DL) paradigm as the stepping stone toward the design of practical (and effective) mobile traffic classifiers based on automatically-extracted features, able to operate with encrypted traffic, and reflecting complex traffic patterns. In this context, the paper contribution is fourfold. First, it provides a taxonomy of the key network traffic analysis subjects where DL is foreseen as attractive. Secondly, it delves into the non-trivial adoption of DL to mobile TC, surfacing potential gains. Thirdly, to capitalize such gains, it proposes and validates a general framework for DL-based encrypted TC. Two concrete instances originating from our framework are then experimentally evaluated on three mobile datasets of human users’ activity. Lastly, our framework is leveraged to point to future research perspectives.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'doi',\n",
              "       'url': 'https://doi.org/10.1016/j.neucom.2020.05.036'},\n",
              "      'pubDate': '2020-10-07',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 30,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'Anansi',\n",
              "       'Unpaywall',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG'],\n",
              "      'title': 'Toward effective mobile encrypted traffic classification through deep learning',\n",
              "      'tldr': {'abstractSimilarityScore': 39,\n",
              "       'text': 'This paper proposes and validates a general framework for DL-based encrypted TC, and provides a taxonomy of the key network traffic analysis subjects where DL is foreseen as attractive, and leveraged to point to future research perspectives.'},\n",
              "      'venue': 'Neurocomputing',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Toan Tran', 'Thanh-Toan Do', 'I. Reid', 'G. Carneiro'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.14285714285714285,\n",
              "       'citationVelocity': 9.666666666666666,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 3, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 14, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 12, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 40.45514331037063,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.23333333333333334,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 30,\n",
              "       'numKeyCitations': 7,\n",
              "       'numKeyReferences': 14,\n",
              "       'numReferences': 40,\n",
              "       'numViewableReferences': 40},\n",
              "      'entities': ['Deep learning',\n",
              "       'Convolutional neural network',\n",
              "       'Information',\n",
              "       'Active learning (machine learning)',\n",
              "       'Computation',\n",
              "       'Computational resource',\n",
              "       'MNIST database'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '4af05d0b97513e19174b759c5039b115e7ff0d4c',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1904.11643'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1904.11643.pdf'}],\n",
              "      'paperAbstract': '© 36th International Conference on Machine Learning, ICML 2019. All rights reserved. Deep learning models have demonstrated outstanding performance in several problems, but their training process tends to require immense amounts of computational and human resources for training and labeling, constraining the types of problems that can be tackled. Therefore, the design of effective training methods that require small labeled training sets is an important research direction that will allow a more effective use of resources. Among current approaches designed to address this issue, two are particularly interesting: data augmentation and active learning. Data augmentation achieves this goal by artificially generating new training points, while active learning relies on the selection of the \"most informative\" subset of unlabeled training samples to be labelled by an oracle. Although successful in practice, data augmentation can waste computational resources because it indiscriminately generates samples that are not guaranteed to be informative, and active learning selects a small subset of informative samples (from a large un-annotated set) that may be insufficient for the training process. In this paper, we propose a Bayesian generative active deep learning approach that combines active learning with data augmentation - we provide theoretical and empirical evidence (MNIST, CIFAR-{10,100}, and SVHN) that our approach has more efficient training and better classification results than data augmentation and active learning.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1904.11643.pdf'},\n",
              "      'pubDate': '2019-04-26',\n",
              "      'pubUpdateDate': '2019-04-26',\n",
              "      'scorecardStats': [{'citationCount': 30,\n",
              "        'keyCitationCount': 7,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP',\n",
              "       'Anansi',\n",
              "       'MAG',\n",
              "       'ArXiv',\n",
              "       'MAG',\n",
              "       'ScienceParseMerged'],\n",
              "      'title': 'Bayesian Generative Active Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'This paper proposes a Bayesian generative active deep learning approach that combines active learning with data augmentation and provides theoretical and empirical evidence that this approach has more efficient training and better classification results than data augmented and active learning.'},\n",
              "      'venue': 'ICML',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Abien Fred Agarap', 'Francis John Hill Pepito'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 9.666666666666666,\n",
              "       'citedByBuckets': [{'count': 10, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 14, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 5, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 46.90017344539645,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.06896551724137931,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 29,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 7,\n",
              "       'numReferences': 20,\n",
              "       'numViewableReferences': 20},\n",
              "      'entities': ['Malware',\n",
              "       'Deep learning',\n",
              "       'Support vector machine',\n",
              "       'Information security',\n",
              "       'Multinomial logistic regression',\n",
              "       'Dropout (neural networks)',\n",
              "       'Binary file',\n",
              "       'Memory-level parallelism'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '241a36814ea7ca444748cc3609647312ae886671',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1801.00318'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1801.00318.pdf'}],\n",
              "      'paperAbstract': 'Effective and efficient mitigation of malware is a long-time endeavor in the information security community. The development of an anti-malware system that can counteract an unknown malware is a prolific activity that may benefit several sectors. We envision an intelligent anti-malware system that utilizes the power of deep learning (DL) models. Using such models would enable the detection of newly-released malware through mathematical generalization. That is, finding the relationship between a given malware $x$ and its corresponding malware family $y$, $f: x \\\\mapsto y$. To accomplish this feat, we used the Malimg dataset (Nataraj et al., 2011) which consists of malware images that were processed from malware binaries, and then we trained the following DL models 1 to classify each malware family: CNN-SVM (Tang, 2013), GRU-SVM (Agarap, 2017), and MLP-SVM. Empirical evidence has shown that the GRU-SVM stands out among the DL models with a predictive accuracy of ~84.92%. This stands to reason for the mentioned model had the relatively most sophisticated architecture design among the presented models. The exploration of an even more optimal DL-SVM model is the next stage towards the engineering of an intelligent anti-malware system.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1801.00318.pdf'},\n",
              "      'pubDate': '2017-12-31',\n",
              "      'pubUpdateDate': '2017-12-31',\n",
              "      'scorecardStats': [{'citationCount': 29,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv',\n",
              "       'DBLP',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'MAG'],\n",
              "      'title': 'Towards Building an Intelligent Anti-Malware System: A Deep Learning Approach using Support Vector Machine (SVM) for Malware Classification',\n",
              "      'tldr': {'abstractSimilarityScore': 47,\n",
              "       'text': 'The exploration of an even more optimal DL-SVM model is the next stage towards the engineering of an intelligent anti-malware system that utilizes the power of deep learning models.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2018'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['R. David',\n",
              "       'J. Duke',\n",
              "       'Advait Jain',\n",
              "       'V. Reddi',\n",
              "       'Nat Jeffries',\n",
              "       'Jian Li',\n",
              "       'Nick Kreeger',\n",
              "       'Ian Nappier',\n",
              "       'Meghna Natraj',\n",
              "       'Shlomi Regev',\n",
              "       'Rocky Rhodes',\n",
              "       'Tiezhen Wang',\n",
              "       'Pete Warden'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 9.333333333333334,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 3, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 24, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 22.56005843326001,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.03571428571428571,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 28,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 7,\n",
              "       'numReferences': 37,\n",
              "       'numViewableReferences': 37},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '1ed1cf769e540d9ad5ce5cdc17d69bf738993257',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2010.08678'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2010.08678.pdf'}],\n",
              "      'paperAbstract': \"Deep learning inference on embedded devices is a burgeoning field with myriad applications because tiny embedded devices are omnipresent. But we must overcome major challenges before we can benefit from this opportunity. Embedded processors are severely resource constrained. Their nearest mobile counterparts exhibit at least a 100---1,000x difference in compute capability, memory availability, and power consumption. As a result, the machine-learning (ML) models and associated ML inference framework must not only execute efficiently but also operate in a few kilobytes of memory. Also, the embedded devices' ecosystem is heavily fragmented. To maximize efficiency, system vendors often omit many features that commonly appear in mainstream systems, including dynamic memory allocation and virtual memory, that allow for cross-platform interoperability. The hardware comes in many flavors (e.g., instruction-set architecture and FPU support, or lack thereof). We introduce TensorFlow Lite Micro (TF Micro), an open-source ML inference framework for running deep-learning models on embedded systems. TF Micro tackles the efficiency requirements imposed by embedded-system resource constraints and the fragmentation challenges that make cross-platform interoperability nearly impossible. The framework adopts a unique interpreter-based approach that provides flexibility while overcoming these challenges. This paper explains the design decisions behind TF Micro and describes its implementation details. Also, we present an evaluation to demonstrate its low resource requirement and minimal run-time performance overhead.\",\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2010.08678.pdf'},\n",
              "      'pubDate': '2020-10-17',\n",
              "      'pubUpdateDate': '2020-10-20',\n",
              "      'scorecardStats': [{'citationCount': 28,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ArXiv',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'TensorFlow Lite Micro: Embedded Machine Learning on TinyML Systems',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': 'TensorFlow Lite Micro is introduced, an open-source ML inference framework for running deep-learning models on embedded systems that tackles the efficiency requirements imposed by embedded-system resource constraints and the fragmentation challenges that make cross-platform interoperability nearly impossible.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09078761.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2020.2990528'}],\n",
              "      'authors': ['Dhiraj Neupane', 'Jong-Hoon Seok'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 13.5,\n",
              "       'citedByBuckets': [{'count': 7, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 20, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 19.76160976492098,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 27,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 12,\n",
              "       'numReferences': 181,\n",
              "       'numViewableReferences': 181},\n",
              "      'entities': ['Deep learning'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'ea92c55c01b9b216a69b07b7687d6382324636d5',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '93155-93178',\n",
              "       'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9078761'}],\n",
              "      'paperAbstract': 'A smart factory is a highly digitized and connected production facility that relies on smart manufacturing. Additionally, artificial intelligence is the core technology of smart factories. The use of machine learning and deep learning algorithms has produced fruitful results in many fields like image processing, speech recognition, fault detection, object detection, or medical sciences. With the increment in the use of smart machinery, the faults in the machinery equipment are expected to increase. Machinery fault detection and diagnosis through various deep learning algorithms has increased day by day. Many types of research have been done and published using both open-source and closed-source datasets, implementing the deep learning algorithms. Out of many publicly available datasets, Case Western Reserve University (CWRU) bearing dataset has been widely used to detect and diagnose machinery bearing fault and is accepted as a standard reference for validating the models. This paper summarizes the recent works which use the CWRU bearing dataset in machinery fault detection and diagnosis employing deep learning algorithms. We have reviewed the published works and presented the working algorithm, result, and other necessary details in this paper. This paper, we believe, can be of good help for future researchers to start their work on machinery fault detection and diagnosis using the CWRU dataset.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9078761'},\n",
              "      'pubDate': '2020-04-27',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 27,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['IEEE',\n",
              "       'Crossref',\n",
              "       'MergedPDFExtraction',\n",
              "       'Unpaywall',\n",
              "       'DBLP',\n",
              "       'MAG'],\n",
              "      'title': 'Bearing Fault Detection and Diagnosis Using Case Western Reserve University Dataset With Deep Learning Approaches: A Review',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'This paper summarizes the recent works which use the CWRU bearing dataset in machinery fault detection and diagnosis employing deep learning algorithms and can be of good help for future researchers to start their work on machinery fault Detection and diagnosis using the C WRU dataset.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'}]}},\n",
              "  {'Page': {'N_Page': 7,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08631171.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2891588'}],\n",
              "      'authors': ['Y. Li', 'Kaiqi Xiong', 'Tommy Chin', 'Chengbin Hu'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 9.0,\n",
              "       'citedByBuckets': [{'count': 4, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 16, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 7, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 46.97356803112738,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.14814814814814814,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 27,\n",
              "       'numKeyCitations': 4,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 0,\n",
              "       'numViewableReferences': 0},\n",
              "      'entities': ['Domain generation algorithm',\n",
              "       'Machine learning',\n",
              "       'Malware',\n",
              "       'Deep learning',\n",
              "       'Hidden Markov model',\n",
              "       'Cluster analysis',\n",
              "       'Time series',\n",
              "       'Artificial neural network',\n",
              "       'Real life',\n",
              "       'Sensor',\n",
              "       'Server (computing)',\n",
              "       'Real-time locating system',\n",
              "       'Markov chain'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '1ad38ef0be72f871af579acba4dad3e2169ab17d',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '32765-32782',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8631171'}],\n",
              "      'paperAbstract': 'Attackers usually use a command and control (C2) server to manipulate the communication. In order to perform an attack, threat actors often employ a domain generation algorithm (DGA), which can allow malware to communicate with C2 by generating a variety of network locations. Traditional malware control methods, such as blacklisting, are insufficient to handle DGA threats. In this paper, we propose a machine learning framework for identifying and detecting DGA domains to alleviate the threat. We collect real-time threat data from the real-life traffic over a one-year period. We also propose a deep learning model to classify a large number of DGA domains. The proposed machine learning framework consists of a two-level model and a prediction model. In the two-level model, we first classify the DGA domains apart from normal domains and then use the clustering method to identify the algorithms that generate those DGA domains. In the prediction model, a time-series model is constructed to predict incoming domain features based on the hidden Markov model (HMM). Furthermore, we build a deep neural network (DNN) model to enhance the proposed machine learning framework by handling the huge dataset we gradually collected. Our extensive experimental results demonstrate the accuracy of the proposed framework and the DNN model. To be precise, we achieve an accuracy of 95.89% for the classification in the framework and 97.79% in the DNN model, 92.45% for the second-level clustering, and 95.21% for the HMM prediction in the framework.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8631171'},\n",
              "      'pubDate': '2019-01-31',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 27,\n",
              "        'keyCitationCount': 4,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'IEEE', 'Unpaywall', 'MAG'],\n",
              "      'title': 'A Machine Learning Framework for Domain Generation Algorithm-Based Malware Detection',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'This paper collects real-time threat data from the real-life traffic over a one-year period and builds a deep neural network model to enhance the proposed machine learning framework by handling the huge dataset it gradually collected.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://research.tees.ac.uk/ws/files/8498798/Manuscript.pdf'}],\n",
              "      'authors': ['Nazia Hameed', 'A. Shabut', 'M. K. Ghosh', 'M. A. Hossain'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.08333333333333333,\n",
              "       'citationVelocity': 8.333333333333334,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 12, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 13, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 29.01064172400368,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.038461538461538464,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 26,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 6,\n",
              "       'numReferences': 119,\n",
              "       'numViewableReferences': 119},\n",
              "      'entities': ['Algorithm', 'Machine learning', 'Deep learning'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '350721104abeeba33aa1414e9110dc1fb10c9a3e',\n",
              "      'journal': {'name': 'Expert Syst. Appl.', 'volume': '141'},\n",
              "      'links': [{'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1016/j.eswa.2019.112961'}],\n",
              "      'paperAbstract': 'Abstract Skin diseases remain a major cause of disability worldwide and contribute approximately 1.79% of the global burden of disease measured in disability-adjusted life years. In the United Kingdom alone, 60% of the population suffer from skin diseases during their lifetime. In this paper, we propose an intelligent digital diagnosis scheme to improve the classification accuracy of multiple diseases. A Multi-Class Multi-Level (MCML) classification algorithm inspired by the “divide and conquer” rule is explored to address the research challenges. The MCML classification algorithm is implemented using traditional machine learning and advanced deep learning approaches. Improved techniques are proposed for noise removal in the traditional machine learning approach. The proposed algorithm is evaluated on 3672 classified images, collected from different sources and the diagnostic accuracy of 96.47% is achieved. To verify the performance of the proposed algorithm, its metrics are compared with the Multi-Class Single-Level classification algorithm which is the main algorithm used in most of the existing literature. The results also indicate that the MCML classification algorithm is capable of enhancing the classification performance of multiple skin lesions.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'doi',\n",
              "       'url': 'https://doi.org/10.1016/j.eswa.2019.112961'},\n",
              "      'pubDate': '2020-03-01',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 26,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Unpaywall',\n",
              "       'Crossref',\n",
              "       'Anansi',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP'],\n",
              "      'title': 'Multi-class multi-level classification algorithm for skin lesions classification using machine learning techniques',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'A Multi-Class Multi-Level (MCML) classification algorithm inspired by the “divide and conquer” rule is explored to address the research challenges and indicates that the MCML classification algorithm is capable of enhancing the classification performance of multiple skin lesions.'},\n",
              "      'venue': 'Expert Syst. Appl.',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/08964364.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2020.2968537'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://e-space.mmu.ac.uk/625217/1/2020-Access-%20Realizing%20an%20Efficient%20IoMT-Assisted.pdf'}],\n",
              "      'authors': ['C. Iwendi',\n",
              "       'Suleman Khan',\n",
              "       'J. H. Anajemba',\n",
              "       'A. Bashir',\n",
              "       'Fazal Noor'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.26666666666666666,\n",
              "       'citationVelocity': 13.0,\n",
              "       'citedByBuckets': [{'count': 15, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 11, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 19.918369473642315,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 26,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 53,\n",
              "       'numViewableReferences': 53},\n",
              "      'entities': ['Machine learning',\n",
              "       'Deep learning',\n",
              "       'Long short-term memory',\n",
              "       'Multilayer perceptron',\n",
              "       'Recurrent neural network',\n",
              "       'Recommender system',\n",
              "       'Logistic regression',\n",
              "       'Naive Bayes classifier',\n",
              "       'Design rationale',\n",
              "       'Algorithm',\n",
              "       'Random neural network'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '5670ce06f2437c966b526e1dcccb8483c74621e8',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '28462-28474',\n",
              "       'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8964364'}],\n",
              "      'paperAbstract': 'Recent studies have shown that robust diets recommended to patients by Dietician or an Artificial Intelligent automated medical diet based cloud system can increase longevity, protect against further disease, and improve the overall quality of life. However, medical personnel are yet to fully understand patient-dietician’s rationale of recommender system. This paper proposes a deep learning solution for health base medical dataset that automatically detects which food should be given to which patient base on the disease and other features like age, gender, weight, calories, protein, fat, sodium, fiber, cholesterol. This research framework is focused on implementing both machine and deep learning algorithms like, logistic regression, naive bayes, Recurrent Neural Network (RNN), Multilayer Perceptron (MLP), Gated Recurrent Units (GRU), and Long Short-Term Memory (LSTM). The medical dataset collected through the internet and hospitals consists of 30 patient’s data with 13 features of different diseases and 1000 products. Product section has 8 features set. The features of these IoMT data were analyzed and further encoded before applying deep and machine and learning-based protocols. The performance of various machine learning and deep learning techniques was carried and the result proves that LSTM technique performs better than other scheme with respect to forecasting accuracy, recall, precision, and <inline-formula> <tex-math notation=\"LaTeX\">$F1$ </tex-math></inline-formula>-measures. We achieved 97.74% accuracy using LSTM deep learning model. Similarly 98% precision, 99% recall and <inline-formula> <tex-math notation=\"LaTeX\">$99\\\\%~F1$ </tex-math></inline-formula>-measure for allowed class is achieved, and for not-allowed class precision is 89%, recall score is 73% and <inline-formula> <tex-math notation=\"LaTeX\">$F1$ </tex-math></inline-formula> Measure score is 80%.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8964364'},\n",
              "      'pubDate': '2020-01-21',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 26,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'DBLP',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'Crossref',\n",
              "       'Unpaywall',\n",
              "       'IEEE'],\n",
              "      'title': 'Realizing an Efficient IoMT-Assisted Patient Diet Recommendation System Through Machine Learning Model',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'A deep learning solution for health base medical dataset that automatically detects which food should be given to which patient base on the disease and other features like age, gender, weight, calories, protein, fat, sodium, fiber, cholesterol is proposed.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Camille Castera',\n",
              "       'J. Bolte',\n",
              "       'C. Févotte',\n",
              "       'Edouard Pauwels'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.08333333333333333,\n",
              "       'citationVelocity': 8.333333333333334,\n",
              "       'citedByBuckets': [{'count': 2, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 12, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 11, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 16.204612196758294,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.12,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 25,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 10,\n",
              "       'numReferences': 66,\n",
              "       'numViewableReferences': 66},\n",
              "      'entities': ['Algorithm',\n",
              "       'Deep learning',\n",
              "       'Computer vision',\n",
              "       'Rectifier (neural networks)',\n",
              "       'Newton',\n",
              "       'Backpropagation',\n",
              "       'Artificial neural network',\n",
              "       'Software propagation',\n",
              "       'Lambda lifting'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '9a03bfda0ad9b8469f93fdcf304156e982c9a2ff',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1905.12278'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1905.12278.pdf'}],\n",
              "      'paperAbstract': 'We introduce a new second-order inertial optimization method for machine learning called INDIAN. It exploits the geometry of the loss function while only requiring stochastic approximations of the function values and the generalized gradients. This makes INDIAN fully implementable and adapted to large-scale optimization problems such as the training of deep neural networks. The algorithm combines both gradient-descent and Newton-like behaviors as well as inertia. We prove the convergence of INDIAN for most deep learning problems. To do so, we provide a well-suited framework to analyze deep learning loss functions involving tame optimization in which we study the continuous dynamical system together with the discrete stochastic approximations. We prove sublinear convergence for the continuous-time differential inclusion which underlies our algorithm. Besides, we also show how standard optimization mini-batch methods applied to nonsmooth nonconvex problems can yield a certain type of spurious stationary points never discussed before. We address this issue by providing a theoretical framework around the new idea of $D$-criticality; we then give a simple asymptotic analysis of INDIAN. Our algorithm allows for using an aggressive learning rate of $o(1/\\\\log k)$. From an empirical viewpoint, we show that INDIAN returns competitive results with respect to state of the art (stochastic gradient descent, ADAGRAD, ADAM) on popular deep learning benchmark problems.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1905.12278.pdf'},\n",
              "      'pubDate': '2019-05-27',\n",
              "      'pubUpdateDate': '2021-07-28',\n",
              "      'scorecardStats': [{'citationCount': 25,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'ArXiv',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'An Inertial Newton Algorithm for Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 94,\n",
              "       'text': 'This work introduces a new second-order inertial optimization method for machine learning called INDIAN, which exploits the geometry of the loss function while only requiring stochastic approximations of the function values and the generalized gradients.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'dblp',\n",
              "        'url': 'https://doi.org/10.1016/j.eswa.2019.03.042'}],\n",
              "      'authors': ['Eunji Kim',\n",
              "       'Jehyuk Lee',\n",
              "       'Hunsik Shin',\n",
              "       'Hoseong Yang',\n",
              "       'S. Cho',\n",
              "       'Seung-kwan Nam',\n",
              "       'Youngmi Song',\n",
              "       'Jeong-a Yoon',\n",
              "       'Jong-Il Kim'],\n",
              "      'badges': [],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 8.333333333333334,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 17, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 7, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 35.73590401415039,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.12,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 25,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 37,\n",
              "       'numViewableReferences': 37},\n",
              "      'entities': ['Deep learning',\n",
              "       'Credit card fraud',\n",
              "       'Machine learning',\n",
              "       'Transaction data',\n",
              "       'Authorization',\n",
              "       'Usability',\n",
              "       'Online and offline'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'f18f2c355f1b186d3ace3590582cb0a243ab2da2',\n",
              "      'journal': {'name': 'Expert Syst. Appl.',\n",
              "       'pages': '214-224',\n",
              "       'volume': '128'},\n",
              "      'links': [{'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1016/J.ESWA.2019.03.042'}],\n",
              "      'paperAbstract': 'Abstract Credit card fraud detection is an essential part of screening fraudulent transactions in advance of their authorization by card issuers. Although credit card frauds occur extremely infrequently, they result in huge losses as most fraudulent transactions have large values. An adequate detection of fraud allows investigators to take timely actions that can potentially prevent additional fraud or financial losses. In practice, however, investigators can only check a few alerts per day since the investigation process can be long and tedious. Thus, the primary goal of the fraud detection model is to return accurate alerts with fewer false alarms and missed frauds. Conventional fraud detection is mainly based on the hybrid ensemble of diverse machine learning models. Recently, several studies have compared deep learning and traditional machine learning models including ensemble. However, these studies used evaluation methods without considering that the real-world fraud detection system operated with the constraints: (i) the number of investigators who check the high-risk transactions from the data-driven scoring models are limited and (ii) the two types of misclassification, false alarms and missed frauds, have different costs. In this study, we conducted an in-depth comparison between the hybrid ensemble and deep learning method to determine whether or not to adopt the latter in our partner’s system that currently operates with the hybrid ensemble model. To compare the two, we introduced the champion-challenger framework and the development process of the two models. After developing the two models, we evaluated them on large transaction data sets taken from our partner, a major card issuing company in South Korea. We used various practical evaluation metrics appropriate for this domain that has severe class and cost imbalances. Moreover, we deployed these models in a real-world fraud detection system to check the post-launch performance for one month. The challenger outperformed the champion on both in off-line and post-launch tests.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'doi',\n",
              "       'url': 'https://doi.org/10.1016/J.ESWA.2019.03.042'},\n",
              "      'pubDate': '2019-08-15',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 25,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'MAG', 'Unpaywall'],\n",
              "      'title': 'Champion-challenger analysis for credit card fraud detection: Hybrid ensemble and deep learning',\n",
              "      'tldr': {'abstractSimilarityScore': 39,\n",
              "       'text': 'An in-depth comparison between the hybrid ensemble and deep learning method to determine whether or not to adopt the latter in a partner’s system that currently operates with the Hybrid ensemble model is conducted.'},\n",
              "      'venue': 'Expert Syst. Appl.',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'dblp',\n",
              "        'url': 'https://doi.org/10.1016/j.neucom.2019.03.084'}],\n",
              "      'authors': ['Ke Li', 'Meng Xiong', 'F. Li', 'Lei Su', 'Jingjing Wu'],\n",
              "      'badges': [],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 8.0,\n",
              "       'citedByBuckets': [{'count': 4, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 12, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 8, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 22.069260601205528,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.041666666666666664,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 24,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 31,\n",
              "       'numViewableReferences': 31},\n",
              "      'entities': ['Medical algorithm',\n",
              "       'Sparse matrix',\n",
              "       'Convolutional neural network',\n",
              "       'Autoencoder',\n",
              "       'Least squares',\n",
              "       'Multilayer perceptron',\n",
              "       'Noise reduction',\n",
              "       'Artificial neural network',\n",
              "       'Encoder',\n",
              "       'R.O.T.O.R.'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'f99eaeba907c37865fad0a18cd108a77a4f54179',\n",
              "      'journal': {'name': 'Neurocomputing',\n",
              "       'pages': '261-270',\n",
              "       'volume': '350'},\n",
              "      'links': [{'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1016/J.NEUCOM.2019.03.084'}],\n",
              "      'paperAbstract': 'Abstract This study presents a new roller bearing fault diagnosis algorithm based on a sparsity and neighborhood preserving deep extreme learning machine (SNP-DELM) and motor current signals. First, an extreme learning machine-autoencoder (ELM-AE) structure is proposed by combining an ELM and an AE. The AE is used to divide the hidden layer of the ELM. Then, sparsity and neighborhood theories are integrated into the deep network. During projection, the global and local manifold structures of the data are preserved through sparse and neighbor representations, respectively, and deep features of the data are extracted layer by layer without supervision. Finally, the signal data is classified by solving least squares. This algorithm is implemented in a rotor fault diagnosis experiment, and the results are compared with those obtained by using an ELM algorithm, a normal DELM algorithm, a stacked denoising auto encoder (SAE) algorithm and a convolutional neural network (CNN) algorithm. The experimental results demonstrate effectivity of the proposed algorithm.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'doi',\n",
              "       'url': 'https://doi.org/10.1016/J.NEUCOM.2019.03.084'},\n",
              "      'pubDate': '2019-07-20',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 24,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'Unpaywall', 'MAG'],\n",
              "      'title': 'A novel fault diagnosis algorithm for rotating machinery based on a sparsity and neighborhood preserving deep extreme learning machine',\n",
              "      'tldr': {'abstractSimilarityScore': 66,\n",
              "       'text': 'A new roller bearing fault diagnosis algorithm based on a sparsity and neighborhood preserving deep extreme learning machine (SNP-DELM) and motor current signals and the results are compared with those obtained by using an ELM algorithm, a normal DELM algorithms, a stacked denoising auto encoder (SAE) algorithm and a convolutional neural network (CNN).'},\n",
              "      'venue': 'Neurocomputing',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Yazeed Alaudah',\n",
              "       'P. Michalowicz',\n",
              "       'M. Alfarraj',\n",
              "       'G. Al-Regib'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 8.0,\n",
              "       'citedByBuckets': [{'count': 2, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 14, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 8, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 11.796055596735275,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.125,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 24,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 41,\n",
              "       'numViewableReferences': 41},\n",
              "      'entities': ['Machine learning',\n",
              "       'Deep learning',\n",
              "       'Deconvolution',\n",
              "       'Benchmark (computing)',\n",
              "       'Face',\n",
              "       'Baseline (configuration management)',\n",
              "       'Visual inspection',\n",
              "       'Open-source software',\n",
              "       'Code',\n",
              "       'Paper',\n",
              "       'Silo (dataset)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science',\n",
              "       'Geology',\n",
              "       'Engineering',\n",
              "       'Physics'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'e8d040ff7cdff42b4c0a8d1c62b47fc2a0a17e3d',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1901.07659'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1901.07659.pdf'}],\n",
              "      'paperAbstract': 'The recent interest in using deep learning for seismic interpretation tasks, such as facies classification, has been facing a significant obstacle, namely the absence of large publicly available annotated datasets for training and testing models. As a result, researchers have often resorted to annotating their own training and testing data. However, different researchers may annotate different classes, or use different train and test splits. In addition, it is common for papers that apply machine learning for facies classification to not contain quantitative results, and rather rely solely on visual inspection of the results. All of these practices have lead to subjective results and have greatly hindered the ability to compare different machine learning models against each other and understand the advantages and disadvantages of each approach. \\nTo address these issues, we open-source a fully-annotated 3D geological model of the Netherlands F3 Block. This model is based on the study of the 3D seismic data in addition to 26 well logs, and is grounded on the careful study of the geology of the region. Furthermore, we propose two baseline models for facies classification based on a deconvolution network architecture and make their codes publicly available. Finally, we propose a scheme for evaluating different models on this dataset, and we share the results of our baseline models. In addition to making the dataset and the code publicly available, this work helps advance research in this area by creating an objective benchmark for comparing the results of different machine learning approaches for facies classification.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1901.07659.pdf'},\n",
              "      'pubDate': '2019-01-12',\n",
              "      'pubUpdateDate': '2019-08-01',\n",
              "      'scorecardStats': [{'citationCount': 24,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv',\n",
              "       'ScienceParseMerged',\n",
              "       'Unpaywall',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG',\n",
              "       'MAG',\n",
              "       'DBLP'],\n",
              "      'title': 'A Machine Learning Benchmark for Facies Classification',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'This work opens-source a fully-annotated 3D geological model of the Netherlands F3 Block, based on the study of the 3D seismic data in addition to 26 well logs, and proposes two baseline models for facies classification based on a deconvolution network architecture and makes their codes publicly available.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Changhao Chen',\n",
              "       'B. Wang',\n",
              "       'Chris Xiaoxuan Lu',\n",
              "       'A. Trigoni',\n",
              "       'A. Markham'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 11.5,\n",
              "       'citedByBuckets': [{'count': 7, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 16, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 22.024622941849344,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 23,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 53,\n",
              "       'numReferences': 254,\n",
              "       'numViewableReferences': 254},\n",
              "      'entities': ['Deep learning',\n",
              "       'Simultaneous localization and mapping',\n",
              "       'Internationalization and localization',\n",
              "       'Artificial intelligence',\n",
              "       'Computer vision',\n",
              "       'Robotics',\n",
              "       'Machine learning',\n",
              "       'Odometry',\n",
              "       'Prospective search',\n",
              "       'On-board data handling',\n",
              "       'Sensor',\n",
              "       'Computation',\n",
              "       'Algorithm'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Engineering'],\n",
              "      'githubReferences': [],\n",
              "      'id': '9dd202ba65241df4a9ad643b5fe9d369d54d2821',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2006.12567'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2006.12567.pdf'}],\n",
              "      'paperAbstract': 'Deep learning based localization and mapping has recently attracted significant attention. Instead of creating hand-designed algorithms through exploitation of physical models or geometric theories, deep learning based solutions provide an alternative to solve the problem in a data-driven way. Benefiting from ever-increasing volumes of data and computational power, these methods are fast evolving into a new area that offers accurate and robust systems to track motion and estimate scenes and their structure for real-world applications. In this work, we provide a comprehensive survey, and propose a new taxonomy for localization and mapping using deep learning. We also discuss the limitations of current models, and indicate possible future directions. A wide range of topics are covered, from learning odometry estimation, mapping, to global localization and simultaneous localization and mapping (SLAM). We revisit the problem of perceiving self-motion and scene understanding with on-board sensors, and show how to solve it by integrating these modules into a prospective spatial machine intelligence system (SMIS). It is our hope that this work can connect emerging works from robotics, computer vision and machine learning communities, and serve as a guide for future researchers to apply deep learning to tackle localization and mapping problems.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2006.12567.pdf'},\n",
              "      'pubDate': '2020-06-22',\n",
              "      'pubUpdateDate': '2020-06-29',\n",
              "      'scorecardStats': [{'citationCount': 23,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv',\n",
              "       'MAG'],\n",
              "      'title': 'A Survey on Deep Learning for Localization and Mapping: Towards the Age of Spatial Machine Intelligence',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': 'This work provides a comprehensive survey, and proposes a new taxonomy for localization and mapping using deep learning, and revisits the problem of perceiving self-motion and scene understanding with on-board sensors, and shows how to solve it by integrating these modules into a prospective spatial machine intelligence system (SMIS).'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09165760.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2020.3015966'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://nmbu.brage.unit.no/nmbu-xmlui/bitstream/handle/11250/2719908/Stock+market+IEEE.pdf?isAllowed=y&sequence=2'}],\n",
              "      'authors': ['M. Nabipour',\n",
              "       'P. Nayyeri',\n",
              "       'H. Jabani',\n",
              "       'S. S.',\n",
              "       'A. Mosavi'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 11.0,\n",
              "       'citedByBuckets': [{'count': 5, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 17, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 13.786966833029465,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 22,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 30,\n",
              "       'numViewableReferences': 30},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'e3f4744f6af14e2e1079e75e8f353b10ec6a30bf',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '150199-150212',\n",
              "       'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9165760'}],\n",
              "      'paperAbstract': 'The nature of stock market movement has always been ambiguous for investors because of various influential factors. This study aims to significantly reduce the risk of trend prediction with machine learning and deep learning algorithms. Four stock market groups, namely diversified financials, petroleum, non-metallic minerals and basic metals from Tehran stock exchange, are chosen for experimental evaluations. This study compares nine machine learning models (Decision Tree, Random Forest, Adaptive Boosting (Adaboost), eXtreme Gradient Boosting (XGBoost), Support Vector Classifier (SVC), Naïve Bayes, K-Nearest Neighbors (KNN), Logistic Regression and Artificial Neural Network (ANN)) and two powerful deep learning methods (Recurrent Neural Network (RNN) and Long short-term memory (LSTM). Ten technical indicators from ten years of historical data are our input values, and two ways are supposed for employing them. Firstly, calculating the indicators by stock trading values as continuous data, and secondly converting indicators to binary data before using. Each prediction model is evaluated by three metrics based on the input ways. The evaluation results indicate that for the continuous data, RNN and LSTM outperform other prediction models with a considerable difference. Also, results show that in the binary data evaluation, those deep learning methods are the best; however, the difference becomes less because of the noticeable improvement of models’ performance in the second way.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9165760'},\n",
              "      'pubDate': None,\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 22,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'Crossref',\n",
              "       'IEEE',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'Unpaywall',\n",
              "       'MAG'],\n",
              "      'title': 'Predicting Stock Market Trends Using Machine Learning and Deep Learning Algorithms Via Continuous and Binary Data; a Comparative Analysis',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'Results show that for the continuous data, RNN and LSTM outperform other prediction models with a considerable difference, and results show that in the binary data evaluation, those deep learning methods are the best; however, the difference becomes less because of the noticeable improvement of models’ performance in the second way.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Shuoheng Yang', 'Yuxin Wang', 'X. Chu'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 10.5,\n",
              "       'citedByBuckets': [{'count': 7, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 14, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 15.343977068195453,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.047619047619047616,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 21,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 12,\n",
              "       'numReferences': 176,\n",
              "       'numViewableReferences': 176},\n",
              "      'entities': ['Neural machine translation',\n",
              "       'Deep learning',\n",
              "       'Natural language processing',\n",
              "       'Timeline',\n",
              "       'Tracing (software)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '3fa8d2a9e9a9cf3ee9626424a157888580dcfaba',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2002.07526'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2002.07526.pdf'}],\n",
              "      'paperAbstract': 'In recent years, natural language processing (NLP) has got great development with deep learning techniques. In the sub-field of machine translation, a new approach named Neural Machine Translation (NMT) has emerged and got massive attention from both academia and industry. However, with a significant number of researches proposed in the past several years, there is little work in investigating the development process of this new technology trend. This literature survey traces back the origin and principal development timeline of NMT, investigates the important branches, categorizes different research orientations, and discusses some future research trends in this field.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2002.07526.pdf'},\n",
              "      'pubDate': '2020-02-18',\n",
              "      'pubUpdateDate': '2020-02-18',\n",
              "      'scorecardStats': [{'citationCount': 21,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ArXiv', 'MergedPDFExtraction', 'DBLP', 'MAG'],\n",
              "      'title': 'A Survey of Deep Learning Techniques for Neural Machine Translation',\n",
              "      'tldr': {'abstractSimilarityScore': 45,\n",
              "       'text': 'This literature survey traces back the origin and principal development timeline of NMT, investigates the important branches, categorizes different research orientations, and discusses some future research trends in this field.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'}]}},\n",
              "  {'Page': {'N_Page': 8,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [],\n",
              "      'authors': ['Marjane Khodatars',\n",
              "       'A. Shoeibi',\n",
              "       'Navid Ghassemi',\n",
              "       'M. Jafari',\n",
              "       'Ali Khadem',\n",
              "       'Delaram Sadeghi',\n",
              "       'Parisa Moridian',\n",
              "       'Sadiq Hussain',\n",
              "       'R. Alizadehsani',\n",
              "       'A. Zare',\n",
              "       'A. Khosravi',\n",
              "       'S. Nahavandi',\n",
              "       'U. Acharya',\n",
              "       'M. Berk'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 10.5,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 20, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 30.67059218438578,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.047619047619047616,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 21,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 17,\n",
              "       'numReferences': 151,\n",
              "       'numViewableReferences': 151},\n",
              "      'entities': ['Deep learning',\n",
              "       'Computer engineering',\n",
              "       'Feature extraction',\n",
              "       'Artificial intelligence',\n",
              "       'Machine learning',\n",
              "       'System administrator',\n",
              "       'Spectrum analyzer',\n",
              "       'Algorithm',\n",
              "       'Corpus-assisted discourse studies',\n",
              "       'Informatics',\n",
              "       'Data acquisition',\n",
              "       'Electrical engineering',\n",
              "       'Smartglasses',\n",
              "       'Requirement',\n",
              "       'Boosting (machine learning)',\n",
              "       'Email',\n",
              "       'Video game rehabilitation',\n",
              "       'Canonical account',\n",
              "       'Wearable computer',\n",
              "       'CP/M'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Engineering', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '01dc8eaf2ff0db81211b1b3c3b44a359bb684cfb',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2007.01285'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2007.01285.pdf'}],\n",
              "      'paperAbstract': 'Accurate diagnosis of Autism Spectrum Disorder (ASD) is essential for its management and rehabilitation. Neuroimaging techniques that are non-invasive are disease markers and may be leveraged to aid ASD diagnosis. Structural and functional neuroimaging techniques provide physicians substantial information about the structure (anatomy and structural connectivity) and function (activity and functional connectivity) of the brain. Due to the intricate structure and function of the brain, diagnosing ASD with neuroimaging data without exploiting artificial intelligence (AI) techniques is extremely challenging. AI techniques comprise traditional machine learning (ML) approaches and deep learning (DL) techniques. Conventional ML methods employ various feature extraction and classification techniques, but in DL, the process of feature extraction and classification is accomplished intelligently and integrally. In this paper, studies conducted with the aid of DL networks to distinguish ASD were investigated. Rehabilitation tools provided by supporting ASD patients utilizing DL networks were also assessed. Finally, we presented important challenges in this automated detection and rehabilitation of ASD.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2007.01285.pdf'},\n",
              "      'pubDate': '2020-07-02',\n",
              "      'pubUpdateDate': '2020-07-11',\n",
              "      'scorecardStats': [{'citationCount': 21,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv'],\n",
              "      'title': 'Deep Learning for Neuroimaging-based Diagnosis and Rehabilitation of Autism Spectrum Disorder: A Review',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'Two studies conducted with the aid of DL networks to distinguish ASD were investigated and important challenges in this automated detection and rehabilitation of ASD were presented.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Frank E. Curtis', 'K. Scheinberg'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 1,\n",
              "         'endKey': 2017,\n",
              "         'startKey': 2017},\n",
              "        {'count': 3, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 6, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 6, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 4, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 15.231562487575719,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.05,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 20,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 6,\n",
              "       'numReferences': 100,\n",
              "       'numViewableReferences': 100},\n",
              "      'entities': ['Machine learning',\n",
              "       'Mathematical optimization',\n",
              "       'Deep learning',\n",
              "       'Logistic regression',\n",
              "       'Supervised learning',\n",
              "       'Algorithm',\n",
              "       'Linear model',\n",
              "       'Gradient method',\n",
              "       'Artificial neural network',\n",
              "       'Institute for Operations Research and the Management Sciences',\n",
              "       'First-order reduction'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '8f75f549a0daf0eba6f617d688101f7fd568a709',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1706.10207'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1706.10207.pdf'}],\n",
              "      'paperAbstract': 'The goal of this tutorial is to introduce key models, algorithms, and open questions related to the use of optimization methods for solving problems arising in machine learning. It is written with an INFORMS audience in mind, specifically those readers who are familiar with the basics of optimization algorithms, but less familiar with machine learning. We begin by deriving a formulation of a supervised learning problem and show how it leads to various optimization problems, depending on the context and underlying assumptions. We then discuss some of the distinctive features of these optimization problems, focusing on the examples of logistic regression and the training of deep neural networks. The latter half of the tutorial focuses on optimization algorithms, first for convex logistic regression, for which we discuss the use of first-order methods, the stochastic gradient method, variance reducing stochastic methods, and second-order methods. Finally, we discuss how these approaches can be employed to the training of deep neural networks, emphasizing the difficulties that arise from the complex, nonconvex structure of these models.',\n",
              "      'presentationUrls': ['https://pdfs.semanticscholar.org/8f75/f549a0daf0eba6f617d688101f7fd568a709.pdf'],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1706.10207.pdf'},\n",
              "      'pubDate': '2017-06-30',\n",
              "      'pubUpdateDate': '2017-06-30',\n",
              "      'scorecardStats': [{'citationCount': 20,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'DBLP',\n",
              "       'ArXiv',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG',\n",
              "       'Unpaywall',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'Optimization Methods for Supervised Machine Learning: From Linear Models to Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 78,\n",
              "       'text': 'The goal of this tutorial is to introduce key models, algorithms, and open questions related to the use of optimization methods for solving problems arising in machine learning, and to discuss how these approaches can be employed to the training of deep neural networks.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2017'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Yuri Gordienko',\n",
              "       'S. Stirenko',\n",
              "       'Yuriy Kochura',\n",
              "       'O. Alienin',\n",
              "       'Michail Novotarskiy',\n",
              "       'N. Gordienko'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 7,\n",
              "         'endKey': 2017,\n",
              "         'startKey': 2017},\n",
              "        {'count': 4, 'endKey': 2018, 'startKey': 2018},\n",
              "        {'count': 4, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 3, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 1, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 26.056025538099938,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 19,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 28,\n",
              "       'numViewableReferences': 28},\n",
              "      'entities': ['Machine learning',\n",
              "       'Deep learning',\n",
              "       'Electroencephalography',\n",
              "       'Cluster analysis',\n",
              "       'Principal component analysis',\n",
              "       'Multimodal interaction',\n",
              "       'Peripheral',\n",
              "       'Circuit restoration',\n",
              "       'Sensor',\n",
              "       'Gyroscope',\n",
              "       'Global Positioning System'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'ffa754c9f2ad4b8313b9f8d72aaac48fa84bd5d4',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1801.06048'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1801.06048.pdf'}],\n",
              "      'paperAbstract': 'The new method is proposed to monitor the level of current physical load and accumulated fatigue by several objective and subjective characteristics. It was applied to the dataset targeted to estimate the physical load and fatigue by several statistical and machine learning methods. The data from peripheral sensors (accelerometer, GPS, gyroscope, magnetometer) and brain-computing interface (electroencephalography) were collected, integrated, and analyzed by several statistical and machine learning methods (moment analysis, cluster analysis, principal component analysis, etc.). The hypothesis 1 was presented and proved that physical activity can be classified not only by objective parameters, but by subjective parameters also. The hypothesis 2 (experienced physical load and subsequent restoration as fatigue level can be estimated quantitatively and distinctive patterns can be recognized) was presented and some ways to prove it were demonstrated. Several \"physical load\" and \"fatigue\" metrics were proposed. The results presented allow to extend application of the machine learning methods for characterization of complex human activity patterns (for example, to estimate their actual physical load and fatigue, and give cautions and advice).',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1801.06048.pdf'},\n",
              "      'pubDate': '2017-12-30',\n",
              "      'pubUpdateDate': '2018-01-19',\n",
              "      'scorecardStats': [{'citationCount': 19,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG',\n",
              "       'DBLP',\n",
              "       'ArXiv',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'Deep Learning for Fatigue Estimation on the Basis of Multimodal Human-Machine Interactions',\n",
              "      'tldr': {'abstractSimilarityScore': 73,\n",
              "       'text': 'The new method is proposed to monitor the level of current physical load and accumulated fatigue by several objective and subjective characteristics and proved that physical activity can be classified not only by objective parameters, but by subjective parameters also.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2018'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://hal.archives-ouvertes.fr/hal-02921443/file/Survey_v16_r_comments.pdf'}],\n",
              "      'authors': ['A. Boulemtafes', 'A. Derhab', 'Y. Challal'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 9.5,\n",
              "       'citedByBuckets': [{'count': 7, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 12, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 16.84600795604319,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.05263157894736842,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 19,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 52,\n",
              "       'numViewableReferences': 52},\n",
              "      'entities': ['Deep learning'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '080bc0cf4033e779a9fa1a03d16bb488224fb070',\n",
              "      'journal': {'name': 'Neurocomputing', 'pages': '21-45', 'volume': '384'},\n",
              "      'links': [{'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1016/j.neucom.2019.11.041'}],\n",
              "      'paperAbstract': 'Abstract Deep learning is one of the advanced approaches of machine learning, and has attracted a growing attention in the recent years. It is used nowadays in different domains and applications such as pattern recognition, medical prediction, and speech recognition. Differently from traditional learning algorithms, deep learning can overcome the dependency on hand-designed features. Deep learning experience is particularly improved by leveraging powerful infrastructures such as clouds and adopting collaborative learning for model training. However, this comes at the expense of privacy, especially when sensitive data are processed during the training and the prediction phases, as well as when training model is shared. In this paper, we provide a review of the existing privacy-preserving deep learning techniques, and propose a novel multi-level taxonomy, which categorizes the current state-of-the-art privacy-preserving deep learning techniques on the basis of privacy-preserving tasks at the top level, and key technological concepts at the base level. This survey further summarizes evaluation results of the reviewed solutions with respect to defined performance metrics. In addition, it derives a set of learned lessons from each privacy-preserving task. Finally, it highlights open research challenges and provides some recommendations as future research directions.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'doi',\n",
              "       'url': 'https://doi.org/10.1016/j.neucom.2019.11.041'},\n",
              "      'pubDate': '2020-04-07',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 19,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG', 'Crossref', 'Unpaywall', 'DBLP'],\n",
              "      'title': 'A review of privacy-preserving techniques for deep learning',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'A novel multi-level taxonomy is proposed, which categorizes the current state-of-the-art privacy-preserving deep learning techniques on the basis of privacy- Preserving tasks at the top level, and key technological concepts at the base level.'},\n",
              "      'venue': 'Neurocomputing',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Quentin Cappart',\n",
              "       'Emmanuel Goutierre',\n",
              "       'David Bergman',\n",
              "       'Louis-Martin Rousseau'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 3,\n",
              "         'endKey': 2019,\n",
              "         'startKey': 2019},\n",
              "        {'count': 8, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 6, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 18.51527284575007,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.1111111111111111,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 18,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 4,\n",
              "       'numReferences': 51,\n",
              "       'numViewableReferences': 51},\n",
              "      'entities': ['Reinforcement learning',\n",
              "       'Machine learning',\n",
              "       'Mathematical optimization',\n",
              "       'Diagram',\n",
              "       'Independent set (graph theory)',\n",
              "       'Maximum cut',\n",
              "       'Combinatorial optimization',\n",
              "       'Discrete optimization',\n",
              "       'Heuristic (computer science)',\n",
              "       'Constraint programming',\n",
              "       'Optimization problem',\n",
              "       'Emoticon',\n",
              "       'Generative model',\n",
              "       'Program optimization',\n",
              "       'Critical graph',\n",
              "       'Experiment',\n",
              "       'Approximation algorithm',\n",
              "       'Scalability',\n",
              "       'Decision problem',\n",
              "       'Linear programming relaxation',\n",
              "       'Synthetic intelligence'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'a1354feb54a9a6014afac691a8ca991f22921ad6',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1809.03359'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1809.03359.pdf'}],\n",
              "      'paperAbstract': 'Finding tight bounds on the optimal solution is a critical element of practical solution methods for discrete optimization problems. In the last decade, decision diagrams (DDs) have brought a new perspective on obtaining upper and lower bounds that can be significantly better than classical bounding mechanisms, such as linear relaxations. It is well known that the quality of the bound achieved through this flexible bounding method is highly reliant on the ordering of variables chosen for building the diagram, and finding an ordering that optimizes standard metrics, or even improving one, is an NP-hard problem. In this paper, we propose an innovative and generic approach based on deep reinforcement learning for obtaining an ordering for tightening the bounds obtained with relaxed and restricted DDs. We apply the approach to both the Maximum Independent Set Problem and the Maximum Cut Problem. Experimental results on synthetic instances show that the deep reinforcement learning approach, by achieving tighter objective function bounds, generally outperforms ordering methods commonly used in the literature when the distribution of instances is known. To the best knowledge of the authors, this is the first paper to apply machine learning to directly improve relaxation bounds obtained by general-purpose bounding mechanisms for combinatorial optimization problems.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1809.03359.pdf'},\n",
              "      'pubDate': '2018-09-10',\n",
              "      'pubUpdateDate': '2019-07-17',\n",
              "      'scorecardStats': [{'citationCount': 18,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MergedPDFExtraction',\n",
              "       'Unpaywall',\n",
              "       'Anansi',\n",
              "       'DBLP',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'DBLP',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'MAG',\n",
              "       'ArXiv',\n",
              "       'MAG',\n",
              "       'ScienceParseMerged'],\n",
              "      'title': 'Improving Optimization Bounds using Machine Learning: Decision Diagrams meet Deep Reinforcement Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'Experimental results on synthetic instances show that the deep reinforcement learning approach, by achieving tighter objective function bounds, generally outperforms ordering methods commonly used in the literature when the distribution of instances is known.'},\n",
              "      'venue': 'AAAI',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/08948030.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2963426'}],\n",
              "      'authors': ['Seungwan Seo',\n",
              "       'Czangyeob Kim',\n",
              "       'Haedong Kim',\n",
              "       'Kyounghyun Mo',\n",
              "       'Pilsung Kang'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 9.0,\n",
              "       'citedByBuckets': [{'count': 10, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 8, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 24.52343254865427,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.05555555555555555,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 18,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 10,\n",
              "       'numReferences': 69,\n",
              "       'numViewableReferences': 69},\n",
              "      'entities': ['Deep learning',\n",
              "       'Statistical classification',\n",
              "       'Recurrent neural network',\n",
              "       'Convolutional neural network',\n",
              "       'Performance',\n",
              "       'Machine learning',\n",
              "       'Artificial neural network'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '91260fca91b7cec43a4e2939f46b49f1cd254d11',\n",
              "      'journal': {'name': 'IEEE Access', 'pages': '6861-6875', 'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8948030'}],\n",
              "      'paperAbstract': 'The purpose of sentiment classification is to determine whether a particular document has a positive or negative nuance. Sentiment classification is extensively used in many business domains to improve products or services by understanding the opinions of customers regarding these products. Deep learning achieves state-of-the-art results in various challenging domains. With the success of deep learning, many studies have proposed deep-learning-based sentiment classification models and achieved better performances compared with conventional machine learning models. However, one practical issue occurring in deep-learning-based sentiment classification is that the best model structure depends on the characteristics of the dataset on which the deep learning model is trained; moreover, it is manually determined based on the domain knowledge of an expert or selected from a grid search of possible candidates. Herein, we present a comparative study of different deep-learning-based sentiment classification model structures to derive meaningful implications for building sentiment classification models. Specifically, eight deep-learning models, three based on convolutional neural networks and five based on recurrent neural networks, with two types of input structures, i.e., word level and character level, are compared for 13 review datasets, and the classification performances are discussed under different perspectives.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8948030'},\n",
              "      'pubDate': None,\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 18,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG',\n",
              "       'Crossref',\n",
              "       'IEEE',\n",
              "       'Unpaywall',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'Comparative Study of Deep Learning-Based Sentiment Classification',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'Eight deep-learning models, three based on convolutional neural networks and five based on recurrent neural networks, with two types of input structures, i.e., word level and character level, are compared for 13 review datasets and the classification performances are discussed under different perspectives.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Sidra Mehtab', 'Jaydip Sen', 'Abhishek Dutta'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 8.5,\n",
              "       'citedByBuckets': [{'count': 3, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 14, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 71.82852040090518,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 17,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 35,\n",
              "       'numViewableReferences': 35},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Economics', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'dca24b733bc182745f11159d223a890333721ee8',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2009.10819'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2009.10819.pdf'}],\n",
              "      'paperAbstract': 'Prediction of stock prices has been an important area of research for a long time. While supporters of the efficient market hypothesis believe that it is impossible to predict stock prices accurately, there are formal propositions demonstrating that accurate modeling and designing of appropriate variables may lead to models using which stock prices and stock price movement patterns can be very accurately predicted. In this work, we propose an approach of hybrid modeling for stock price prediction building different machine learning and deep learning-based models. For the purpose of our study, we have used NIFTY 50 index values of the National Stock Exchange (NSE) of India, during the period December 29, 2014 till July 31, 2020. We have built eight regression models using the training data that consisted of NIFTY 50 index records during December 29, 2014 till December 28, 2018. Using these regression models, we predicted the open values of NIFTY 50 for the period December 31, 2018 till July 31, 2020. We, then, augment the predictive power of our forecasting framework by building four deep learning-based regression models using long-and short-term memory (LSTM) networks with a novel approach of walk-forward validation. We exploit the power of LSTM regression models in forecasting the future NIFTY 50 open values using four different models that differ in their architecture and in the structure of their input data. Extensive results are presented on various metrics for the all the regression models. The results clearly indicate that the LSTM-based univariate model that uses one-week prior data as input for predicting the next week open value of the NIFTY 50 time series is the most accurate model.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2009.10819.pdf'},\n",
              "      'pubDate': '2020-09-20',\n",
              "      'pubUpdateDate': '2020-09-20',\n",
              "      'scorecardStats': [{'citationCount': 17,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref', 'DBLP', 'ArXiv', 'MergedPDFExtraction', 'MAG'],\n",
              "      'title': 'Stock Price Prediction Using Machine Learning and LSTM-Based Deep Learning Models',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'This work proposes an approach of hybrid modeling for stock price prediction building different machine learning and deep learning-based models using long-and short-term memory (LSTM) networks with a novel approach of walk-forward validation and exploits the power of LSTM regression models in forecasting the future NIFTY 50 open values.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['O. Gencoglu',\n",
              "       'M. Gils',\n",
              "       'E. Guldogan',\n",
              "       'Chamin Morikawa',\n",
              "       'Mehmet Süzen',\n",
              "       'M. Gruber',\n",
              "       'J. Leinonen',\n",
              "       'H. Huttunen'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 1,\n",
              "         'endKey': 2018,\n",
              "         'startKey': 2018},\n",
              "        {'count': 3, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 5, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 8, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 19.852825590095893,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.11764705882352941,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 17,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 7,\n",
              "       'numReferences': 100,\n",
              "       'numViewableReferences': 100},\n",
              "      'entities': ['Machine learning',\n",
              "       'Deep learning',\n",
              "       'Speech recognition',\n",
              "       'Algorithm',\n",
              "       'Descent',\n",
              "       'Real life',\n",
              "       'The Grid Analysis and Display System (GrADS)',\n",
              "       'Behavior',\n",
              "       'Generalization (Psychology)',\n",
              "       'Physical object'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'BLOG'}, 'count': 1}],\n",
              "      'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'f338535b03a70abae3de4597584d57f423b2d48b',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1904.07633'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1904.07633.pdf'}],\n",
              "      'paperAbstract': 'Recent advancements in machine learning research, i.e., deep learning, introduced methods that excel conventional algorithms as well as humans in several complex tasks, ranging from detection of objects in images and speech recognition to playing difficult strategic games. However, the current methodology of machine learning research and consequently, implementations of the real-world applications of such algorithms, seems to have a recurring HARKing (Hypothesizing After the Results are Known) issue. In this work, we elaborate on the algorithmic, economic and social reasons and consequences of this phenomenon. We present examples from current common practices of conducting machine learning research (e.g. avoidance of reporting negative results) and failure of generalization ability of the proposed algorithms and datasets in actual real-life usage. Furthermore, a potential future trajectory of machine learning research and development from the perspective of accountable, unbiased, ethical and privacy-aware algorithmic decision making is discussed. We would like to emphasize that with this discussion we neither claim to provide an exhaustive argumentation nor blame any specific institution or individual on the raised issues. This is simply a discussion put forth by us, insiders of the machine learning field, reflecting on us.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1904.07633.pdf'},\n",
              "      'pubDate': '2019-04-16',\n",
              "      'pubUpdateDate': '2019-04-16',\n",
              "      'scorecardStats': [{'citationCount': 17,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'ArXiv',\n",
              "       'MAG'],\n",
              "      'title': 'HARK Side of Deep Learning - From Grad Student Descent to Automated Machine Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'This work elaborate on the algorithmic, economic and social reasons and consequences of HARKing, and presents examples from current common practices of conducting machine learning research and failure of generalization ability of the proposed algorithms and datasets in actual real-life usage.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Qian Zhang',\n",
              "       'Yeqi Liu',\n",
              "       'Chuanyang Gong',\n",
              "       'Yingyi Chen',\n",
              "       'HuiHui Yu'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 5.666666666666667,\n",
              "       'citedByBuckets': [{'count': 1, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 7, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 9, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 32.07342672539197,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.058823529411764705,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 17,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 12,\n",
              "       'numReferences': 130,\n",
              "       'numViewableReferences': 130},\n",
              "      'entities': ['Learning Disorders',\n",
              "       'Neural Network Simulation',\n",
              "       'Bio-Informatics',\n",
              "       'Obstruction'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Medicine'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'ac0d024d53c1e6252229217c79fcd3b1f5d91caf',\n",
              "      'journal': {'name': 'Sensors (Basel, Switzerland)', 'volume': '20'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/4c03/f4292270757020ca1162a494ce60038a25cd.pdf'}],\n",
              "      'paperAbstract': 'Deep Learning (DL) is the state-of-the-art machine learning technology, which shows superior performance in computer vision, bioinformatics, natural language processing, and other areas. Especially as a modern image processing technology, DL has been successfully applied in various tasks, such as object detection, semantic segmentation, and scene analysis. However, with the increase of dense scenes in reality, due to severe occlusions, and small size of objects, the analysis of dense scenes becomes particularly challenging. To overcome these problems, DL recently has been increasingly applied to dense scenes and has begun to be used in dense agricultural scenes. The purpose of this review is to explore the applications of DL for dense scenes analysis in agriculture. In order to better elaborate the topic, we first describe the types of dense scenes in agriculture, as well as the challenges. Next, we introduce various popular deep neural networks used in these dense scenes. Then, the applications of these structures in various agricultural tasks are comprehensively introduced in this review, including recognition and classification, detection, counting and yield estimation. Finally, the surveyed DL applications, limitations and the future work for analysis of dense images in agriculture are summarized.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/4c03/f4292270757020ca1162a494ce60038a25cd.pdf'},\n",
              "      'pubDate': '2020-03-01',\n",
              "      'pubUpdateDate': '2020-03-10',\n",
              "      'scorecardStats': [{'citationCount': 17,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Unpaywall',\n",
              "       'Crossref',\n",
              "       'Medline',\n",
              "       'MAG',\n",
              "       'PubMedCentral',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'Applications of Deep Learning for Dense Scenes Analysis in Agriculture: A Review',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'The applications of DL for dense scenes analysis in agriculture are explored, including recognition and classification, detection, counting and yield estimation, and various popular deep neural networks used in these dense scenes.'},\n",
              "      'venue': 'Sensors',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Stefan Blücher',\n",
              "       'Lukas Kades',\n",
              "       'J. Pawlowski',\n",
              "       'N. Strodthoff',\n",
              "       'Julian M. Urban'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 8.5,\n",
              "       'citedByBuckets': [{'count': 10, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 7, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 9.433054663169592,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 17,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 1,\n",
              "       'numReferences': 76,\n",
              "       'numViewableReferences': 76},\n",
              "      'entities': ['Machine learning',\n",
              "       'Lattice field theory',\n",
              "       'Observable',\n",
              "       'Multilayer perceptron',\n",
              "       'Deep learning',\n",
              "       'Pretext',\n",
              "       'Monte Carlo method',\n",
              "       'Phase diagram',\n",
              "       'Quantum field theory',\n",
              "       'Relevance',\n",
              "       'Algorithm',\n",
              "       'Software propagation'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Physics', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '09cb7577910887d469f76c8c7d95573e9709f4e4',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2003.01504'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2003.01504.pdf'}],\n",
              "      'paperAbstract': 'Machine learning has the potential to aid our understanding of phase structures in lattice quantum field theories through the statistical analysis of Monte Carlo samples. Available algorithms, in particular those based on deep learning, often demonstrate remarkable performance in the search for previously unidentified features, but tend to lack transparency if applied naively. To address these shortcomings, we propose representation learning in combination with interpretability methods as a framework for the identification of observables. More specifically, we investigate action parameter regression as a pretext task while using layer-wise relevance propagation (LRP) to identify the most important observables depending on the location in the phase diagram. The approach is put to work in the context of a scalar Yukawa model in (2+1)d. First, we investigate a multilayer perceptron to determine an importance hierarchy of several predefined, standard observables. The method is then applied directly to the raw field configurations using a convolutional network, demonstrating the ability to reconstruct all order parameters from the learned filter weights. Based on our results, we argue that due to its broad applicability, attribution methods such as LRP could prove a useful and versatile tool in our search for new physical insights. In the case of the Yukawa model, it facilitates the construction of an observable that characterises the symmetric phase.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2003.01504.pdf'},\n",
              "      'pubDate': '2020-03-03',\n",
              "      'pubUpdateDate': '2020-05-20',\n",
              "      'scorecardStats': [{'citationCount': 17,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'DBLP',\n",
              "       'Crossref',\n",
              "       'Unpaywall',\n",
              "       'ArXiv',\n",
              "       'MAG'],\n",
              "      'title': 'Towards Novel Insights in Lattice Field Theory with Explainable Machine Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'This work investigates action parameter regression as a pretext task while using layer-wise relevance propagation (LRP) to identify the most important observables depending on the location in the phase diagram and argues that due to its broad applicability, attribution methods such as LRP could prove a useful and versatile tool in the search for new physical insights.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'}]}},\n",
              "  {'Page': {'N_Page': 9,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [],\n",
              "      'authors': ['Faraz Malik Awan', 'Y. Saleem', 'R. Minerva', 'N. Crespi'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 8.0,\n",
              "       'citedByBuckets': [{'count': 9, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 7, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 8.09553734158187,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 16,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 26,\n",
              "       'numViewableReferences': 26},\n",
              "      'entities': ['Deep learning',\n",
              "       'Multilayer perceptron',\n",
              "       'Random forest',\n",
              "       'Decision tree',\n",
              "       'Qualitative comparative analysis',\n",
              "       'K-nearest neighbors algorithm',\n",
              "       'Ensemble learning',\n",
              "       'Application domain'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Medicine'],\n",
              "      'githubReferences': [],\n",
              "      'id': '5e22fbd9f7588be283d8c2592b49fdf3aec338b6',\n",
              "      'journal': {'name': 'Sensors (Basel, Switzerland)', 'volume': '20'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/a3f2/98ec9909eec05bb2d02789fbf84f96c2fa57.pdf'}],\n",
              "      'paperAbstract': 'Machine/Deep Learning (ML/DL) techniques have been applied to large data sets in order to extract relevant information and for making predictions. The performance and the outcomes of different ML/DL algorithms may vary depending upon the data sets being used, as well as on the suitability of algorithms to the data and the application domain under consideration. Hence, determining which ML/DL algorithm is most suitable for a specific application domain and its related data sets would be a key advantage. To respond to this need, a comparative analysis of well-known ML/DL techniques, including Multilayer Perceptron, K-Nearest Neighbors, Decision Tree, Random Forest, and Voting Classifier (or the Ensemble Learning Approach) for the prediction of parking space availability has been conducted. This comparison utilized Santander’s parking data set, initiated while working on the H2020 WISE-IoT project. The data set was used in order to evaluate the considered algorithms and to determine the one offering the best prediction. The results of this analysis show that, regardless of the data set size, the less complex algorithms like Decision Tree, Random Forest, and KNN outperform complex algorithms such as Multilayer Perceptron, in terms of higher prediction accuracy, while providing comparable information for the prediction of parking space availability. In addition, in this paper, we are providing Top-K parking space recommendations on the basis of distance between current position of vehicles and free parking spots.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/a3f2/98ec9909eec05bb2d02789fbf84f96c2fa57.pdf'},\n",
              "      'pubDate': '2020-01-01',\n",
              "      'pubUpdateDate': '2020-01-06',\n",
              "      'scorecardStats': [{'citationCount': 16,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'Medline',\n",
              "       'Unpaywall',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP',\n",
              "       'Anansi',\n",
              "       'PubMedCentral',\n",
              "       'MAG'],\n",
              "      'title': 'A Comparative Analysis of Machine/Deep Learning Models for Parking Space Availability Prediction',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'The results of this analysis show that the less complex algorithms like Decision Tree, Random Forest, and KNN outperform complex algorithms such as Multilayer Perceptron, in terms of higher prediction accuracy, while providing comparable information for the prediction of parking space availability.'},\n",
              "      'venue': 'Sensors',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/08967080.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2020.2968900'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://martingjoreski.github.io/files/08967080.pdf'}],\n",
              "      'authors': ['Martin Gjoreski',\n",
              "       'A. Gradišek',\n",
              "       'Borut Budna',\n",
              "       'M. Gams',\n",
              "       'G. Poglajen'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 7.0,\n",
              "       'citedByBuckets': [{'count': 9, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 5, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 13.149065459005644,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 14,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 4,\n",
              "       'numReferences': 54,\n",
              "       'numViewableReferences': 54},\n",
              "      'entities': ['Deep learning',\n",
              "       'Cryptographic hash function',\n",
              "       'Machine learning',\n",
              "       'Sensor',\n",
              "       'End-to-end principle',\n",
              "       'Baseline (configuration management)',\n",
              "       'Incidence matrix'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Medicine', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '463f4bc4ff08def190d808f9e6fb5b2267b251f7',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '20313-20324',\n",
              "       'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8967080'}],\n",
              "      'paperAbstract': 'Chronic heart failure (CHF) affects over 26 million of people worldwide, and its incidence is increasing by 2% annually. Despite the significant burden that CHF poses and despite the ubiquity of sensors in our lives, methods for automatically detecting CHF are surprisingly scarce, even in the research community. We present a method for CHF detection based on heart sounds. The method combines classic Machine-Learning (ML) and end-to-end Deep Learning (DL). The classic ML learns from expert features, and the DL learns from a spectro-temporal representation of the signal. The method was evaluated on recordings from 947 subjects from six publicly available datasets and one CHF dataset that was collected for this study. Using the same evaluation method as a recent PhysoNet challenge, the proposed method achieved a score of 89.3, which is 9.1 higher than the challenge’s baseline method. The method’s aggregated accuracy is 92.9% (error of 7.1%); while the experimental results are not directly comparable, this error rate is relatively close to the percentage of recordings labeled as “unknown” by experts (9.7%). Finally, we identified 15 expert features that are useful for building ML models to differentiate between CHF phases (i.e., in the decompensated phase during hospitalization and in the recompensated phase) with an accuracy of 93.2%. The proposed method shows promising results both for the distinction of recordings between healthy subjects and patients and for the detection of different CHF phases. This may lead to the easier identification of new CHF patients and the development of home-based CHF monitors for avoiding hospitalizations.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8967080'},\n",
              "      'pubDate': '2020-01-23',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 14,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'MAG',\n",
              "       'Unpaywall',\n",
              "       'IEEE',\n",
              "       'DBLP'],\n",
              "      'title': 'Machine Learning and End-to-End Deep Learning for the Detection of Chronic Heart Failure From Heart Sounds',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'The proposed method shows promising results both for the distinction of recordings between healthy subjects and patients and for the detection of different CHF phases, which may lead to the easier identification of new CHF patients and the development of home-based CHF monitors for avoiding hospitalizations.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Dingding Wang',\n",
              "       'Jiaqing Mo',\n",
              "       'Gang Zhou',\n",
              "       'Liang Xu',\n",
              "       'Yajun Liu'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 7.0,\n",
              "       'citedByBuckets': [{'count': 14, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 12.088977692607504,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.07142857142857142,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 14,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 4,\n",
              "       'numReferences': 44,\n",
              "       'numViewableReferences': 44},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Medicine'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'f8747fc9742f40193e32123614adbc89576bb847',\n",
              "      'journal': {'name': 'PLoS ONE', 'volume': '15'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/bdda/bb4ae809990983889bce5fe4c668a64bb560.pdf'}],\n",
              "      'paperAbstract': 'A newly emerged coronavirus (COVID-19) seriously threatens human life and health worldwide. In coping and fighting against COVID-19, the most critical step is to effectively screen and diagnose infected patients. Among them, chest X-ray imaging technology is a valuable imaging diagnosis method. The use of computer-aided diagnosis to screen X-ray images of COVID-19 cases can provide experts with auxiliary diagnosis suggestions, which can reduce the burden of experts to a certain extent. In this study, we first used conventional transfer learning methods, using five pre-trained deep learning models, which the Xception model showed a relatively ideal effect, and the diagnostic accuracy reached 96.75%. In order to further improve the diagnostic accuracy, we propose an efficient diagnostic method that uses a combination of deep features and machine learning classification. It implements an end-to-end diagnostic model. The proposed method was tested on two datasets and performed exceptionally well on both of them. We first evaluated the model on 1102 chest X-ray images. The experimental results show that the diagnostic accuracy of Xception + SVM is as high as 99.33%. Compared with the baseline Xception model, the diagnostic accuracy is improved by 2.58%. The sensitivity, specificity and AUC of this model reached 99.27%, 99.38% and 99.32%, respectively. To further illustrate the robustness of our method, we also tested our proposed model on another dataset. Finally also achieved good results. Compared with related research, our proposed method has higher classification accuracy and efficient diagnostic performance. Overall, the proposed method substantially advances the current radiology based methodology, it can be very helpful tool for clinical practitioners and radiologists to aid them in diagnosis and follow-up of COVID-19 cases.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/bdda/bb4ae809990983889bce5fe4c668a64bb560.pdf'},\n",
              "      'pubDate': '2020-11-17',\n",
              "      'pubUpdateDate': '2020-11-17',\n",
              "      'scorecardStats': [{'citationCount': 14,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'PubMedCentral',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'Unpaywall',\n",
              "       'Medline',\n",
              "       'WHO'],\n",
              "      'title': 'An efficient mixture of deep and machine learning models for COVID-19 diagnosis in chest X-ray images',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'An efficient diagnostic method that uses a combination of deep features and machine learning classification and implements an end-to-end diagnostic model that substantially advances the current radiology based methodology and can be very helpful tool for clinical practitioners and radiologists to aid them in diagnosis and follow-up of COVID-19 cases.'},\n",
              "      'venue': 'PloS one',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['A. Gómez',\n",
              "       'Alejandro Cervantes',\n",
              "       'Y. Sáez',\n",
              "       'P. I. Viñuela'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 4.666666666666667,\n",
              "       'citedByBuckets': [{'count': 10, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 4, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 18.04057632113203,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.21428571428571427,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 14,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 40,\n",
              "       'numViewableReferences': 40},\n",
              "      'entities': ['Trees (plant)'],\n",
              "      'entityRelations': [{'destEntityId': '63786',\n",
              "        'destEntityName': 'Leisure Activities',\n",
              "        'destEntitySlug': 'Leisure-Activities',\n",
              "        'mentionContexts': ['The dataset comprises thirteen activities , including <e1>physical activities</e1> , common postures , working activities and <e2>leisure activities</e2> .'],\n",
              "        'mentionTexts': [['physical activities', 'leisure activities']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_sibling_of'},\n",
              "        'srcEntityId': '885',\n",
              "        'srcEntityName': 'Exercise',\n",
              "        'srcEntitySlug': 'Exercise'},\n",
              "       {'destEntityId': '885',\n",
              "        'destEntityName': 'Exercise',\n",
              "        'destEntitySlug': 'Exercise',\n",
              "        'mentionContexts': ['The dataset comprises thirteen activities , including <e2>physical activities</e2> , common postures , working activities and <e1>leisure activities</e1> .'],\n",
              "        'mentionTexts': [['leisure activities', 'physical activities']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_sibling_of'},\n",
              "        'srcEntityId': '63786',\n",
              "        'srcEntityName': 'Leisure Activities',\n",
              "        'srcEntitySlug': 'Leisure-Activities'}],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Medicine'],\n",
              "      'githubReferences': [],\n",
              "      'id': '0a805099a5ceeff5af6aee77bac0416661addc3d',\n",
              "      'journal': {'name': 'Sensors (Basel, Switzerland)', 'volume': '19'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/0a80/5099a5ceeff5af6aee77bac0416661addc3d.pdf'}],\n",
              "      'paperAbstract': 'We have compared the performance of different machine learning techniques for human activity recognition. Experiments were made using a benchmark dataset where each subject wore a device in the pocket and another on the wrist. The dataset comprises thirteen activities, including physical activities, common postures, working activities and leisure activities. We apply a methodology known as the activity recognition chain, a sequence of steps involving preprocessing, segmentation, feature extraction and classification for traditional machine learning methods; we also tested convolutional deep learning networks that operate on raw data instead of using computed features. Results show that combination of two sensors does not necessarily result in an improved accuracy. We have determined that best results are obtained by the extremely randomized trees approach, operating on precomputed features and on data obtained from the wrist sensor. Deep learning architectures did not produce competitive results with the tested architecture.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/0a80/5099a5ceeff5af6aee77bac0416661addc3d.pdf'},\n",
              "      'pubDate': '2019-01-26',\n",
              "      'pubUpdateDate': '2019-01-26',\n",
              "      'scorecardStats': [{'citationCount': 14,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'Anansi',\n",
              "       'Medline',\n",
              "       'PubMedCentral',\n",
              "       'ScienceParseMerged',\n",
              "       'Unpaywall'],\n",
              "      'title': 'A Comparison of Machine Learning and Deep Learning Techniques for Activity Recognition using Mobile Devices',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'A methodology known as the activity recognition chain is applied, a sequence of steps involving preprocessing, segmentation, feature extraction and classification for traditional machine learning methods; convolutional deep learning networks that operate on raw data instead of using computed features are tested.'},\n",
              "      'venue': 'Sensors',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09064510.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2020.2987435'}],\n",
              "      'authors': ['Mingfu Xue',\n",
              "       'Chengxiang Yuan',\n",
              "       'Heyi Wu',\n",
              "       'Yushu Zhang',\n",
              "       'Weiqiang Liu'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 7.0,\n",
              "       'citedByBuckets': [{'count': 5, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 9, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 10.682096779363096,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 14,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 50,\n",
              "       'numReferences': 127,\n",
              "       'numViewableReferences': 127},\n",
              "      'entities': ['Machine learning',\n",
              "       'Deep learning',\n",
              "       'Test set',\n",
              "       'Backdoor (computing)',\n",
              "       'Threat model',\n",
              "       'Complex systems'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '3136dd4036331b4559b341560712942ca2e765e3',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '74720-74742',\n",
              "       'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9064510'}],\n",
              "      'paperAbstract': 'Machine learning has been pervasively used in a wide range of applications due to its technical breakthroughs in recent years. It has demonstrated significant success in dealing with various complex problems, and shows capabilities close to humans or even beyond humans. However, recent studies show that machine learning models are vulnerable to various attacks, which will compromise the security of the models themselves and the application systems. Moreover, such attacks are stealthy due to the unexplained nature of the deep learning models. In this survey, we systematically analyze the security issues of machine learning, focusing on existing attacks on machine learning systems, corresponding defenses or secure learning techniques, and security evaluation methods. Instead of focusing on one stage or one type of attack, this paper covers all the aspects of machine learning security from the training phase to the test phase. First, the machine learning model in the presence of adversaries is presented, and the reasons why machine learning can be attacked are analyzed. Then, the machine learning security-related issues are classified into five categories: training set poisoning; backdoors in the training set; adversarial example attacks; model theft; recovery of sensitive training data. The threat models, attack approaches, and defense techniques are analyzed systematically. To demonstrate that these threats are real concerns in the physical world, we also reviewed the attacks in real-world conditions. Several suggestions on security evaluations of machine learning systems are also provided. Last, future directions for machine learning security are also presented.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9064510'},\n",
              "      'pubDate': '2020-04-13',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 14,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['IEEE',\n",
              "       'MergedPDFExtraction',\n",
              "       'Crossref',\n",
              "       'DBLP',\n",
              "       'MAG',\n",
              "       'Unpaywall'],\n",
              "      'title': 'Machine Learning Security: Threats, Countermeasures, and Evaluations',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'This survey systematically analyzes the security issues of machine learning, focusing on existing attacks on machine learning systems, corresponding defenses or secure learning techniques, and security evaluation methods.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09165732.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2020.3016062'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://repository.kaust.edu.sa/bitstream/handle/10754/664603/Early%20detection.pdf?isAllowed=y&sequence=1'}],\n",
              "      'authors': ['Wu Wang', 'Junho Lee', 'F. Harrou', 'Ying Sun'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 6.0,\n",
              "       'citedByBuckets': [{'count': 2, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 10, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 11.108344432801948,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 12,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 5,\n",
              "       'numReferences': 74,\n",
              "       'numViewableReferences': 74},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '3f5e8e5b51b043b7f818dee5ecd365f5e1b4b194',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '147635-147646',\n",
              "       'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9165732'}],\n",
              "      'paperAbstract': 'Accurately detecting Parkinson’s disease (PD) at an early stage is certainly indispensable for slowing down its progress and providing patients the possibility of accessing to disease-modifying therapy. Towards this end, the premotor stage in PD should be carefully monitored. An innovative deep-learning technique is introduced to early uncover whether an individual is affected with PD or not based on premotor features. Specifically, to uncover PD at an early stage, several indicators have been considered in this study, including Rapid Eye Movement and olfactory loss, Cerebrospinal fluid data, and dopaminergic imaging markers. A comparison between the proposed deep learning model and twelve machine learning and ensemble learning methods based on relatively small data including 183 healthy individuals and 401 early PD patients shows the superior detection performance of the designed model, which achieves the highest accuracy, 96.45% on average. Besides detecting the PD, we also provide the feature importance on the PD detection process based on the Boosting method.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9165732'},\n",
              "      'pubDate': '2020-08-12',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 12,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'Anansi',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'Unpaywall',\n",
              "       'IEEE',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'Early Detection of Parkinson’s Disease Using Deep Learning and Machine Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'A comparison between the proposed deep learning model and twelve machine learning and ensemble learning methods based on relatively small data shows the superior detection performance of the designed model, which achieves the highest accuracy, 96.45% on average.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8948470/09062481.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2020.2986810'},\n",
              "       {'linkType': 'anansi',\n",
              "        'url': 'https://martingjoreski.github.io/files/09062481.pdf'}],\n",
              "      'authors': ['Martin Gjoreski',\n",
              "       'M. Gams',\n",
              "       'M. Luštrek',\n",
              "       'Pelin Genc',\n",
              "       'Jens-Uwe Garbas',\n",
              "       'Teena Hassan'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 5,\n",
              "         'endKey': 2020,\n",
              "         'startKey': 2020},\n",
              "        {'count': 5, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 7.531273655990582,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.1,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 10,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 8,\n",
              "       'numReferences': 81,\n",
              "       'numViewableReferences': 81},\n",
              "      'entities': ['Deep learning',\n",
              "       'Machine learning',\n",
              "       'F1 score',\n",
              "       'Sensor',\n",
              "       'Gradient boosting',\n",
              "       'Eye tracking',\n",
              "       'Overfitting',\n",
              "       'Microsoft Windows',\n",
              "       'Driving simulator',\n",
              "       'Wearable computer',\n",
              "       'Open research',\n",
              "       'End-to-end principle',\n",
              "       'Information',\n",
              "       'Simulation',\n",
              "       'Autonomous robot',\n",
              "       'Test set',\n",
              "       'Embedded system',\n",
              "       'Modality (human–computer interaction)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '818fdb9911c0901a76a854d4673c07eda3f70f9b',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '70590-70603',\n",
              "       'volume': '8'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9062481'}],\n",
              "      'paperAbstract': 'It is only a matter of time until autonomous vehicles become ubiquitous; however, human driving supervision will remain a necessity for decades. To assess the driver’s ability to take control over the vehicle in critical scenarios, driver distractions can be monitored using wearable sensors or sensors that are embedded in the vehicle, such as video cameras. The types of driving distractions that can be sensed with various sensors is an open research question that this study attempts to answer. This study compared data from physiological sensors (palm electrodermal activity (pEDA), heart rate and breathing rate) and visual sensors (eye tracking, pupil diameter, nasal EDA (nEDA), emotional activation and facial action units (AUs)) for the detection of four types of distractions. The dataset was collected in a previous driving simulation study. The statistical tests showed that the most informative feature/modality for detecting driver distraction depends on the type of distraction, with emotional activation and AUs being the most promising. The experimental comparison of seven classical machine learning (ML) and seven end-to-end deep learning (DL) methods, which were evaluated on a separate test set of 10 subjects, showed that when classifying windows into distracted or not distracted, the highest F1-score of 79% was realized by the extreme gradient boosting (XGB) classifier using 60-second windows of AUs as input. When classifying complete driving sessions, XGB’s F1-score was 94%. The best-performing DL model was a spectro-temporal ResNet, which realized an F1-score of 75% when classifying segments and an F1-score of 87% when classifying complete driving sessions. Finally, this study identified and discussed problems, such as label jitter, scenario overfitting and unsatisfactory generalization performance, that may adversely affect related ML approaches.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9062481'},\n",
              "      'pubDate': '2020-04-13',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 10,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MergedPDFExtraction',\n",
              "       'Crossref',\n",
              "       'MAG',\n",
              "       'Anansi',\n",
              "       'DBLP',\n",
              "       'IEEE',\n",
              "       'Unpaywall'],\n",
              "      'title': 'Machine Learning and End-to-End Deep Learning for Monitoring Driver Distractions From Physiological and Visual Signals',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'This study compared data from physiological sensors and visual sensors for the detection of four types of distractions and identified problems, such as label jitter, scenario overfitting and unsatisfactory generalization performance, that may adversely affect related ML approaches.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['R. Brehar',\n",
              "       'D. Mitrea',\n",
              "       'F. Vancea',\n",
              "       'T. Mariţa',\n",
              "       'S. Nedevschi',\n",
              "       'M. Platon',\n",
              "       'Magda Rotaru',\n",
              "       'R. Badea'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 2,\n",
              "         'endKey': 2020,\n",
              "         'startKey': 2020},\n",
              "        {'count': 7, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 8.101191773126473,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 9,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 7,\n",
              "       'numReferences': 46,\n",
              "       'numViewableReferences': 46},\n",
              "      'entities': ['Liver carcinoma',\n",
              "       'Parenchyma',\n",
              "       'Computer Assisted Diagnosis',\n",
              "       'Learning Disorders',\n",
              "       'Numerous',\n",
              "       'Medical Records Systems, Computerized'],\n",
              "      'entityRelations': [{'destEntityId': '702653',\n",
              "        'destEntityName': 'Medical Records Systems, Computerized',\n",
              "        'destEntitySlug': 'Medical-Records-Systems,-Computerized',\n",
              "        'mentionContexts': ['In the case of <e2>medical image</e2> processing and <e1>computer - aided diagnosis</e1> within ultrasound images , where the amount of available annotated data is smaller , a natural question arises : are deep - learning methods better than conventional machine - learning methods ?'],\n",
              "        'mentionTexts': [['computer - aided diagnosis', 'medical image']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_sibling_of'},\n",
              "        'srcEntityId': '82154',\n",
              "        'srcEntityName': 'Computer Assisted Diagnosis',\n",
              "        'srcEntitySlug': 'Computer-Assisted-Diagnosis'},\n",
              "       {'destEntityId': '82154',\n",
              "        'destEntityName': 'Computer Assisted Diagnosis',\n",
              "        'destEntitySlug': 'Computer-Assisted-Diagnosis',\n",
              "        'mentionContexts': ['In the case of <e1>medical image</e1> processing and <e2>computer - aided diagnosis</e2> within ultrasound images , where the amount of available annotated data is smaller , a natural question arises : are deep - learning methods better than conventional machine - learning methods ?'],\n",
              "        'mentionTexts': [['medical image', 'computer - aided diagnosis']],\n",
              "        'relationshipSubtype': 'no_subtype',\n",
              "        'relationshipType': {'id': 'is_sibling_of'},\n",
              "        'srcEntityId': '702653',\n",
              "        'srcEntityName': 'Medical Records Systems, Computerized',\n",
              "        'srcEntitySlug': 'Medical-Records-Systems,-Computerized'}],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Medicine', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '9b056ec797d1dd207d7afc2473f4fe274bd59dc3',\n",
              "      'journal': {'name': 'Sensors (Basel, Switzerland)', 'volume': '20'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/1886/734e3e4a0bceca926425592552d9780cf126.pdf'}],\n",
              "      'paperAbstract': 'The emergence of deep-learning methods in different computer vision tasks has proved to offer increased detection, recognition or segmentation accuracy when large annotated image datasets are available. In the case of medical image processing and computer-aided diagnosis within ultrasound images, where the amount of available annotated data is smaller, a natural question arises: are deep-learning methods better than conventional machine-learning methods? How do the conventional machine-learning methods behave in comparison with deep-learning methods on the same dataset? Based on the study of various deep-learning architectures, a lightweight multi-resolution Convolutional Neural Network (CNN) architecture is proposed. It is suitable for differentiating, within ultrasound images, between the Hepatocellular Carcinoma (HCC), respectively the cirrhotic parenchyma (PAR) on which HCC had evolved. The proposed deep-learning model is compared with other CNN architectures that have been adapted by transfer learning for the ultrasound binary classification task, but also with conventional machine-learning (ML) solutions trained on textural features. The achieved results show that the deep-learning approach overcomes classical machine-learning solutions, by providing a higher classification performance.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/1886/734e3e4a0bceca926425592552d9780cf126.pdf'},\n",
              "      'pubDate': '2020-05-29',\n",
              "      'pubUpdateDate': '2020-05-29',\n",
              "      'scorecardStats': [{'citationCount': 9,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'Medline',\n",
              "       'PubMedCentral',\n",
              "       'MAG',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction',\n",
              "       'Unpaywall'],\n",
              "      'title': 'Comparison of Deep-Learning and Conventional Machine-Learning Methods for the Automatic Recognition of the Hepatocellular Carcinoma Areas from Ultrasound Images',\n",
              "      'tldr': {'abstractSimilarityScore': 42,\n",
              "       'text': 'A lightweight multi-resolution Convolutional Neural Network architecture is proposed, suitable for differentiating, within ultrasound images, between the Hepatocellular Carcinoma and the cirrhotic parenchyma on which HCC had evolved, and is compared with other CNN architectures that have been adapted by transfer learning for the ultrasound binary classification task.'},\n",
              "      'venue': 'Sensors',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Sidra Mehtab', 'Jaydip Sen'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 4,\n",
              "         'endKey': 2020,\n",
              "         'startKey': 2020},\n",
              "        {'count': 4, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 6.142793298846722,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 8,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 3,\n",
              "       'numReferences': 83,\n",
              "       'numViewableReferences': 83},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Economics', 'Computer Science', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '763022a3b5eba6cc6e44346ac7466e6cdd840e61',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2004.11697'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2004.11697.pdf'}],\n",
              "      'paperAbstract': 'Prediction of future movement of stock prices has always been a challenging task for the researchers. While the advocates of the efficient market hypothesis (EMH) believe that it is impossible to design any predictive framework that can accurately predict the movement of stock prices, there are seminal work in the literature that have clearly demonstrated that the seemingly random movement patterns in the time series of a stock price can be predicted with a high level of accuracy. Design of such predictive models requires choice of appropriate variables, right transformation methods of the variables, and tuning of the parameters of the models. In this work, we present a very robust and accurate framework of stock price prediction that consists of an agglomeration of statistical, machine learning and deep learning models. We use the daily stock price data, collected at five minutes interval of time, of a very well known company that is listed in the National Stock Exchange (NSE) of India. The granular data is aggregated into three slots in a day, and the aggregated data is used for building and training the forecasting models. We contend that the agglomerative approach of model building that uses a combination of statistical, machine learning, and deep learning approaches, can very effectively learn from the volatile and random movement patterns in a stock price data. We build eight classification and eight regression models based on statistical and machine learning approaches. In addition to these models, a deep learning regression model using a long-and-short-term memory (LSTM) network is also built. Extensive results have been presented on the performance of these models, and the results are critically analyzed.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2004.11697.pdf'},\n",
              "      'pubDate': '2020-04-17',\n",
              "      'pubUpdateDate': '2021-05-31',\n",
              "      'scorecardStats': [{'citationCount': 8,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'ArXiv',\n",
              "       'MAG',\n",
              "       'DBLP'],\n",
              "      'title': 'A Time Series Analysis-Based Stock Price Prediction Using Machine Learning and Deep Learning Models',\n",
              "      'tldr': {'abstractSimilarityScore': 38,\n",
              "       'text': 'It is contended that the agglomerative approach of model building that uses a combination of statistical, machine learning, and deep learning approaches, can very effectively learn from the volatile and random movement patterns in a stock price data.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08636191.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2897327'}],\n",
              "      'authors': ['Wahab Khan',\n",
              "       'Ali Daud',\n",
              "       'Khairullah Khan',\n",
              "       'J. Nasir',\n",
              "       'Mohammed Basheri',\n",
              "       'Naif R. Aljohani',\n",
              "       'F. Alotaibi'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 4,\n",
              "         'endKey': 2019,\n",
              "         'startKey': 2019},\n",
              "        {'count': 1, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 3, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 10.196904041003625,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2020,\n",
              "       'numCitations': 8,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 0,\n",
              "       'numViewableReferences': 0},\n",
              "      'entities': ['Deep learning',\n",
              "       'Part-of-speech tagging',\n",
              "       'Conditional random field',\n",
              "       'Hidden Markov model',\n",
              "       'Support vector machine',\n",
              "       'Long short-term memory',\n",
              "       'Recurrent neural network',\n",
              "       'Machine translation',\n",
              "       'Information extraction',\n",
              "       'Speech processing',\n",
              "       'Machine learning',\n",
              "       'Natural language processing',\n",
              "       'Bigram',\n",
              "       'Markov chain',\n",
              "       'Language-independent specification',\n",
              "       'Artificial neural network',\n",
              "       'N-gram',\n",
              "       'Tag cloud',\n",
              "       'Benchmark (computing)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '05755f4147610373f5677e620aee2f1ac5c0460e',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '38918-38936',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8636191'}],\n",
              "      'paperAbstract': 'In Urdu, part of speech (POS) tagging is a challenging task as it is both inflectionally and derivationally rich morphological language. Verbs are generally conceived a highly inflected object in Urdu comparatively to nouns. POS tagging is used as a preliminary linguistic text analysis in diverse natural language processing domains such as speech processing, information extraction, machine translation, and others. It is a task that first identifies appropriate syntactic categories for each word in running text and second assigns the predicted syntactic tag to all concerned words. The current work is the extension of our previous work. Previously, we presented conditional random field (CRF)-based POS tagger with both language dependent and independent feature set. However, in the current study, we offer: 1) the implementation of both machine and deep learning models for Urdu POS tagging task with well-balanced language-independent feature set and 2) to highlight diverse challenges which cause Urdu POS task a challenging one. In this research, we demonstrated the effectiveness of machine learning and deep learning models for Urdu POS task. Empirically, we have evaluated the performance of all models on two benchmark datasets. The core models evaluated in this study are CRF, support vector machine (SVM), two variants of the deep recurrent neural network (DRNN), and a variant of n-gram Markov model the bigram hidden Markov model (HMM). The two variants of DRRN models evaluated include forward long short-term memory (LSTM)-RNN and LSTM-RNN with CRF output.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8636191'},\n",
              "      'pubDate': '2019-02-06',\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 8,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'Unpaywall', 'MAG', 'IEEE'],\n",
              "      'title': 'Part of Speech Tagging in Urdu: Comparison of Machine and Deep Learning Approaches',\n",
              "      'tldr': {'abstractSimilarityScore': 39,\n",
              "       'text': 'The implementation of both machine and deep learning models for Urdu POS tagging task with well-balanced language-independent feature set is offered to highlight diverse challenges which cause UrduPOS task a challenging one.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'}]}},\n",
              "  {'Page': {'N_Page': 10,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://www.mdpi.com/2072-4292/13/1/155/pdf'}],\n",
              "      'authors': ['Dmitry I. Rukhovich',\n",
              "       'P. Koroleva',\n",
              "       'D. D. Rukhovich',\n",
              "       'N. Kalinina'],\n",
              "      'badges': [{'id': 'UNPAYWALL'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 2,\n",
              "         'endKey': 2021,\n",
              "         'startKey': 2021}],\n",
              "       'estNumCitations': 0.0,\n",
              "       'firstCitationVelocityYear': 2021,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 2,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 20,\n",
              "       'numViewableReferences': 20},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '5266bd36415b29bfef262cf7ab65280347e862d7',\n",
              "      'journal': {'name': 'Remote. Sens.', 'pages': '155', 'volume': '13'},\n",
              "      'links': [{'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.3390/rs13010155'}],\n",
              "      'paperAbstract': 'Soil degradation processes are widespread on agricultural land. Ground-based methods for detecting degradation require a lot of labor and time. Remote methods based on the analysis of vegetation indices can significantly reduce the volume of ground surveys. Currently, machine learning methods are increasingly being used to analyze remote sensing data. In this paper, the task is set to apply deep machine learning methods and methods of vegetation indices calculation to automate the detection of areas of soil degradation development on arable land. In the course of the work, a method was developed for determining the location of degraded areas of soil cover on arable fields. The method is based on the use of multi-temporal remote sensing data. The selection of suitable remote sensing data scenes is based on deep machine learning. Deep machine learning was based on an analysis of 1028 scenes of Landsats 4, 5, 7 and 8 on 530 agricultural fields. Landsat data from 1984 to 2019 was analyzed. Dataset was created manually for each pair of “Landsat scene”/“agricultural field number”(for each agricultural field, the suitability of each Landsat scene was assessed). Areas of soil degradation were calculated based on the frequency of occurrence of low NDVI values over 35 years. Low NDVI values were calculated separately for each suitable fragment of the satellite image within the boundaries of each agricultural field. NDVI values of one-third of the field area and lower than the other two-thirds were considered low. During testing, the method gave 12.5% of type I errors (false positive) and 3.8% of type II errors (false negative). Independent verification of the method was carried out on six agricultural fields on an area of 713.3 hectares. Humus content and thickness of the humus horizon were determined in 42 ground-based points. In arable land degradation areas identified by the proposed method, the probability of detecting soil degradation by field methods was 87.5%. The probability of detecting soil degradation by ground-based methods outside the predicted regions was 3.8%. The results indicate that deep machine learning is feasible for remote sensing data selection based on a binary dataset. This eliminates the need for intermediate filtering systems in the selection of satellite imagery (determination of clouds, shadows from clouds, open soil surface, etc.). Direct selection of Landsat scenes suitable for calculations has been made. It allows automating the process of constructing soil degradation maps.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'doi',\n",
              "       'url': 'https://doi.org/10.3390/rs13010155'},\n",
              "      'pubDate': None,\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 2,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'Crossref', 'Unpaywall'],\n",
              "      'title': 'The Use of Deep Machine Learning for the Automated Selection of Remote Sensing Data for the Determination of Areas of Arable Land Degradation Processes Distribution',\n",
              "      'tldr': None,\n",
              "      'venue': 'Remote. Sens.',\n",
              "      'videos': [],\n",
              "      'year': '2021'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Adita Kulkarni', 'A. Seetharam'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 2,\n",
              "         'endKey': 2020,\n",
              "         'startKey': 2020}],\n",
              "       'estNumCitations': 2.3542600896860986,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.5,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 2,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 1,\n",
              "       'numReferences': 18,\n",
              "       'numViewableReferences': 18},\n",
              "      'entities': ['Machine learning',\n",
              "       'Routing',\n",
              "       'Reinforcement learning',\n",
              "       'Deep learning',\n",
              "       'Graphical model',\n",
              "       'Network performance',\n",
              "       'Floor and ceiling functions',\n",
              "       'Experiment',\n",
              "       'Tracing (software)',\n",
              "       'Cache (computing)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '6c179b9506ebfafc5f6cadaaede540082bebff97',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2004.06787'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2004.06787.pdf'}],\n",
              "      'paperAbstract': 'In-network caching is likely to become an integral part of various networked systems (e.g., 5G networks, LPWAN and IoT systems) in the near future. In this paper, we compare and contrast model-based and machine learning approaches for designing caching and routing strategies to improve cache network performance (e.g., delay, hit rate). We first outline the key principles used in the design of model-based strategies and discuss the analytical results and bounds obtained for these approaches. By conducting experiments on real-world traces and networks, we identify the interplay between content popularity skewness and request stream correlation as an important factor affecting cache performance. With respect to routing, we show that the main factors impacting performance are alternate path routing and content search. We then discuss the applicability of multiple machine learning models, specifically reinforcement learning, deep learning, transfer learning and probabilistic graphical models for the caching and routing problem.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2004.06787.pdf'},\n",
              "      'pubDate': '2020-04-14',\n",
              "      'pubUpdateDate': '2020-04-14',\n",
              "      'scorecardStats': [{'citationCount': 2,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ArXiv', 'MergedPDFExtraction', 'DBLP', 'MAG'],\n",
              "      'title': 'Model and Machine Learning based Caching and Routing Algorithms for Cache-enabled Networks',\n",
              "      'tldr': {'abstractSimilarityScore': 55,\n",
              "       'text': 'This paper compares and contrast model-based and machine learning approaches for designing caching and routing strategies to improve cache network performance and discusses the applicability of multiple machine learning models, specifically reinforcement learning, deep learning, transfer learning and probabilistic graphical models.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Kakia Chatsiou', 'Slava J. Mikhaylov'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 2,\n",
              "         'endKey': 2020,\n",
              "         'startKey': 2020}],\n",
              "       'estNumCitations': 1.0285757006861491,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 2,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 5,\n",
              "       'numReferences': 128,\n",
              "       'numViewableReferences': 128},\n",
              "      'entities': ['Deep learning',\n",
              "       'Natural language processing',\n",
              "       'Artificial intelligence',\n",
              "       'Machine learning',\n",
              "       'Computational resource',\n",
              "       'Theory',\n",
              "       'Algorithm'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'acff518b945f15b1a687ac313b25048c50fed044',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2005.06540'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2005.06540.pdf'}],\n",
              "      'paperAbstract': 'Political science, and social science in general, have traditionally been using computational methods to study areas such as voting behavior, policy making, international conflict, and international development. More recently, increasingly available quantities of data are being combined with improved algorithms and affordable computational resources to predict, learn, and discover new insights from data that is large in volume and variety. New developments in the areas of machine learning, deep learning, natural language processing (NLP), and, more generally, artificial intelligence (AI) are opening up new opportunities for testing theories and evaluating the impact of interventions and programs in a more dynamic and effective way. Applications using large volumes of structured and unstructured data are becoming common in government and industry, and increasingly also in social science research. This chapter offers an introduction to such methods drawing examples from political science. Focusing on the areas where the strengths of the methods coincide with challenges in these fields, the chapter first presents an introduction to AI and its core technology - machine learning, with its rapidly developing subfield of deep learning. The discussion of deep neural networks is illustrated with the NLP tasks that are relevant to political science. The latest advances in deep learning methods for NLP are also reviewed, together with their potential for improving information extraction and pattern recognition from political science texts.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2005.06540.pdf'},\n",
              "      'pubDate': '2020-04-09',\n",
              "      'pubUpdateDate': '2020-05-13',\n",
              "      'scorecardStats': [{'citationCount': 2,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'Unpaywall',\n",
              "       'ArXiv',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP'],\n",
              "      'title': 'Deep Learning for Political Science',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'Focusing on the areas where the strengths of the methods coincide with challenges in these fields, the chapter first presents an introduction to AI and its core technology - machine learning, with its rapidly developing subfield of deep learning.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Manav Kaushik', 'A. K. Giri'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 1,\n",
              "         'endKey': 2020,\n",
              "         'startKey': 2020}],\n",
              "       'estNumCitations': 0.0,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 1,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 30,\n",
              "       'numViewableReferences': 30},\n",
              "      'entities': ['Long short-term memory',\n",
              "       'Foreign exchange service (telecommunications)',\n",
              "       'Deep learning',\n",
              "       'Machine learning',\n",
              "       'Time series',\n",
              "       'Support vector machine',\n",
              "       'Interdependence',\n",
              "       'Computational intelligence',\n",
              "       'Recurrent neural network',\n",
              "       'Vector autoregression',\n",
              "       'Random neural network',\n",
              "       'Neural network software'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Economics', 'Mathematics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '10868870c07478d653a6d7445d1c54621d65b33b',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2002.10247'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2002.10247.pdf'}],\n",
              "      'paperAbstract': 'In todays global economy, accuracy in predicting macro-economic parameters such as the foreign the exchange rate or at least estimating the trend correctly is of key importance for any future investment. In recent times, the use of computational intelligence-based techniques for forecasting macroeconomic variables has been proven highly successful. This paper tries to come up with a multivariate time series approach to forecast the exchange rate (USD/INR) while parallelly comparing the performance of three multivariate prediction modelling techniques: Vector Auto Regression (a Traditional Econometric Technique), Support Vector Machine (a Contemporary Machine Learning Technique), and Recurrent Neural Networks (a Contemporary Deep Learning Technique). We have used monthly historical data for several macroeconomic variables from April 1994 to December 2018 for USA and India to predict USD-INR Foreign Exchange Rate. The results clearly depict that contemporary techniques of SVM and RNN (Long Short-Term Memory) outperform the widely used traditional method of Auto Regression. The RNN model with Long Short-Term Memory (LSTM) provides the maximum accuracy (97.83%) followed by SVM Model (97.17%) and VAR Model (96.31%). At last, we present a brief analysis of the correlation and interdependencies of the variables used for forecasting.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2002.10247.pdf'},\n",
              "      'pubDate': '2020-02-19',\n",
              "      'pubUpdateDate': '2020-02-19',\n",
              "      'scorecardStats': [{'citationCount': 1,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG', 'MergedPDFExtraction', 'DBLP', 'ArXiv', 'Anansi'],\n",
              "      'title': 'Forecasting Foreign Exchange Rate: A Multivariate Comparative Analysis between Traditional Econometric, Contemporary Machine Learning & Deep Learning Techniques',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'The results clearly depict that contemporary techniques of SVM and RNN (Long Short-Term Memory) outperform the widely used traditional method of Auto Regression in predicting the exchange rate.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/9312710/09363896.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2021.3062484'}],\n",
              "      'authors': ['P. Khan',\n",
              "       'Md. Fazlul Kader',\n",
              "       'S. M. Islam',\n",
              "       'A. B. Rahman',\n",
              "       'Md. Shahriar Kamal',\n",
              "       'Masbah Uddin Toha',\n",
              "       'K. Kwak'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 1,\n",
              "         'endKey': 2021,\n",
              "         'startKey': 2021}],\n",
              "       'estNumCitations': 1.0004688579607146,\n",
              "       'firstCitationVelocityYear': 2021,\n",
              "       'keyCitationRate': 1.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 1,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 197,\n",
              "       'numViewableReferences': 197},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'd0efd261e12c316a0a4f50c2f673af04a04b6200',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '37622-37655',\n",
              "       'volume': '9'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9363896'}],\n",
              "      'paperAbstract': 'Brain is the controlling center of our body. With the advent of time, newer and newer brain diseases are being discovered. Thus, because of the variability of brain diseases, existing diagnosis or detection systems are becoming challenging and are still an open problem for research. Detection of brain diseases at an early stage can make a huge difference in attempting to cure them. In recent years, the use of artificial intelligence (AI) is surging through all spheres of science, and no doubt, it is revolutionizing the field of neurology. Application of AI in medical science has made brain disease prediction and detection more accurate and precise. In this study, we present a review on recent machine learning and deep learning approaches in detecting four brain diseases such as Alzheimer’s disease (AD), brain tumor, epilepsy, and Parkinson’s disease. 147 recent articles on four brain diseases are reviewed considering diverse machine learning and deep learning approaches, modalities, datasets etc. Twenty-two datasets are discussed which are used most frequently in the reviewed articles as a primary source of brain disease data. Moreover, a brief overview of different feature extraction techniques that are used in diagnosing brain diseases is provided. Finally, key findings from the reviewed articles are summarized and a number of major issues related to machine learning/deep learning-based brain disease diagnostic approaches are discussed. Through this study, we aim at finding the most accurate technique for detecting different brain diseases which can be employed for future betterment.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9363896'},\n",
              "      'pubDate': None,\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 1,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref', 'DBLP', 'IEEE', 'MergedPDFExtraction'],\n",
              "      'title': 'Machine Learning and Deep Learning Approaches for Brain Disease Diagnosis: Principles and Recent Advances',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': \"This study aims at finding the most accurate technique for detecting different brain diseases which can be employed for future betterment through a review on recent machine learning and deep learning approaches in detecting four brain diseases such as Alzheimer's disease, brain tumor, epilepsy, and Parkinson's disease.\"},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2021'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://www.nature.com/articles/s41598-020-76928-z.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1038/s41598-020-76928-z'}],\n",
              "      'authors': ['A. Goyal',\n",
              "       'Maheshwar Kuchana',\n",
              "       'Kameswari Prasada Rao Ayyagari'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 1,\n",
              "         'endKey': 2021,\n",
              "         'startKey': 2021}],\n",
              "       'estNumCitations': 1.991188285603214,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 1,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 76,\n",
              "       'numViewableReferences': 76},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Medicine', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'b6f01851898fdba03a8153519f9f2efaf6cfbb2a',\n",
              "      'journal': {'name': 'Scientific Reports', 'volume': '10'},\n",
              "      'links': [{'linkType': 'medline',\n",
              "        'url': 'https://www.ncbi.nlm.nih.gov/pubmed/33262383'}],\n",
              "      'paperAbstract': 'In-vitro fertilization (IVF) is a popular method of resolving complications such as endometriosis, poor egg quality, a genetic disease of mother or father, problems with ovulation, antibody problems that harm sperm or eggs, the inability of sperm to penetrate or survive in the cervical mucus and low sperm counts, resulting human infertility. Nevertheless, IVF does not guarantee success in the fertilization. Choosing IVF is burdensome for the reason of high cost and uncertainty in the result. As the complications and fertilization factors are numerous in the IVF process, it is a cumbersome task for fertility doctors to give an accurate prediction of a successful birth. Artificial Intelligence (AI) has been employed in this study for predicting the live-birth occurrence. This work mainly focuses on making predictions of live-birth occurrence when an embryo forms from a couple and not a donor. Here, we compare various AI algorithms, including both classical Machine Learning, deep learning architecture, and an ensemble of algorithms on the publicly available dataset provided by Human Fertilisation and Embryology Authority (HFEA). Insights on data and metrics such as confusion matrices, F1-score, precision, recall, receiver operating characteristic (ROC) curves are demonstrated in the subsequent sections. The training process has two settings Without feature selection and With feature selection to train classifier models. Machine Learning, Deep learning, ensemble models classification paradigms have been trained in both settings. The Random Forest model achieves the highest F1-score of 76.49% in without feature selection setting. For the same model, the precision, recall, and area under the ROC Curve (ROC AUC) scores are 77%, 76%, and 84.60%, respectively. The success of the pregnancy depends on both male and female traits and living conditions. This study predicts a successful pregnancy through the clinically relevant parameters in In-vitro fertilization. Thus artificial intelligence plays a promising role in decision making process to support the diagnosis, prognosis, treatment etc.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'medline',\n",
              "       'url': 'https://www.ncbi.nlm.nih.gov/pubmed/33262383'},\n",
              "      'pubDate': '2020-12-01',\n",
              "      'pubUpdateDate': '2020-12-01',\n",
              "      'scorecardStats': [{'citationCount': 1,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Medline',\n",
              "       'Crossref',\n",
              "       'Unpaywall',\n",
              "       'MergedPDFExtraction',\n",
              "       'PubMedCentral',\n",
              "       'MAG'],\n",
              "      'title': 'Machine learning predicts live-birth occurrence before in-vitro fertilization treatment',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': 'Artificial intelligence plays a promising role in decision making process to support the diagnosis, prognosis, treatment etc.'},\n",
              "      'venue': 'Scientific reports',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['M. Chieregato',\n",
              "       'Fabio Frangiamore',\n",
              "       'M. Morassi',\n",
              "       'C. Baresi',\n",
              "       'S. Nici',\n",
              "       'C. Bassetti',\n",
              "       'C. Bnà',\n",
              "       'M. Galelli'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [],\n",
              "       'estNumCitations': 0.0,\n",
              "       'firstCitationVelocityYear': 2021,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2020,\n",
              "       'numCitations': 0,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 61,\n",
              "       'numViewableReferences': 61},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science',\n",
              "       'Biology',\n",
              "       'Engineering',\n",
              "       'Physics'],\n",
              "      'githubReferences': [],\n",
              "      'id': '2b28254c78f6f4f7711f31d90d56b9715005ee79',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2105.06141'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2105.06141.pdf'}],\n",
              "      'paperAbstract': 'COVID-19 clinical presentation and prognosis are highly variable, ranging from asymptomatic and paucisymptomatic cases to acute respiratory distress syndrome and multi-organ involvement. We developed a hybrid machine learning/deep learning model to classify patients in two outcome categories, non-ICU and ICU (intensive care admission or death), using 558 patients admitted in a northern Italy hospital in February/May of 2020. A fully 3D patient-level CNN classifier on baseline CT images is used as feature extractor. Features extracted, alongside with laboratory and clinical data, are fed for selection in a Boruta algorithm with SHAP game theoretical values. A classifier is built on the reduced feature space using CatBoost gradient boosting algorithm and reaching a probabilistic AUC of 0.949 on holdout test set. The model aims to provide clinical decision support to medical doctors, with the probability score of belonging to an outcome class and with case-based SHAP interpretation of features importance.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2105.06141.pdf'},\n",
              "      'pubDate': '2021-05-13',\n",
              "      'pubUpdateDate': '2021-05-13',\n",
              "      'scorecardStats': [],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'MergedPDFExtraction', 'ArXiv'],\n",
              "      'title': 'A hybrid machine learning/deep learning COVID-19 severity predictive model from CT images and clinical data',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'A hybrid machine learning/deep learning model to classify patients in two outcome categories, non-ICU and ICU (intensive care admission or death), using 558 patients admitted in a northern Italy hospital in February/May of 2020 is developed.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2021'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['M. R. Ahmed',\n",
              "       'J. Yasmin',\n",
              "       'Eunsung Park',\n",
              "       'Geonwoo Kim',\n",
              "       'Moon S. Kim',\n",
              "       'Collins Wakholi',\n",
              "       'C. Mo',\n",
              "       'B. Cho'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [],\n",
              "       'estNumCitations': 0.0,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 0,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 1,\n",
              "       'numReferences': 36,\n",
              "       'numViewableReferences': 36},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Medicine'],\n",
              "      'githubReferences': [],\n",
              "      'id': '80f342e045d62b172f6bef4c83e90d74678ff49c',\n",
              "      'journal': {'name': 'Sensors (Basel, Switzerland)', 'volume': '20'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/da12/f9fab846c06f6b8968a37e2713d6007e01f6.pdf'}],\n",
              "      'paperAbstract': 'In this study, conventional machine learning and deep leaning approaches were evaluated using X-ray imaging techniques for investigating the internal parameters (endosperm and air space) of three cultivars of watermelon seed. In the conventional machine learning, six types of image features were extracted after applying different types of image preprocessing, such as image intensity and contrast enhancement, and noise reduction. The sequential forward selection (SFS) method and Fisher objective function were used as the search strategy and feature optimization. Three classifiers were tested (linear discriminant analysis (LDA), quadratic discriminant analysis (QDA), and k-nearest neighbors algorithm (KNN)) to find the best performer. On the other hand, in the transfer learning (deep learning) approaches, simple ConvNet, AlexNet, VGG-19, ResNet-50, and ResNet-101 were used to train the dataset and class prediction of the seed. For the supervised model development (both conventional machine learning and deep learning), the germination test results of the samples were used where the seeds were divided into two classes: (1) normal viable seeds and (2) nonviable and abnormal viable seeds. In the conventional classification, 83.6% accuracy was obtained by LDA using 48 features. ResNet-50 performed better than other transfer learning architectures, with an 87.3% accuracy which was the highest accuracy in all classification models. The findings of this study manifested that transfer learning is a constructive strategy for classifying seeds by analyzing their morphology, where X-ray imaging can be adopted as a potential imaging technique.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/da12/f9fab846c06f6b8968a37e2713d6007e01f6.pdf'},\n",
              "      'pubDate': '2020-11-26',\n",
              "      'pubUpdateDate': '2020-11-26',\n",
              "      'scorecardStats': [],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['PubMedCentral',\n",
              "       'DBLP',\n",
              "       'Crossref',\n",
              "       'Unpaywall',\n",
              "       'Medline',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG'],\n",
              "      'title': 'Classification of Watermelon Seeds Using Morphological Patterns of X-ray Imaging: A Comparison of Conventional Machine Learning and Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'The findings of this study manifested that transfer learning is a constructive strategy for classifying seeds by analyzing their morphology, where X-ray imaging can be adopted as a potential imaging technique.'},\n",
              "      'venue': 'Sensors',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['V. Gripon', 'C. Lassance', 'G. B. Hacene'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [],\n",
              "       'estNumCitations': 0.0,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2020,\n",
              "       'numCitations': 0,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 1,\n",
              "       'numReferences': 32,\n",
              "       'numViewableReferences': 32},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '74283efabb1c6278478c5cd106ba822db65f2974',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2012.01509'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2012.01509.pdf'}],\n",
              "      'paperAbstract': 'Learning deep representations to solve complex machine learning tasks has become the prominent trend in the past few years. Indeed, Deep Neural Networks are now the golden standard in domains as various as computer vision, natural language processing or even playing combinatorial games. However, problematic limitations are hidden behind this surprising universal capability. Among other things, explainability of the decisions is a major concern, especially since deep neural networks are made up of a very large number of trainable parameters. Moreover, computational complexity can quickly become a problem, especially in contexts constrained by real time or limited resources. Therefore, understanding how information is stored and the impact this storage can have on the system remains a major and open issue. In this chapter, we introduce a method to transform deep neural network models into deep associative memories, with simpler, more explicable and less expensive operations. We show through experiments that these transformations can be done without penalty on predictive performance. The resulting deep associative memories are excellent candidates for artificial intelligence that is easier to theorize and manipulate.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2012.01509.pdf'},\n",
              "      'pubDate': '2020-12-02',\n",
              "      'pubUpdateDate': '2020-12-03',\n",
              "      'scorecardStats': [],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG',\n",
              "       'Anansi',\n",
              "       'ArXiv',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP',\n",
              "       'MergedPDFExtraction'],\n",
              "      'title': 'DecisiveNets: Training Deep Associative Memories to Solve Complex Machine Learning Problems',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'This chapter introduces a method to transform deep neural network models into deep associative memories, with simpler, more explicable and less expensive operations, and shows that these transformations can be done without penalty on predictive performance.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Luoxiao Yang', 'Long Wang', 'Zijun Zhang'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [],\n",
              "       'estNumCitations': 0.0,\n",
              "       'firstCitationVelocityYear': 2021,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 0,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 27,\n",
              "       'numViewableReferences': 27},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'a8f5e13c04f55104bc5046cd75010a07dfc3ac65',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2109.00894'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2109.00894.pdf'}],\n",
              "      'paperAbstract': 'This paper develops a novel self-training U-net (STUnet) based method for the automated WPC model generation without requiring data pre-processing. The self-training (ST) process of STU-net has two steps. First, different from traditional studies regarding the WPC modeling as a curve fitting problem, in this paper, we renovate the WPC modeling formulation from a machine vision aspect. To develop sufficiently diversified training samples, we synthesize supervisory control and data acquisition (SCADA) data based on a set of S-shape functions depicting WPCs. These synthesized SCADA data and WPC functions are visualized as images and paired as training samples (Ix, Iwpc ). A U-net is then developed to approximate the model recovering Iwpc from Ix . The developed U-net is applied into observed SCADA data and can successfully generate the Iwpc. Moreover, we develop a pixel mapping and correction process to derive a mathematical form fwpc representing Iwpc generated previously. The proposed STU-net only needs to train once and does not require any data preprocessing in applications. Numerical experiments based on 76 WTs are conducted to validate the superiority of the proposed method by benchmarking against classical WPC modeling methods. To demonstrate the repeatability of the presented research, we release our code at https://github.com/IkeYang/STUnet.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2109.00894.pdf'},\n",
              "      'pubDate': '2021-08-19',\n",
              "      'pubUpdateDate': '2021-08-19',\n",
              "      'scorecardStats': [],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'ArXiv', 'MergedPDFExtraction'],\n",
              "      'title': 'Generative Wind Power Curve Modeling Via Machine Vision: A Self-learning Deep Convolutional Network Based Method',\n",
              "      'tldr': None,\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2021'}]}},\n",
              "  {'Page': {'N_Page': 11,\n",
              "    'N_Papers': 10,\n",
              "    'Papers': [{'alternatePaperLinks': [],\n",
              "      'authors': ['R. Carmona', 'M. Laurière'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.1,\n",
              "       'citationVelocity': 13.333333333333334,\n",
              "       'citedByBuckets': [{'count': 2, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 20, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 18, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 27.803296226071524,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.05,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 40,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 3,\n",
              "       'numReferences': 50,\n",
              "       'numViewableReferences': 50},\n",
              "      'entities': ['Machine learning',\n",
              "       'Loss function',\n",
              "       'Optimal control',\n",
              "       'Stochastic gradient descent',\n",
              "       'Mathematical optimization',\n",
              "       'Numerical partial differential equations',\n",
              "       'Artificial neural network',\n",
              "       'Numerical method',\n",
              "       'Optimization problem',\n",
              "       'Image noise',\n",
              "       'Computation',\n",
              "       'Approximation algorithm',\n",
              "       'Finite element method'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '8c276955fba84356ebfba02bfd30af21f650b215',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1908.01613'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1908.01613.pdf'}],\n",
              "      'paperAbstract': 'We propose two algorithms for the solution of the optimal control of ergodic McKean-Vlasov dynamics. Both algorithms are based on the approximation of the theoretical solutions by neural networks, the latter being characterized by their architecture and a set of parameters. This allows the use of modern machine learning tools, and efficient implementations of stochastic gradient descent. The first algorithm is based on the idiosyncrasies of the ergodic optimal control problem. We provide a mathematical proof of the convergence of the algorithm, and we analyze rigorously the approximation by controlling the different sources of error. The second method is an adaptation of the deep Galerkin method to the system of partial differential equations issued from the optimality condition. We demonstrate the efficiency of these algorithms on several numerical examples, some of them being chosen to show that our algorithms succeed where existing ones failed. We also argue that both methods can easily be applied to problems in dimensions larger than what can be found in the existing literature. Finally, we illustrate the fact that, although the first algorithm is specifically designed for mean field control problems, the second one is more general and can also be applied to the partial differential equation systems arising in the theory of mean field games.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1908.01613.pdf'},\n",
              "      'pubDate': '2019-07-13',\n",
              "      'pubUpdateDate': '2019-08-05',\n",
              "      'scorecardStats': [{'citationCount': 40,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ArXiv',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP',\n",
              "       'MAG'],\n",
              "      'title': 'Convergence Analysis of Machine Learning Algorithms for the Numerical Solution of Mean Field Control and Games: II - The Finite Horizon Case',\n",
              "      'tldr': {'abstractSimilarityScore': 70,\n",
              "       'text': 'Two algorithms are proposed for the solution of the optimal control of ergodic McKean-Vlasov dynamics based on the approximation of the theoretical solutions by neural networks, which allows the use of modern machine learning tools, and efficient implementations of stochastic gradient descent.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Piero Molino', 'Yaroslav Dudin', 'Sai Sumanth Miryala'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.3125,\n",
              "       'citationVelocity': 10.0,\n",
              "       'citedByBuckets': [{'count': 3, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 16, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 11, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 26.62643556308892,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.03333333333333333,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 30,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 4,\n",
              "       'numReferences': 25,\n",
              "       'numViewableReferences': 25},\n",
              "      'entities': ['Deep learning',\n",
              "       'Encoder',\n",
              "       'Machine learning',\n",
              "       'Experience',\n",
              "       'Encapsulation (networking)',\n",
              "       'Declarative programming'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Mathematics', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '402e60cae27d28485d45a49e11e992869f08edfd',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1909.07930'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1909.07930.pdf'}],\n",
              "      'paperAbstract': 'In this work we present Ludwig, a flexible, extensible and easy to use toolbox which allows users to train deep learning models and use them for obtaining predictions without writing code. Ludwig implements a novel approach to deep learning model building based on two main abstractions: data types and declarative configuration files. The data type abstraction allows for easier code and sub-model reuse, and the standardized interfaces imposed by this abstraction allow for encapsulation and make the code easy to extend. Declarative model definition configuration files enable inexperienced users to obtain effective models and increase the productivity of expert users. Alongside these two innovations, Ludwig introduces a general modularized deep learning architecture called Encoder-Combiner-Decoder that can be instantiated to perform a vast amount of machine learning tasks. These innovations make it possible for engineers, scientists from other fields and, in general, a much broader audience to adopt deep learning models for their tasks, concretely helping in its democratization.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1909.07930.pdf'},\n",
              "      'pubDate': '2019-09-17',\n",
              "      'pubUpdateDate': '2019-09-17',\n",
              "      'scorecardStats': [{'citationCount': 30,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG', 'DBLP', 'ArXiv', 'MergedPDFExtraction'],\n",
              "      'title': 'Ludwig: a type-based declarative deep learning toolbox',\n",
              "      'tldr': {'abstractSimilarityScore': 69,\n",
              "       'text': 'Ludwig is a flexible, extensible and easy to use toolbox which allows users to train deep learning models and use them for obtaining predictions without writing code, and introduces a general modularized deep learning architecture called Encoder-Combiner-Decoder that can be instantiated to perform a vast amount of machine learning tasks.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['S. Weng', 'L. Vaz', 'N. Qureshi', 'J. Kai'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.14285714285714285,\n",
              "       'citationVelocity': 10.0,\n",
              "       'citedByBuckets': [{'count': 4, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 14, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 12, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 33.32810033234526,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 30,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 35,\n",
              "       'numViewableReferences': 35},\n",
              "      'entities': ['Cessation of life',\n",
              "       'Area Under Curve',\n",
              "       'algorithm',\n",
              "       'Epidemiology'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'BLOG'}, 'count': 1},\n",
              "       {'contentType': {'id': 'NEWS'}, 'count': 6}],\n",
              "      'fieldsOfStudy': ['Medicine'],\n",
              "      'githubReferences': [],\n",
              "      'id': '18000ef9b6e02308ae299c4e1e2b3a32e951a508',\n",
              "      'journal': {'name': 'PLoS ONE', 'volume': '14'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/1800/0ef9b6e02308ae299c4e1e2b3a32e951a508.pdf'}],\n",
              "      'paperAbstract': 'Background Prognostic modelling using standard methods is well-established, particularly for predicting risk of single diseases. Machine-learning may offer potential to explore outcomes of even greater complexity, such as premature death. This study aimed to develop novel prediction algorithms using machine-learning, in addition to standard survival modelling, to predict premature all-cause mortality. Methods A prospective population cohort of 502,628 participants aged 40–69 years were recruited to the UK Biobank from 2006–2010 and followed-up until 2016. Participants were assessed on a range of demographic, biometric, clinical and lifestyle factors. Mortality data by ICD-10 were obtained from linkage to Office of National Statistics. Models were developed using deep learning, random forest and Cox regression. Calibration was assessed by comparing observed to predicted risks; and discrimination by area under the ‘receiver operating curve’ (AUC). Findings 14,418 deaths (2.9%) occurred over a total follow-up time of 3,508,454 person-years. A simple age and gender Cox model was the least predictive (AUC 0.689, 95% CI 0.681–0.699). A multivariate Cox regression model significantly improved discrimination by 6.2% (AUC 0.751, 95% CI 0.748–0.767). The application of machine-learning algorithms further improved discrimination by 3.2% using random forest (AUC 0.783, 95% CI 0.776–0.791) and 3.9% using deep learning (AUC 0.790, 95% CI 0.783–0.797). These ML algorithms improved discrimination by 9.4% and 10.1% respectively from a simple age and gender Cox regression model. Random forest and deep learning achieved similar levels of discrimination with no significant difference. Machine-learning algorithms were well-calibrated, while Cox regression models consistently over-predicted risk. Conclusions Machine-learning significantly improved accuracy of prediction of premature all-cause mortality in this middle-aged population, compared to standard methods. This study illustrates the value of machine-learning for risk prediction within a traditional epidemiological study design, and how this approach might be reported to assist scientific verification.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/1800/0ef9b6e02308ae299c4e1e2b3a32e951a508.pdf'},\n",
              "      'pubDate': '2019-03-27',\n",
              "      'pubUpdateDate': '2019-03-27',\n",
              "      'scorecardStats': [{'citationCount': 30,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'Medline',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'MAG',\n",
              "       'Unpaywall',\n",
              "       'PubMedCentral'],\n",
              "      'title': 'Prediction of premature all-cause mortality: A prospective general population cohort study comparing machine-learning and standard epidemiological approaches',\n",
              "      'tldr': {'abstractSimilarityScore': 40,\n",
              "       'text': 'Machine-learning significantly improved accuracy of prediction of premature all-cause mortality in this middle-aged population, compared to standard methods, and illustrates the value of machine-learning for risk prediction within a traditional epidemiological study design.'},\n",
              "      'venue': 'PloS one',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://ieeexplore.ieee.org/ielx7/6287639/8600701/08651516.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1109/ACCESS.2019.2901672'},\n",
              "       {'linkType': 'dblp',\n",
              "        'url': 'https://www.wikidata.org/entity/Q62828794'}],\n",
              "      'authors': ['Musaed A. Alhussein', 'G. Muhammad', 'M. S. Hossain'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': -0.4,\n",
              "       'citationVelocity': 9.666666666666666,\n",
              "       'citedByBuckets': [{'count': 5, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 15, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 9, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 24.292258203643268,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.06896551724137931,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 29,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 34,\n",
              "       'numViewableReferences': 34},\n",
              "      'entities': ['Deep learning',\n",
              "       'Convolutional neural network',\n",
              "       'Multilayer perceptron',\n",
              "       'Machine learning',\n",
              "       'Artificial neural network',\n",
              "       'Body of uterus',\n",
              "       'Electroencephalography Phase Synchronization',\n",
              "       'Mental Suffering',\n",
              "       'Biological Neural Networks'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'f0f37ca0473e9871ab04589c3b00dcaca0e86af7',\n",
              "      'journal': {'name': 'IEEE Access',\n",
              "       'pages': '27781-27788',\n",
              "       'volume': '7'},\n",
              "      'links': [{'linkType': 'ieee',\n",
              "        'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8651516'}],\n",
              "      'paperAbstract': 'With the advancement of machine learning technologies, particularly deep learning, the automated systems to assist human life are flourishing. In this paper, we propose an automatic electroencephalogram (EEG) pathology detection system based on deep learning. Various types of pathologies can affect brain signals. Thus, the brain signals captured in the form of EEG signals can indicate whether a person suffers from pathology or not. In the proposed system, the raw EEG signals are processed in the form of a spatio-temporal representation. The spatio-temporal form of the EEG signals is the input to a convolutional neural network (CNN). Two different CNN models, namely, a shallow model and a deep model, are investigated using transfer learning. A fusion strategy based on a multilayer perceptron is also investigated. The experimental results on the Temple University Hospital EEG Abnormal Corpus v2.0.0 show that the proposed system with the deep CNN model and fusion achieves 87.96% accuracy, which is better than some reported accuracy rates on the same corpus.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'ieee',\n",
              "       'url': 'http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8651516'},\n",
              "      'pubDate': None,\n",
              "      'pubUpdateDate': None,\n",
              "      'scorecardStats': [{'citationCount': 29,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['MAG', 'DBLP', 'ScienceParseMerged', 'IEEE', 'Unpaywall'],\n",
              "      'title': 'EEG Pathology Detection Based on Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'An automatic electroencephalogram (EEG) pathology detection system based on deep learning that achieves 87.96% accuracy, which is better than some reported accuracy rates on the same corpus.'},\n",
              "      'venue': 'IEEE Access',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['S. S. Mostafa',\n",
              "       'Fábio Mendonça',\n",
              "       'A. Ravelo-García',\n",
              "       'F. M. Dias'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationAcceleration': 0.9,\n",
              "       'citationVelocity': 9.666666666666666,\n",
              "       'citedByBuckets': [{'count': 10, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 19, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 37.43722146717502,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.06896551724137931,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 29,\n",
              "       'numKeyCitations': 2,\n",
              "       'numKeyReferences': 14,\n",
              "       'numReferences': 105,\n",
              "       'numViewableReferences': 105},\n",
              "      'entities': ['Sleep Apnea Syndromes',\n",
              "       'Exclusion',\n",
              "       'algorithm',\n",
              "       'Paper',\n",
              "       'Indexes',\n",
              "       'Scientific Publication'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science', 'Medicine'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'fe500d07922e5a82cb2bd3bcd2b3c412570017f5',\n",
              "      'journal': {'name': 'Sensors (Basel, Switzerland)', 'volume': '19'},\n",
              "      'links': [{'linkType': 's2',\n",
              "        'url': 'https://pdfs.semanticscholar.org/65fc/b0fd564b738d25953cf71e2ccd8a46500c83.pdf'}],\n",
              "      'paperAbstract': 'Sleep apnea is a sleep related disorder that significantly affects the population. Polysomnography, the gold standard, is expensive, inaccessible, uncomfortable and an expert technician is needed to score. Numerous researchers have proposed and implemented automatic scoring processes to address these issues, based on fewer sensors and automatic classification algorithms. Deep learning is gaining higher interest due to database availability, newly developed techniques, the possibility of producing machine created features and higher computing power that allows the algorithms to achieve better performance than the shallow classifiers. Therefore, the sleep apnea research has currently gained significant interest in deep learning. The goal of this work is to analyze the published research in the last decade, providing an answer to the research questions such as how to implement the different deep networks, what kind of pre-processing or feature extraction is needed, and the advantages and disadvantages of different kinds of networks. The employed signals, sensors, databases and implementation challenges were also considered. A systematic search was conducted on five indexing services from 2008–2018. A total of 255 papers were found and 21 were selected by considering the inclusion and exclusion criteria, using the preferred reporting items for systematic reviews and meta-analyses (PRISMA) approach.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 's2',\n",
              "       'url': 'https://pdfs.semanticscholar.org/65fc/b0fd564b738d25953cf71e2ccd8a46500c83.pdf'},\n",
              "      'pubDate': '2019-11-01',\n",
              "      'pubUpdateDate': '2019-11-12',\n",
              "      'scorecardStats': [{'citationCount': 29,\n",
              "        'keyCitationCount': 2,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Unpaywall',\n",
              "       'MergedPDFExtraction',\n",
              "       'Medline',\n",
              "       'DBLP',\n",
              "       'MAG',\n",
              "       'PubMedCentral',\n",
              "       'Crossref'],\n",
              "      'title': 'A Systematic Review of Detecting Sleep Apnea Using Deep Learning',\n",
              "      'tldr': {'abstractSimilarityScore': 41,\n",
              "       'text': 'The goal of this work is to analyze the published research in the last decade, providing an answer to the research questions such as how to implement the different deep networks, what kind of pre-processing or feature extraction is needed, and the advantages and disadvantages of different kinds of networks.'},\n",
              "      'venue': 'Sensors',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['M. Chaumont'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citationVelocity': 7.0,\n",
              "       'citedByBuckets': [{'count': 3, 'endKey': 2019, 'startKey': 2019},\n",
              "        {'count': 11, 'endKey': 2020, 'startKey': 2020},\n",
              "        {'count': 7, 'endKey': 2021, 'startKey': 2021}],\n",
              "       'estNumCitations': 37.62634272705707,\n",
              "       'firstCitationVelocityYear': 2019,\n",
              "       'keyCitationRate': 0.14285714285714285,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 21,\n",
              "       'numKeyCitations': 3,\n",
              "       'numKeyReferences': 17,\n",
              "       'numReferences': 134,\n",
              "       'numViewableReferences': 134},\n",
              "      'entities': ['Steganalysis',\n",
              "       'Deep learning',\n",
              "       'Steganography',\n",
              "       'Convolutional neural network',\n",
              "       'Artificial neural network',\n",
              "       'JPEG',\n",
              "       'Machine learning',\n",
              "       'Performance',\n",
              "       'Computation',\n",
              "       'Ensemble learning'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '29c53684ac64453e3d8b16454eb19473eebeb83c',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/1904.01444'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/1904.01444.pdf'}],\n",
              "      'paperAbstract': 'For almost 10 years, the detection of a message hidden in an image has been mainly carried out by the computation of a Rich Model (RM), followed by a classification by an Ensemble Classifier (EC). In 2015, the first study using a convolutional neural network (CNN) obtained the first results of steganalysis by Deep Learning approaching the results of two-step approaches (EC + RM). Therefore, over the 2015-2018 period, numerous publications have shown that it is possible to obtain better performances notably in spatial steganalysis, in JPEG steganalysis, in Selection-Channel-Aware steganalysis, in quantitative steganalysis. This chapter deals with deep learning in steganalysis from the point of view of the existing, by presenting the different neural networks that have been evaluated with a methodology specific to the discipline of steganalysis, and this during the period 2015-2018. The chapter is not intended to repeat the basic concepts of machine learning or deep learning. We will thus give in a generic way the structure of a deep neural network, we will present the networks proposed in the literature for the different scenarios of steganalysis, and finally, we will discuss steganography by GAN.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/1904.01444.pdf'},\n",
              "      'pubDate': '2019-03-31',\n",
              "      'pubUpdateDate': '2019-04-02',\n",
              "      'scorecardStats': [{'citationCount': 21,\n",
              "        'keyCitationCount': 3,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'ArXiv',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'Anansi',\n",
              "       'ScienceParseMerged',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'Anansi',\n",
              "       'MergedPDFExtraction',\n",
              "       'MergedPDFExtraction',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'ScienceParseMerged',\n",
              "       'Anansi'],\n",
              "      'title': 'Deep Learning in steganography and steganalysis from 2015 to 2018',\n",
              "      'tldr': {'abstractSimilarityScore': 37,\n",
              "       'text': 'The structure of a deep neural network is given in a generic way, the networks proposed in the literature for the different scenarios of steganalysis are presented, and steganography by GAN is discussed.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2019'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Adita Kulkarni', 'A. Seetharam'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 2,\n",
              "         'endKey': 2020,\n",
              "         'startKey': 2020}],\n",
              "       'estNumCitations': 2.3542600896860986,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.5,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 2,\n",
              "       'numKeyCitations': 1,\n",
              "       'numKeyReferences': 1,\n",
              "       'numReferences': 18,\n",
              "       'numViewableReferences': 18},\n",
              "      'entities': ['Machine learning',\n",
              "       'Routing',\n",
              "       'Reinforcement learning',\n",
              "       'Deep learning',\n",
              "       'Graphical model',\n",
              "       'Network performance',\n",
              "       'Floor and ceiling functions',\n",
              "       'Experiment',\n",
              "       'Tracing (software)',\n",
              "       'Cache (computing)'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': '6c179b9506ebfafc5f6cadaaede540082bebff97',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2004.06787'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2004.06787.pdf'}],\n",
              "      'paperAbstract': 'In-network caching is likely to become an integral part of various networked systems (e.g., 5G networks, LPWAN and IoT systems) in the near future. In this paper, we compare and contrast model-based and machine learning approaches for designing caching and routing strategies to improve cache network performance (e.g., delay, hit rate). We first outline the key principles used in the design of model-based strategies and discuss the analytical results and bounds obtained for these approaches. By conducting experiments on real-world traces and networks, we identify the interplay between content popularity skewness and request stream correlation as an important factor affecting cache performance. With respect to routing, we show that the main factors impacting performance are alternate path routing and content search. We then discuss the applicability of multiple machine learning models, specifically reinforcement learning, deep learning, transfer learning and probabilistic graphical models for the caching and routing problem.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2004.06787.pdf'},\n",
              "      'pubDate': '2020-04-14',\n",
              "      'pubUpdateDate': '2020-04-14',\n",
              "      'scorecardStats': [{'citationCount': 2,\n",
              "        'keyCitationCount': 1,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['ArXiv', 'MergedPDFExtraction', 'DBLP', 'MAG'],\n",
              "      'title': 'Model and Machine Learning based Caching and Routing Algorithms for Cache-enabled Networks',\n",
              "      'tldr': {'abstractSimilarityScore': 55,\n",
              "       'text': 'This paper compares and contrast model-based and machine learning approaches for designing caching and routing strategies to improve cache network performance and discusses the applicability of multiple machine learning models, specifically reinforcement learning, deep learning, transfer learning and probabilistic graphical models.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Kakia Chatsiou', 'Slava J. Mikhaylov'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 2,\n",
              "         'endKey': 2020,\n",
              "         'startKey': 2020}],\n",
              "       'estNumCitations': 1.0285757006861491,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 2,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 5,\n",
              "       'numReferences': 128,\n",
              "       'numViewableReferences': 128},\n",
              "      'entities': ['Deep learning',\n",
              "       'Natural language processing',\n",
              "       'Artificial intelligence',\n",
              "       'Machine learning',\n",
              "       'Computational resource',\n",
              "       'Theory',\n",
              "       'Algorithm'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'acff518b945f15b1a687ac313b25048c50fed044',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2005.06540'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2005.06540.pdf'}],\n",
              "      'paperAbstract': 'Political science, and social science in general, have traditionally been using computational methods to study areas such as voting behavior, policy making, international conflict, and international development. More recently, increasingly available quantities of data are being combined with improved algorithms and affordable computational resources to predict, learn, and discover new insights from data that is large in volume and variety. New developments in the areas of machine learning, deep learning, natural language processing (NLP), and, more generally, artificial intelligence (AI) are opening up new opportunities for testing theories and evaluating the impact of interventions and programs in a more dynamic and effective way. Applications using large volumes of structured and unstructured data are becoming common in government and industry, and increasingly also in social science research. This chapter offers an introduction to such methods drawing examples from political science. Focusing on the areas where the strengths of the methods coincide with challenges in these fields, the chapter first presents an introduction to AI and its core technology - machine learning, with its rapidly developing subfield of deep learning. The discussion of deep neural networks is illustrated with the NLP tasks that are relevant to political science. The latest advances in deep learning methods for NLP are also reviewed, together with their potential for improving information extraction and pattern recognition from political science texts.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2005.06540.pdf'},\n",
              "      'pubDate': '2020-04-09',\n",
              "      'pubUpdateDate': '2020-05-13',\n",
              "      'scorecardStats': [{'citationCount': 2,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Crossref',\n",
              "       'Unpaywall',\n",
              "       'ArXiv',\n",
              "       'MAG',\n",
              "       'MergedPDFExtraction',\n",
              "       'DBLP'],\n",
              "      'title': 'Deep Learning for Political Science',\n",
              "      'tldr': {'abstractSimilarityScore': 43,\n",
              "       'text': 'Focusing on the areas where the strengths of the methods coincide with challenges in these fields, the chapter first presents an introduction to AI and its core technology - machine learning, with its rapidly developing subfield of deep learning.'},\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [],\n",
              "      'authors': ['Yi Wang',\n",
              "       'Yang Yang',\n",
              "       'Weiguo Zhu',\n",
              "       'Yi Wu',\n",
              "       'Xu Yan',\n",
              "       'Yongfeng Liu',\n",
              "       'Yu Wang',\n",
              "       'Liang Xie',\n",
              "       'Ziyao Gao',\n",
              "       'Wenjing Zhu',\n",
              "       'Xiang Chen',\n",
              "       'Wei Yan',\n",
              "       'Mingjie Tang',\n",
              "       'Yuan-ju Tang'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 2,\n",
              "         'endKey': 2021,\n",
              "         'startKey': 2021}],\n",
              "       'estNumCitations': 2.057329511365909,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 2,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 2,\n",
              "       'numReferences': 13,\n",
              "       'numViewableReferences': 13},\n",
              "      'entities': ['SQL',\n",
              "       'Machine learning',\n",
              "       'Apache Hive',\n",
              "       'MySQL',\n",
              "       'Unsupervised learning',\n",
              "       'XGBoost',\n",
              "       'Database',\n",
              "       'Feature extraction',\n",
              "       'TensorFlow',\n",
              "       'Parsing',\n",
              "       'scikit-learn',\n",
              "       'Visual modeling',\n",
              "       'End-to-end principle',\n",
              "       'Algorithm',\n",
              "       'Microservices',\n",
              "       'Online and offline',\n",
              "       'Software deployment'],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [{'contentType': {'id': 'GITHUB_REPO'},\n",
              "        'count': 1}],\n",
              "      'fieldsOfStudy': ['Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'bbb579cf30403aedb8071b877c3991744757a38e',\n",
              "      'journal': {'name': 'ArXiv', 'volume': 'abs/2001.06846'},\n",
              "      'links': [{'linkType': 'arxiv',\n",
              "        'url': 'https://arxiv.org/pdf/2001.06846.pdf'}],\n",
              "      'paperAbstract': 'Industrial AI systems are mostly end-to-end machine learning (ML) workflows. A typical recommendation or business intelligence system includes many online micro-services and offline jobs. We describe SQLFlow for developing such workflows efficiently in SQL. SQL enables developers to write short programs focusing on the purpose (what) and ignoring the procedure (how). Previous database systems extended their SQL dialect to support ML. SQLFlow (this https URL ) takes another strategy to work as a bridge over various database systems, including MySQL, Apache Hive, and Alibaba MaxCompute, and ML engines like TensorFlow, XGBoost, and scikit-learn. We extended SQL syntax carefully to make the extension working with various SQL dialects. We implement the extension by inventing a collaborative parsing algorithm. SQLFlow is efficient and expressive to a wide variety of ML techniques -- supervised and unsupervised learning; deep networks and tree models; visual model explanation in addition to training and prediction; data processing and feature extraction in addition to ML. SQLFlow compiles a SQL program into a Kubernetes-native workflow for fault-tolerable execution and on-cloud deployment. Current industrial users include Ant Financial, DiDi, and Alibaba Group.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'arxiv',\n",
              "       'url': 'https://arxiv.org/pdf/2001.06846.pdf'},\n",
              "      'pubDate': '2020-01-19',\n",
              "      'pubUpdateDate': '2020-01-19',\n",
              "      'scorecardStats': [{'citationCount': 2,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['DBLP', 'ArXiv', 'MergedPDFExtraction', 'MAG'],\n",
              "      'title': 'SQLFlow: A Bridge between SQL and Machine Learning',\n",
              "      'tldr': None,\n",
              "      'venue': 'ArXiv',\n",
              "      'videos': [],\n",
              "      'year': '2020'},\n",
              "     {'alternatePaperLinks': [{'linkType': 'openaccess',\n",
              "        'url': 'https://www.nature.com/articles/s41598-020-76928-z.pdf'},\n",
              "       {'linkType': 'doi',\n",
              "        'url': 'https://doi.org/10.1038/s41598-020-76928-z'}],\n",
              "      'authors': ['A. Goyal',\n",
              "       'Maheshwar Kuchana',\n",
              "       'Kameswari Prasada Rao Ayyagari'],\n",
              "      'badges': [{'id': 'OPEN_ACCESS'}],\n",
              "      'blogs': [],\n",
              "      'citationContexts': [],\n",
              "      'citationStats': {'citedByBuckets': [{'count': 1,\n",
              "         'endKey': 2021,\n",
              "         'startKey': 2021}],\n",
              "       'estNumCitations': 1.991188285603214,\n",
              "       'firstCitationVelocityYear': 2020,\n",
              "       'keyCitationRate': 0.0,\n",
              "       'keyCitedByBuckets': [],\n",
              "       'lastCitationVelocityYear': 2021,\n",
              "       'numCitations': 1,\n",
              "       'numKeyCitations': 0,\n",
              "       'numKeyReferences': 0,\n",
              "       'numReferences': 76,\n",
              "       'numViewableReferences': 76},\n",
              "      'entities': [],\n",
              "      'entityRelations': [],\n",
              "      'externalContentStats': [],\n",
              "      'fieldsOfStudy': ['Medicine', 'Computer Science'],\n",
              "      'githubReferences': [],\n",
              "      'id': 'b6f01851898fdba03a8153519f9f2efaf6cfbb2a',\n",
              "      'journal': {'name': 'Scientific Reports', 'volume': '10'},\n",
              "      'links': [{'linkType': 'medline',\n",
              "        'url': 'https://www.ncbi.nlm.nih.gov/pubmed/33262383'}],\n",
              "      'paperAbstract': 'In-vitro fertilization (IVF) is a popular method of resolving complications such as endometriosis, poor egg quality, a genetic disease of mother or father, problems with ovulation, antibody problems that harm sperm or eggs, the inability of sperm to penetrate or survive in the cervical mucus and low sperm counts, resulting human infertility. Nevertheless, IVF does not guarantee success in the fertilization. Choosing IVF is burdensome for the reason of high cost and uncertainty in the result. As the complications and fertilization factors are numerous in the IVF process, it is a cumbersome task for fertility doctors to give an accurate prediction of a successful birth. Artificial Intelligence (AI) has been employed in this study for predicting the live-birth occurrence. This work mainly focuses on making predictions of live-birth occurrence when an embryo forms from a couple and not a donor. Here, we compare various AI algorithms, including both classical Machine Learning, deep learning architecture, and an ensemble of algorithms on the publicly available dataset provided by Human Fertilisation and Embryology Authority (HFEA). Insights on data and metrics such as confusion matrices, F1-score, precision, recall, receiver operating characteristic (ROC) curves are demonstrated in the subsequent sections. The training process has two settings Without feature selection and With feature selection to train classifier models. Machine Learning, Deep learning, ensemble models classification paradigms have been trained in both settings. The Random Forest model achieves the highest F1-score of 76.49% in without feature selection setting. For the same model, the precision, recall, and area under the ROC Curve (ROC AUC) scores are 77%, 76%, and 84.60%, respectively. The success of the pregnancy depends on both male and female traits and living conditions. This study predicts a successful pregnancy through the clinically relevant parameters in In-vitro fertilization. Thus artificial intelligence plays a promising role in decision making process to support the diagnosis, prognosis, treatment etc.',\n",
              "      'presentationUrls': [],\n",
              "      'primaryPaperLink': {'linkType': 'medline',\n",
              "       'url': 'https://www.ncbi.nlm.nih.gov/pubmed/33262383'},\n",
              "      'pubDate': '2020-12-01',\n",
              "      'pubUpdateDate': '2020-12-01',\n",
              "      'scorecardStats': [{'citationCount': 1,\n",
              "        'keyCitationCount': 0,\n",
              "        'score': 10.0,\n",
              "        'typeKey': 'cited_by'}],\n",
              "      'socialLinks': [],\n",
              "      'sources': ['Medline',\n",
              "       'Crossref',\n",
              "       'Unpaywall',\n",
              "       'MergedPDFExtraction',\n",
              "       'PubMedCentral',\n",
              "       'MAG'],\n",
              "      'title': 'Machine learning predicts live-birth occurrence before in-vitro fertilization treatment',\n",
              "      'tldr': {'abstractSimilarityScore': 44,\n",
              "       'text': 'Artificial intelligence plays a promising role in decision making process to support the diagnosis, prognosis, treatment etc.'},\n",
              "      'venue': 'Scientific reports',\n",
              "      'videos': [],\n",
              "      'year': '2020'}]}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_AxXsbJuARM"
      },
      "source": [
        "# Tudo que vem com base em 1 paper (dict.)\n",
        "# from_Webpage.all[\"Results\"][0][\"Papers\"][0]\n",
        "\n",
        "# json file = SearchWeb().load_json(\"JsonFile.json\")\n",
        "data = from_Webpage.load_json('../Data/Data(total-citations).json')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G56ggSNCiiE",
        "outputId": "94a98eed-2099-409e-d0bf-f2a76a2b7494"
      },
      "source": [
        "print(data[\"Results\"][0]['Page']['Papers'][0].keys())\n",
        "data[\"Results\"][0]['Page']['Papers'][0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['authors', 'id', 'socialLinks', 'title', 'paperAbstract', 'year', 'venue', 'citationContexts', 'citationStats', 'sources', 'externalContentStats', 'journal', 'presentationUrls', 'links', 'primaryPaperLink', 'alternatePaperLinks', 'entities', 'entityRelations', 'blogs', 'videos', 'githubReferences', 'scorecardStats', 'fieldsOfStudy', 'pubDate', 'pubUpdateDate', 'badges', 'tldr'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'authors': ['J. E. Bell', 'P. McMullen'],\n",
              " 'id': 'd2af1253d2529b9406eced6e2dfc51fb2cb12226',\n",
              " 'socialLinks': [],\n",
              " 'title': 'Ant colony optimization techniques for the vehicle routing problem',\n",
              " 'paperAbstract': 'Abstract This research applies the meta-heuristic method of ant colony optimization (ACO) to an established set of vehicle routing problems (VRP). The procedure simulates the decision-making processes of ant colonies as they forage for food and is similar to other adaptive learning and artificial intelligence techniques such as Tabu Search, Simulated Annealing and Genetic Algorithms. Modifications are made to the ACO algorithm used to solve the traditional traveling salesman problem in order to allow the search of the multiple routes of the VRP. Experimentation shows that the algorithm is successful in finding solutions within 1% of known optimal solutions and the use of multiple ant colonies is found to provide a comparatively competitive solution technique especially for larger problems. Additionally, the size of the candidate lists used within the algorithm is a significant factor in finding improved solutions, and the computational times for the algorithm compare favorably with other solution methods.',\n",
              " 'year': '2004',\n",
              " 'venue': 'Adv. Eng. Informatics',\n",
              " 'citationContexts': [],\n",
              " 'citationStats': {'citedByBuckets': [{'startKey': 2003,\n",
              "    'endKey': 2003,\n",
              "    'count': 1},\n",
              "   {'startKey': 2005, 'endKey': 2005, 'count': 5},\n",
              "   {'startKey': 2006, 'endKey': 2006, 'count': 12},\n",
              "   {'startKey': 2007, 'endKey': 2007, 'count': 21},\n",
              "   {'startKey': 2008, 'endKey': 2008, 'count': 22},\n",
              "   {'startKey': 2009, 'endKey': 2009, 'count': 35},\n",
              "   {'startKey': 2010, 'endKey': 2010, 'count': 46},\n",
              "   {'startKey': 2011, 'endKey': 2011, 'count': 38},\n",
              "   {'startKey': 2012, 'endKey': 2012, 'count': 53},\n",
              "   {'startKey': 2013, 'endKey': 2013, 'count': 52},\n",
              "   {'startKey': 2014, 'endKey': 2014, 'count': 41},\n",
              "   {'startKey': 2015, 'endKey': 2015, 'count': 48},\n",
              "   {'startKey': 2016, 'endKey': 2016, 'count': 53},\n",
              "   {'startKey': 2017, 'endKey': 2017, 'count': 51},\n",
              "   {'startKey': 2018, 'endKey': 2018, 'count': 39},\n",
              "   {'startKey': 2019, 'endKey': 2019, 'count': 48},\n",
              "   {'startKey': 2020, 'endKey': 2020, 'count': 51},\n",
              "   {'startKey': 2021, 'endKey': 2021, 'count': 15}],\n",
              "  'keyCitedByBuckets': [],\n",
              "  'numCitations': 635,\n",
              "  'estNumCitations': 888.1761019324003,\n",
              "  'numReferences': 25,\n",
              "  'numKeyCitations': 28,\n",
              "  'numKeyReferences': 4,\n",
              "  'numViewableReferences': 25,\n",
              "  'keyCitationRate': 0.04409448818897638,\n",
              "  'citationVelocity': 38.0,\n",
              "  'citationAcceleration': -0.7058823529411765,\n",
              "  'firstCitationVelocityYear': 2019,\n",
              "  'lastCitationVelocityYear': 2021},\n",
              " 'sources': ['Crawler',\n",
              "  'Anansi',\n",
              "  'ScienceParseMerged',\n",
              "  'DBLP',\n",
              "  'Grobid',\n",
              "  'Unpaywall',\n",
              "  'MAG',\n",
              "  'CiteSeerX'],\n",
              " 'externalContentStats': [],\n",
              " 'journal': {'name': 'Adv. Eng. Informatics',\n",
              "  'volume': '18',\n",
              "  'pages': '41-48'},\n",
              " 'presentationUrls': [],\n",
              " 'links': [{'url': 'https://doi.org/10.1016/j.aei.2004.07.001',\n",
              "   'linkType': 'doi'}],\n",
              " 'primaryPaperLink': {'url': 'https://doi.org/10.1016/j.aei.2004.07.001',\n",
              "  'linkType': 'doi'},\n",
              " 'alternatePaperLinks': [{'url': 'http://natcomp.liacs.nl/SWI/papers/ant.colony.optimization/Ant%20colony%20optimization%20techniques%20for%20the%20vehicle%20routing%20problem.pdf',\n",
              "   'linkType': 'anansi'},\n",
              "  {'url': 'http://www.joydivisionman.com/vita/aei2.pdf',\n",
              "   'linkType': 'anansi'}],\n",
              " 'entities': ['Vehicle routing problem',\n",
              "  'Ant colony optimization algorithms',\n",
              "  'Mathematical optimization',\n",
              "  'Tabu search',\n",
              "  'Travelling salesman problem',\n",
              "  'Simulated annealing',\n",
              "  'Artificial intelligence',\n",
              "  'Genetic algorithm',\n",
              "  'Heuristic',\n",
              "  'Computation'],\n",
              " 'entityRelations': [],\n",
              " 'blogs': [],\n",
              " 'videos': [],\n",
              " 'githubReferences': [],\n",
              " 'scorecardStats': [{'typeKey': 'cited_by',\n",
              "   'citationCount': 635,\n",
              "   'keyCitationCount': 28,\n",
              "   'score': 10.0}],\n",
              " 'fieldsOfStudy': ['Engineering', 'Computer Science'],\n",
              " 'pubDate': None,\n",
              " 'pubUpdateDate': None,\n",
              " 'badges': [{'id': 'OPEN_ACCESS'}],\n",
              " 'tldr': {'text': 'Modifications are made to the ACO algorithm used to solve the traditional traveling salesman problem in order to allow the search of the multiple routes of the VRP and the use of multiple ant colonies is found to provide a comparatively competitive solution technique especially for larger problems.',\n",
              "  'abstractSimilarityScore': 43}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}